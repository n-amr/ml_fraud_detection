{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "    - The goal of this notebook is to test some ML models in order to optimize fraud detection for an ecommerce website\n",
    "    - We will try out different classifiers (logreg, decision tree, random forest, svm) and also try a boosting method with AdaBoost\n",
    "    - The purpose of this exercise is to practice Machine Learning as well as data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "fraud_init = pd.read_csv(\"Fraud_Data.csv\")\n",
    "ip_init = pd.read_csv(\"IpAddress_to_Country.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151112, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>signup_time</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>device_id</th>\n",
       "      <th>source</th>\n",
       "      <th>browser</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22058</td>\n",
       "      <td>2015-02-24 22:55:49</td>\n",
       "      <td>2015-04-18 02:47:11</td>\n",
       "      <td>34</td>\n",
       "      <td>QVPSPJUOCKZAR</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>7.327584e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>333320</td>\n",
       "      <td>2015-06-07 20:39:50</td>\n",
       "      <td>2015-06-08 01:38:54</td>\n",
       "      <td>16</td>\n",
       "      <td>EOGFQPIZPYXFZ</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>3.503114e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1359</td>\n",
       "      <td>2015-01-01 18:52:44</td>\n",
       "      <td>2015-01-01 18:52:45</td>\n",
       "      <td>15</td>\n",
       "      <td>YSSKYOSJHPPLJ</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Opera</td>\n",
       "      <td>M</td>\n",
       "      <td>53</td>\n",
       "      <td>2.621474e+09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150084</td>\n",
       "      <td>2015-04-28 21:13:25</td>\n",
       "      <td>2015-05-04 13:54:50</td>\n",
       "      <td>44</td>\n",
       "      <td>ATGTXKYKUDUQN</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>41</td>\n",
       "      <td>3.840542e+09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221365</td>\n",
       "      <td>2015-07-21 07:09:52</td>\n",
       "      <td>2015-09-09 18:40:53</td>\n",
       "      <td>39</td>\n",
       "      <td>NAUITBZFJKHWW</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>4.155831e+08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id          signup_time        purchase_time  purchase_value  \\\n",
       "0    22058  2015-02-24 22:55:49  2015-04-18 02:47:11              34   \n",
       "1   333320  2015-06-07 20:39:50  2015-06-08 01:38:54              16   \n",
       "2     1359  2015-01-01 18:52:44  2015-01-01 18:52:45              15   \n",
       "3   150084  2015-04-28 21:13:25  2015-05-04 13:54:50              44   \n",
       "4   221365  2015-07-21 07:09:52  2015-09-09 18:40:53              39   \n",
       "\n",
       "       device_id source browser sex  age    ip_address  class  \n",
       "0  QVPSPJUOCKZAR    SEO  Chrome   M   39  7.327584e+08      0  \n",
       "1  EOGFQPIZPYXFZ    Ads  Chrome   F   53  3.503114e+08      0  \n",
       "2  YSSKYOSJHPPLJ    SEO   Opera   M   53  2.621474e+09      1  \n",
       "3  ATGTXKYKUDUQN    SEO  Safari   M   41  3.840542e+09      0  \n",
       "4  NAUITBZFJKHWW    Ads  Safari   M   45  4.155831e+08      0  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(fraud_init.shape)\n",
    "fraud_init.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>signup_time</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>device_id</th>\n",
       "      <th>source</th>\n",
       "      <th>browser</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>151112.000000</td>\n",
       "      <td>151112</td>\n",
       "      <td>151112</td>\n",
       "      <td>151112.000000</td>\n",
       "      <td>151112</td>\n",
       "      <td>151112</td>\n",
       "      <td>151112</td>\n",
       "      <td>151112</td>\n",
       "      <td>151112.000000</td>\n",
       "      <td>1.511120e+05</td>\n",
       "      <td>151112.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>151112</td>\n",
       "      <td>150679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137956</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-12 04:18:34</td>\n",
       "      <td>2015-06-08 09:42:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NGQCKIADMZORL</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>60615</td>\n",
       "      <td>61432</td>\n",
       "      <td>88293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>200171.040970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.935372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.140704</td>\n",
       "      <td>2.152145e+09</td>\n",
       "      <td>0.093646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>115369.285024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.322762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.617733</td>\n",
       "      <td>1.248497e+09</td>\n",
       "      <td>0.291336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.209350e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100642.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.085934e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>199958.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.154770e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>300054.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>3.243258e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>400000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>4.294850e+09</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              user_id          signup_time        purchase_time  \\\n",
       "count   151112.000000               151112               151112   \n",
       "unique            NaN               151112               150679   \n",
       "top               NaN  2015-02-12 04:18:34  2015-06-08 09:42:04   \n",
       "freq              NaN                    1                    3   \n",
       "mean    200171.040970                  NaN                  NaN   \n",
       "std     115369.285024                  NaN                  NaN   \n",
       "min          2.000000                  NaN                  NaN   \n",
       "25%     100642.500000                  NaN                  NaN   \n",
       "50%     199958.000000                  NaN                  NaN   \n",
       "75%     300054.000000                  NaN                  NaN   \n",
       "max     400000.000000                  NaN                  NaN   \n",
       "\n",
       "        purchase_value      device_id  source browser     sex            age  \\\n",
       "count    151112.000000         151112  151112  151112  151112  151112.000000   \n",
       "unique             NaN         137956       3       5       2            NaN   \n",
       "top                NaN  NGQCKIADMZORL     SEO  Chrome       M            NaN   \n",
       "freq               NaN             20   60615   61432   88293            NaN   \n",
       "mean         36.935372            NaN     NaN     NaN     NaN      33.140704   \n",
       "std          18.322762            NaN     NaN     NaN     NaN       8.617733   \n",
       "min           9.000000            NaN     NaN     NaN     NaN      18.000000   \n",
       "25%          22.000000            NaN     NaN     NaN     NaN      27.000000   \n",
       "50%          35.000000            NaN     NaN     NaN     NaN      33.000000   \n",
       "75%          49.000000            NaN     NaN     NaN     NaN      39.000000   \n",
       "max         154.000000            NaN     NaN     NaN     NaN      76.000000   \n",
       "\n",
       "          ip_address          class  \n",
       "count   1.511120e+05  151112.000000  \n",
       "unique           NaN            NaN  \n",
       "top              NaN            NaN  \n",
       "freq             NaN            NaN  \n",
       "mean    2.152145e+09       0.093646  \n",
       "std     1.248497e+09       0.291336  \n",
       "min     5.209350e+04       0.000000  \n",
       "25%     1.085934e+09       0.000000  \n",
       "50%     2.154770e+09       0.000000  \n",
       "75%     3.243258e+09       0.000000  \n",
       "max     4.294850e+09       1.000000  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_init.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>age</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002617</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>-0.003144</td>\n",
       "      <td>0.001945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>purchase_value</th>\n",
       "      <td>0.002617</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>-0.000328</td>\n",
       "      <td>0.001011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.006624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ip_address</th>\n",
       "      <td>-0.003144</td>\n",
       "      <td>-0.000328</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>0.001945</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.006624</td>\n",
       "      <td>-0.005208</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id  purchase_value       age  ip_address     class\n",
       "user_id         1.000000        0.002617  0.000611   -0.003144  0.001945\n",
       "purchase_value  0.002617        1.000000  0.002370   -0.000328  0.001011\n",
       "age             0.000611        0.002370  1.000000    0.001140  0.006624\n",
       "ip_address     -0.003144       -0.000328  0.001140    1.000000 -0.005208\n",
       "class           0.001945        0.001011  0.006624   -0.005208  1.000000"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_init.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(138846, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lower_bound_ip_address</th>\n",
       "      <th>upper_bound_ip_address</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16777216.0</td>\n",
       "      <td>16777471</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16777472.0</td>\n",
       "      <td>16777727</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16777728.0</td>\n",
       "      <td>16778239</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16778240.0</td>\n",
       "      <td>16779263</td>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16779264.0</td>\n",
       "      <td>16781311</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lower_bound_ip_address  upper_bound_ip_address    country\n",
       "0              16777216.0                16777471  Australia\n",
       "1              16777472.0                16777727      China\n",
       "2              16777728.0                16778239      China\n",
       "3              16778240.0                16779263  Australia\n",
       "4              16779264.0                16781311      China"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ip_init.shape)\n",
    "ip_init.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def transform_ip(ip_ad) :\n",
    "    try :\n",
    "        return ip_init.country[(ip_init.lower_bound_ip_address < ip_ad) &\\\n",
    "                                  (ip_init.upper_bound_ip_address > ip_ad)].iloc[0]\n",
    "    except IndexError :\n",
    "        return \"Unknown_Country\"  \n",
    "fraud_init[\"country_name\"] = fraud_init[\"ip_address\"].apply(transform_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>signup_time</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>device_id</th>\n",
       "      <th>source</th>\n",
       "      <th>browser</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>class</th>\n",
       "      <th>country_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22058</td>\n",
       "      <td>2015-02-24 22:55:49</td>\n",
       "      <td>2015-04-18 02:47:11</td>\n",
       "      <td>34</td>\n",
       "      <td>QVPSPJUOCKZAR</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>7.327584e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>333320</td>\n",
       "      <td>2015-06-07 20:39:50</td>\n",
       "      <td>2015-06-08 01:38:54</td>\n",
       "      <td>16</td>\n",
       "      <td>EOGFQPIZPYXFZ</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>3.503114e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1359</td>\n",
       "      <td>2015-01-01 18:52:44</td>\n",
       "      <td>2015-01-01 18:52:45</td>\n",
       "      <td>15</td>\n",
       "      <td>YSSKYOSJHPPLJ</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Opera</td>\n",
       "      <td>M</td>\n",
       "      <td>53</td>\n",
       "      <td>2.621474e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150084</td>\n",
       "      <td>2015-04-28 21:13:25</td>\n",
       "      <td>2015-05-04 13:54:50</td>\n",
       "      <td>44</td>\n",
       "      <td>ATGTXKYKUDUQN</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>41</td>\n",
       "      <td>3.840542e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown_Country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221365</td>\n",
       "      <td>2015-07-21 07:09:52</td>\n",
       "      <td>2015-09-09 18:40:53</td>\n",
       "      <td>39</td>\n",
       "      <td>NAUITBZFJKHWW</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>4.155831e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id          signup_time        purchase_time  purchase_value  \\\n",
       "0    22058  2015-02-24 22:55:49  2015-04-18 02:47:11              34   \n",
       "1   333320  2015-06-07 20:39:50  2015-06-08 01:38:54              16   \n",
       "2     1359  2015-01-01 18:52:44  2015-01-01 18:52:45              15   \n",
       "3   150084  2015-04-28 21:13:25  2015-05-04 13:54:50              44   \n",
       "4   221365  2015-07-21 07:09:52  2015-09-09 18:40:53              39   \n",
       "\n",
       "       device_id source browser sex  age    ip_address  class     country_name  \n",
       "0  QVPSPJUOCKZAR    SEO  Chrome   M   39  7.327584e+08      0            Japan  \n",
       "1  EOGFQPIZPYXFZ    Ads  Chrome   F   53  3.503114e+08      0    United States  \n",
       "2  YSSKYOSJHPPLJ    SEO   Opera   M   53  2.621474e+09      1    United States  \n",
       "3  ATGTXKYKUDUQN    SEO  Safari   M   41  3.840542e+09      0  Unknown_Country  \n",
       "4  NAUITBZFJKHWW    Ads  Safari   M   45  4.155831e+08      0    United States  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_init.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>signup_time</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>device_id</th>\n",
       "      <th>source</th>\n",
       "      <th>browser</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>class</th>\n",
       "      <th>country_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>151112.000000</td>\n",
       "      <td>151112</td>\n",
       "      <td>151112</td>\n",
       "      <td>151112.000000</td>\n",
       "      <td>151112</td>\n",
       "      <td>151112</td>\n",
       "      <td>151112</td>\n",
       "      <td>151112</td>\n",
       "      <td>151112.000000</td>\n",
       "      <td>1.511120e+05</td>\n",
       "      <td>151112.000000</td>\n",
       "      <td>151112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>151112</td>\n",
       "      <td>150679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137956</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-12 04:18:34</td>\n",
       "      <td>2015-06-08 09:42:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NGQCKIADMZORL</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>60615</td>\n",
       "      <td>61432</td>\n",
       "      <td>88293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>200171.040970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.935372</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.140704</td>\n",
       "      <td>2.152145e+09</td>\n",
       "      <td>0.093646</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>115369.285024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.322762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.617733</td>\n",
       "      <td>1.248497e+09</td>\n",
       "      <td>0.291336</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.209350e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100642.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.085934e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>199958.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.154770e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>300054.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>3.243258e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>400000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>4.294850e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              user_id          signup_time        purchase_time  \\\n",
       "count   151112.000000               151112               151112   \n",
       "unique            NaN               151112               150679   \n",
       "top               NaN  2015-02-12 04:18:34  2015-06-08 09:42:04   \n",
       "freq              NaN                    1                    3   \n",
       "mean    200171.040970                  NaN                  NaN   \n",
       "std     115369.285024                  NaN                  NaN   \n",
       "min          2.000000                  NaN                  NaN   \n",
       "25%     100642.500000                  NaN                  NaN   \n",
       "50%     199958.000000                  NaN                  NaN   \n",
       "75%     300054.000000                  NaN                  NaN   \n",
       "max     400000.000000                  NaN                  NaN   \n",
       "\n",
       "        purchase_value      device_id  source browser     sex            age  \\\n",
       "count    151112.000000         151112  151112  151112  151112  151112.000000   \n",
       "unique             NaN         137956       3       5       2            NaN   \n",
       "top                NaN  NGQCKIADMZORL     SEO  Chrome       M            NaN   \n",
       "freq               NaN             20   60615   61432   88293            NaN   \n",
       "mean         36.935372            NaN     NaN     NaN     NaN      33.140704   \n",
       "std          18.322762            NaN     NaN     NaN     NaN       8.617733   \n",
       "min           9.000000            NaN     NaN     NaN     NaN      18.000000   \n",
       "25%          22.000000            NaN     NaN     NaN     NaN      27.000000   \n",
       "50%          35.000000            NaN     NaN     NaN     NaN      33.000000   \n",
       "75%          49.000000            NaN     NaN     NaN     NaN      39.000000   \n",
       "max         154.000000            NaN     NaN     NaN     NaN      76.000000   \n",
       "\n",
       "          ip_address          class   country_name  \n",
       "count   1.511120e+05  151112.000000         151112  \n",
       "unique           NaN            NaN            182  \n",
       "top              NaN            NaN  United States  \n",
       "freq             NaN            NaN          58049  \n",
       "mean    2.152145e+09       0.093646            NaN  \n",
       "std     1.248497e+09       0.291336            NaN  \n",
       "min     5.209350e+04       0.000000            NaN  \n",
       "25%     1.085934e+09       0.000000            NaN  \n",
       "50%     2.154770e+09       0.000000            NaN  \n",
       "75%     3.243258e+09       0.000000            NaN  \n",
       "max     4.294850e+09       1.000000            NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_init.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# function that easily returns table of count with percentage\n",
    "def show_unique_count(df_name, column_name, digits=2):\n",
    "    \n",
    "    count = df_name[column_name].value_counts(dropna=False)\n",
    "    percentage = (df_name[column_name].value_counts \\\n",
    "                      (dropna=False, normalize=True) \\\n",
    "                      *100).round(digits)\n",
    "    table = pd.concat([count,percentage],\\\n",
    "                    axis=1,\\\n",
    "                    keys=['counts', '%'])\n",
    "    return(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>58049</td>\n",
       "      <td>38.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown_Country</th>\n",
       "      <td>21966</td>\n",
       "      <td>14.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>12038</td>\n",
       "      <td>7.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japan</th>\n",
       "      <td>7306</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United Kingdom</th>\n",
       "      <td>4490</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Sudan</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bonaire; Sint Eustatius; Saba</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>British Indian Ocean Territory</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tajikistan</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burundi</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                counts      %\n",
       "United States                    58049  38.41\n",
       "Unknown_Country                  21966  14.54\n",
       "China                            12038   7.97\n",
       "Japan                             7306   4.83\n",
       "United Kingdom                    4490   2.97\n",
       "...                                ...    ...\n",
       "South Sudan                          1   0.00\n",
       "Bonaire; Sint Eustatius; Saba        1   0.00\n",
       "British Indian Ocean Territory       1   0.00\n",
       "Tajikistan                           1   0.00\n",
       "Burundi                              1   0.00\n",
       "\n",
       "[182 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_unique_count(fraud_init, \"country_name\")\n",
    "### lot's of uknown countries --> will see if they have an effect on conversion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dataframe to work on from now on \n",
    "fraud = fraud_init.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>age</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>151112.000000</td>\n",
       "      <td>151112.000000</td>\n",
       "      <td>151112.000000</td>\n",
       "      <td>1.511120e+05</td>\n",
       "      <td>151112.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>200171.040970</td>\n",
       "      <td>36.935372</td>\n",
       "      <td>33.140704</td>\n",
       "      <td>2.152145e+09</td>\n",
       "      <td>0.093646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>115369.285024</td>\n",
       "      <td>18.322762</td>\n",
       "      <td>8.617733</td>\n",
       "      <td>1.248497e+09</td>\n",
       "      <td>0.291336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.209350e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100642.500000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.085934e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>199958.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.154770e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>300054.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>3.243258e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>400000.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>4.294850e+09</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id  purchase_value            age    ip_address  \\\n",
       "count  151112.000000   151112.000000  151112.000000  1.511120e+05   \n",
       "mean   200171.040970       36.935372      33.140704  2.152145e+09   \n",
       "std    115369.285024       18.322762       8.617733  1.248497e+09   \n",
       "min         2.000000        9.000000      18.000000  5.209350e+04   \n",
       "25%    100642.500000       22.000000      27.000000  1.085934e+09   \n",
       "50%    199958.000000       35.000000      33.000000  2.154770e+09   \n",
       "75%    300054.000000       49.000000      39.000000  3.243258e+09   \n",
       "max    400000.000000      154.000000      76.000000  4.294850e+09   \n",
       "\n",
       "               class  \n",
       "count  151112.000000  \n",
       "mean        0.093646  \n",
       "std         0.291336  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dropping duplicates\n",
    "fraud = fraud.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>age</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>151112.000000</td>\n",
       "      <td>151112.000000</td>\n",
       "      <td>151112.000000</td>\n",
       "      <td>1.511120e+05</td>\n",
       "      <td>151112.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>200171.040970</td>\n",
       "      <td>36.935372</td>\n",
       "      <td>33.140704</td>\n",
       "      <td>2.152145e+09</td>\n",
       "      <td>0.093646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>115369.285024</td>\n",
       "      <td>18.322762</td>\n",
       "      <td>8.617733</td>\n",
       "      <td>1.248497e+09</td>\n",
       "      <td>0.291336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.209350e+04</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100642.500000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.085934e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>199958.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.154770e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>300054.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>3.243258e+09</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>400000.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>4.294850e+09</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             user_id  purchase_value            age    ip_address  \\\n",
       "count  151112.000000   151112.000000  151112.000000  1.511120e+05   \n",
       "mean   200171.040970       36.935372      33.140704  2.152145e+09   \n",
       "std    115369.285024       18.322762       8.617733  1.248497e+09   \n",
       "min         2.000000        9.000000      18.000000  5.209350e+04   \n",
       "25%    100642.500000       22.000000      27.000000  1.085934e+09   \n",
       "50%    199958.000000       35.000000      33.000000  2.154770e+09   \n",
       "75%    300054.000000       49.000000      39.000000  3.243258e+09   \n",
       "max    400000.000000      154.000000      76.000000  4.294850e+09   \n",
       "\n",
       "               class  \n",
       "count  151112.000000  \n",
       "mean        0.093646  \n",
       "std         0.291336  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud.describe() ## we see there were no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>58049</td>\n",
       "      <td>38.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown_Country</th>\n",
       "      <td>21966</td>\n",
       "      <td>14.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>12038</td>\n",
       "      <td>7.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japan</th>\n",
       "      <td>7306</td>\n",
       "      <td>4.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United Kingdom</th>\n",
       "      <td>4490</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Sudan</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bonaire; Sint Eustatius; Saba</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>British Indian Ocean Territory</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tajikistan</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burundi</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                counts      %\n",
       "United States                    58049  38.41\n",
       "Unknown_Country                  21966  14.54\n",
       "China                            12038   7.97\n",
       "Japan                             7306   4.83\n",
       "United Kingdom                    4490   2.97\n",
       "...                                ...    ...\n",
       "South Sudan                          1   0.00\n",
       "Bonaire; Sint Eustatius; Saba        1   0.00\n",
       "British Indian Ocean Territory       1   0.00\n",
       "Tajikistan                           1   0.00\n",
       "Burundi                              1   0.00\n",
       "\n",
       "[182 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show unique count for country_name\n",
    "show_unique_count(fraud, \"country_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## putting countries with under 20 occurences into \"other\"\n",
    "count_country = fraud[\"country_name\"].value_counts(dropna=False)\n",
    "fraud[\"country_name\"] = np.where(fraud[\"country_name\"].\n",
    "                                 isin(count_country.index[count_country >=20]),\\\n",
    "                                 fraud[\"country_name\"], 'Other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Guatemala              20\n",
       "Iraq                   20\n",
       "Trinidad and Tobago    22\n",
       "Malta                  22\n",
       "Namibia                23\n",
       "Name: country_name, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking it worked well\n",
    "fraud[\"country_name\"].value_counts(ascending = True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f905fcef190>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEGCAYAAABYV4NmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWUElEQVR4nO3df6zd9X3f8ecrdkJIW4gBk1Lbqmmw2gHLlHLlsEaaongDb+sC6iDy1AxrteoV0R9Dq1pot9IlQwpqNidkBQmVxIZlActJB5vEUsuszX4Qk0t+1BjKuAop3ODgS+wy2jV0Zu/9cT5XOb5cX27s+znH2M+HdHS+5/39fj7n85UsXny+n+/53lQVkiQttTeNewCSpFOTASNJ6sKAkSR1YcBIkrowYCRJXSwf9wBOFuedd16tXbt23MOQpDeUxx577MWqWjnfPgOmWbt2LZOTk+MehiS9oST502Pt8xKZJKmLbgGT5FNJDiZ5fJ59v5qkkpw3VLs5yVSSp5JcOVS/LMm+tu/2JGn1M5Lc3+p7k6wdarM5ydPttbnXOUqSjq3nDGY7sHFuMcka4O8Azw7VLgY2AZe0NnckWdZ23wlsBda112yfW4DDVXURsA24rfV1DnAL8B5gPXBLkhVLfG6SpNfRLWCq6ovAoXl2bQN+DRh+Rs1VwH1V9UpVPQNMAeuTXACcVVWP1OCZNvcAVw+12dG2dwEb2uzmSmB3VR2qqsPAbuYJOklSXyNdg0nyAeBbVfX1ObtWAc8NfZ5utVVte279qDZVdQR4CTh3gb7mG8/WJJNJJmdmZo7rnCRJ8xtZwCR5G/CbwG/Nt3ueWi1QP942Rxer7qqqiaqaWLly3rvsJEnHaZQzmHcCFwJfT/JNYDXwlSQ/zGCWsWbo2NXA862+ep46w22SLAfOZnBJ7lh9SZJGaGQBU1X7qur8qlpbVWsZBMFPVtW3gQeBTe3OsAsZLOY/WlUHgJeTXN7WV64DHmhdPgjM3iF2DfBwW6f5AnBFkhVtcf+KVpMkjVC3H1om+SzwPuC8JNPALVV193zHVtX+JDuBJ4AjwA1V9WrbfT2DO9LOBB5qL4C7gXuTTDGYuWxqfR1K8hHgy+24D1fVfDcbSJI6in9wbGBiYqJO9Jf8K1bcuESj0ank8OFt4x6C1E2Sx6pqYr59/pJfktSFASNJ6sKAkSR1YcBIkrowYCRJXRgwkqQuDBhJUhcGjCSpCwNGktSFASNJ6sKAkSR1YcBIkrowYCRJXRgwkqQuDBhJUhcGjCSpCwNGktSFASNJ6sKAkSR1YcBIkrowYCRJXXQLmCSfSnIwyeNDtd9J8idJ/jjJ7yd5+9C+m5NMJXkqyZVD9cuS7Gv7bk+SVj8jyf2tvjfJ2qE2m5M83V6be52jJOnYes5gtgMb59R2A5dW1buA/wXcDJDkYmATcElrc0eSZa3NncBWYF17zfa5BThcVRcB24DbWl/nALcA7wHWA7ckWdHh/CRJC+gWMFX1ReDQnNofVNWR9vFLwOq2fRVwX1W9UlXPAFPA+iQXAGdV1SNVVcA9wNVDbXa07V3Ahja7uRLYXVWHquowg1CbG3SSpM7GuQbzc8BDbXsV8NzQvulWW9W259aPatNC6yXg3AX6eo0kW5NMJpmcmZk5oZORJB1tLAGT5DeBI8BnZkvzHFYL1I+3zdHFqruqaqKqJlauXLnwoCVJ35eRB0xbdP9p4GfbZS8YzDLWDB22Gni+1VfPUz+qTZLlwNkMLskdqy9J0giNNGCSbAR+HfhAVf2foV0PApvanWEXMljMf7SqDgAvJ7m8ra9cBzww1Gb2DrFrgIdbYH0BuCLJira4f0WrSZJGaHmvjpN8FngfcF6SaQZ3dt0MnAHsbncbf6mqfqGq9ifZCTzB4NLZDVX1auvqegZ3pJ3JYM1mdt3mbuDeJFMMZi6bAKrqUJKPAF9ux324qo662UCS1F++d5Xq9DYxMVGTk5Mn1MeKFTcu0Wh0Kjl8eNu4hyB1k+SxqpqYb5+/5JckdWHASJK6MGAkSV0YMJKkLgwYSVIXBowkqQsDRpLUhQEjSerCgJEkdWHASJK6MGAkSV0YMJKkLgwYSVIXBowkqQsDRpLUhQEjSerCgJEkdWHASJK6MGAkSV0YMJKkLgwYSVIX3QImyaeSHEzy+FDtnCS7kzzd3lcM7bs5yVSSp5JcOVS/LMm+tu/2JGn1M5Lc3+p7k6wdarO5fcfTSTb3OkdJ0rH1nMFsBzbOqd0E7KmqdcCe9pkkFwObgEtamzuSLGtt7gS2Auvaa7bPLcDhqroI2Abc1vo6B7gFeA+wHrhlOMgkSaPRLWCq6ovAoTnlq4AdbXsHcPVQ/b6qeqWqngGmgPVJLgDOqqpHqqqAe+a0me1rF7ChzW6uBHZX1aGqOgzs5rVBJ0nqbNRrMO+oqgMA7f38Vl8FPDd03HSrrWrbc+tHtamqI8BLwLkL9CVJGqGTZZE/89Rqgfrxtjn6S5OtSSaTTM7MzCxqoJKkxRl1wLzQLnvR3g+2+jSwZui41cDzrb56nvpRbZIsB85mcEnuWH29RlXdVVUTVTWxcuXKEzgtSdJcow6YB4HZu7o2Aw8M1Te1O8MuZLCY/2i7jPZyksvb+sp1c9rM9nUN8HBbp/kCcEWSFW1x/4pWkySN0PJeHSf5LPA+4Lwk0wzu7PoosDPJFuBZ4FqAqtqfZCfwBHAEuKGqXm1dXc/gjrQzgYfaC+Bu4N4kUwxmLptaX4eSfAT4cjvuw1U192YDSVJnGfxPvyYmJmpycvKE+lix4sYlGo1OJYcPbxv3EKRukjxWVRPz7TtZFvklSacYA0aS1IUBI0nqwoCRJHVhwEiSujBgJEldGDCSpC4MGElSFwaMJKkLA0aS1IUBI0nqwoCRJHVhwEiSujBgJEldGDCSpC4MGElSFwaMJKkLA0aS1IUBI0nqwoCRJHVhwEiSujBgJEldjCVgktyYZH+Sx5N8Nslbk5yTZHeSp9v7iqHjb04yleSpJFcO1S9Lsq/tuz1JWv2MJPe3+t4ka0d/lpJ0eht5wCRZBfwyMFFVlwLLgE3ATcCeqloH7GmfSXJx238JsBG4I8my1t2dwFZgXXttbPUtwOGqugjYBtw2glOTJA0Z1yWy5cCZSZYDbwOeB64CdrT9O4Cr2/ZVwH1V9UpVPQNMAeuTXACcVVWPVFUB98xpM9vXLmDD7OxGkjQaIw+YqvoW8DHgWeAA8FJV/QHwjqo60I45AJzfmqwCnhvqYrrVVrXtufWj2lTVEeAl4Ny5Y0myNclkksmZmZmlOUFJErDIgEmyZzG1Rfa1gsEM40LgR4AfSPKhhZrMU6sF6gu1ObpQdVdVTVTVxMqVKxceuCTp+7J8oZ1J3srgEtZ5LRhm/8N9FoNwOB5/G3imqmbad3we+CnghSQXVNWBdvnrYDt+Glgz1H41g0tq0217bn24zXS7DHc2cOg4xytJOg6vN4P5p8BjwE+099nXA8DvHud3PgtcnuRtbV1kA/Ak8CCwuR2zuX0Hrb6p3Rl2IYPF/EfbZbSXk1ze+rluTpvZvq4BHm7rNJKkEVlwBlNVnwA+keSXquqTS/GFVbU3yS7gK8AR4KvAXcAPAjuTbGEQQte24/cn2Qk80Y6/oapebd1dD2wHzgQeai+Au4F7k0wxmLlsWoqxS5IWL4v9H/skPwWsZSiUquqePsMavYmJiZqcnDyhPlasuHGJRqNTyeHD28Y9BKmbJI9V1cR8+xacwQx1cC/wTuBrwOzsYfbWYEmSXmNRAQNMABe7jiFJWqzF/g7mceCHew5EknRqWewM5jzgiSSPAq/MFqvqA11GJUl6w1tswPx2z0FIkk49iwqYqvqj3gORJJ1aFnsX2ct871ErbwHeDPxFVZ3Va2CSpDe2xc5gfmj4c5KrgfVdRiRJOiUc19OUq+o/Au9f4rFIkk4hi71E9jNDH9/E4Hcx/iZGknRMi72L7B8MbR8BvsngkfuSJM1rsWsw/6T3QCRJp5bF/sGx1Ul+P8nBJC8k+VyS1a/fUpJ0ulrsIv+nGfyNlR9h8OeI/1OrSZI0r8UGzMqq+nRVHWmv7YB/Y1iSdEyLDZgXk3woybL2+hDwnZ4DkyS9sS02YH4O+CDwbeAAgz9D7MK/JOmYFnub8keAzVV1GCDJOcDHGASPJEmvsdgZzLtmwwWgqg4B7+4zJEnSqWCxAfOmJCtmP7QZzGJnP5Kk09BiQ+LfAP8zyS4Gj4j5IHBrt1FJkt7wFjWDqap7gH8IvADMAD9TVfce75cmeXuSXUn+JMmTSf5mknOS7E7ydHsfnjHdnGQqyVNJrhyqX5ZkX9t3e5K0+hlJ7m/1vUnWHu9YJUnHZ9FPU66qJ6rq31XVJ6vqiRP83k8A/6WqfgL4G8CTwE3AnqpaB+xpn0lyMbAJuATYCNyRZFnr505gK7CuvTa2+hbgcFVdBGwDbjvB8UqSvk/H9bj+E5HkLOBvAXcDVNVfVdWfMXh45o522A7g6rZ9FXBfVb1SVc8AU8D6JBcAZ1XVI1VVwD1z2sz2tQvYMDu7kSSNxsgDBvgxBpfZPp3kq0l+L8kPAO+oqgMA7f38dvwq4Lmh9tOttqptz60f1aaqjgAvAefOHUiSrUkmk0zOzMws1flJkhhPwCwHfhK4s6reDfwF7XLYMcw386gF6gu1ObpQdVdVTVTVxMqVPvlGkpbSOAJmGpiuqr3t8y4GgfNCu+xFez84dPyaofargedbffU89aPaJFkOnA0cWvIzkSQd08gDpqq+DTyX5MdbaQPwBIOnNW9utc3AA237QWBTuzPsQgaL+Y+2y2gvJ7m8ra9cN6fNbF/XAA+3dRpJ0oiM68eSvwR8JslbgG8weK7Zm4CdSbYAzwLXAlTV/iQ7GYTQEeCGqnq19XM9sB04E3iovWBwA8G9SaYYzFw2jeKkJEnfM5aAqaqvARPz7NpwjONvZZ4fdlbVJHDpPPXv0gJKkjQe41iDkSSdBgwYSVIXBowkqQsDRpLUhQEjSerCgJEkdWHASJK6MGAkSV0YMJKkLgwYSVIXBowkqQsDRpLUhQEjSerCgJEkdWHASJK6MGAkSV0YMJKkLgwYSVIXBowkqQsDRpLUhQEjSepibAGTZFmSryb5z+3zOUl2J3m6va8YOvbmJFNJnkpy5VD9siT72r7bk6TVz0hyf6vvTbJ21OcnSae7cc5gfgV4cujzTcCeqloH7GmfSXIxsAm4BNgI3JFkWWtzJ7AVWNdeG1t9C3C4qi4CtgG39T0VSdJcYwmYJKuBvw/83lD5KmBH294BXD1Uv6+qXqmqZ4ApYH2SC4CzquqRqirgnjltZvvaBWyYnd1IkkZjXDOYjwO/Bvy/odo7quoAQHs/v9VXAc8NHTfdaqva9tz6UW2q6gjwEnDu3EEk2ZpkMsnkzMzMiZ6TJGnIyAMmyU8DB6vqscU2madWC9QXanN0oequqpqoqomVK1cucjiSpMVYPobvfC/wgSR/D3grcFaSfw+8kOSCqjrQLn8dbMdPA2uG2q8Gnm/11fPUh9tMJ1kOnA0c6nVCkqTXGvkMpqpurqrVVbWWweL9w1X1IeBBYHM7bDPwQNt+ENjU7gy7kMFi/qPtMtrLSS5v6yvXzWkz29c17TteM4ORJPUzjhnMsXwU2JlkC/AscC1AVe1PshN4AjgC3FBVr7Y21wPbgTOBh9oL4G7g3iRTDGYum0Z1EpKkgbEGTFX9IfCHbfs7wIZjHHcrcOs89Ung0nnq36UFlCRpPPwlvySpCwNGktSFASNJ6sKAkSR1YcBIkrowYCRJXRgwkqQuDBhJUhcGjCSpCwNGktSFASNJ6sKAkSR1YcBIkrowYCRJXRgwkqQuDBhJUhcGjCSpCwNGktSFASNJ6sKAkSR1YcBIkroYecAkWZPkvyZ5Msn+JL/S6uck2Z3k6fa+YqjNzUmmkjyV5Mqh+mVJ9rV9tydJq5+R5P5W35tk7ajPU5JOd+OYwRwB/nlV/TXgcuCGJBcDNwF7qmodsKd9pu3bBFwCbATuSLKs9XUnsBVY114bW30LcLiqLgK2AbeN4sQkSd8z8oCpqgNV9ZW2/TLwJLAKuArY0Q7bAVzdtq8C7quqV6rqGWAKWJ/kAuCsqnqkqgq4Z06b2b52ARtmZzeSpNEY6xpMu3T1bmAv8I6qOgCDEALOb4etAp4bajbdaqva9tz6UW2q6gjwEnBuj3OQJM1vbAGT5AeBzwH/rKr+90KHzlOrBeoLtZk7hq1JJpNMzszMvN6QJUnfh7EETJI3MwiXz1TV51v5hXbZi/Z+sNWngTVDzVcDz7f66nnqR7VJshw4Gzg0dxxVdVdVTVTVxMqVK5fi1CRJzTjuIgtwN/BkVf3boV0PApvb9mbggaH6pnZn2IUMFvMfbZfRXk5yeevzujltZvu6Bni4rdNIkkZk+Ri+873APwb2Jflaq/0G8FFgZ5ItwLPAtQBVtT/JTuAJBneg3VBVr7Z21wPbgTOBh9oLBgF2b5IpBjOXTb1PSpJ0tJEHTFX9d+ZfIwHYcIw2twK3zlOfBC6dp/5dWkBJksbDX/JLkrowYCRJXRgwkqQuxrHIL2kMVtx447iHoJPQ4W3buvXtDEaS1IUBI0nqwoCRJHVhwEiSujBgJEldGDCSpC4MGElSFwaMJKkLA0aS1IUBI0nqwoCRJHVhwEiSujBgJEldGDCSpC4MGElSFwaMJKkLA0aS1IUBI0nq4pQOmCQbkzyVZCrJTeMejySdTk7ZgEmyDPhd4O8CFwP/KMnF4x2VJJ0+TtmAAdYDU1X1jar6K+A+4Koxj0mSThvLxz2AjlYBzw19ngbeM3xAkq3A1vbxz5M8NaKxnQ7OA14c9yBOBsnHxz0EvZb/Ppt8/IT/ff7osXacygGTeWp11Iequ4C7RjOc00uSyaqaGPc4pPn473M0TuVLZNPAmqHPq4HnxzQWSTrtnMoB82VgXZILk7wF2AQ8OOYxSdJp45S9RFZVR5L8IvAFYBnwqaraP+ZhnU689KiTmf8+RyBV9fpHSZL0fTqVL5FJksbIgJEkdWHAaMn5iB6djJJ8KsnBJI+PeyynCwNGS8pH9Ogkth3YOO5BnE4MGC01H9Gjk1JVfRE4NO5xnE4MGC21+R7Rs2pMY5E0RgaMltrrPqJH0unBgNFS8xE9kgADRkvPR/RIAgwYLbGqOgLMPqLnSWCnj+jRySDJZ4FHgB9PMp1ky7jHdKrzUTGSpC6cwUiSujBgJEldGDCSpC4MGElSFwaMJKkLA0Y6SST57SS/Ou5xSEvFgJEkdWHASGOS5Lokf5zk60nunbPv55N8ue37XJK3tfq1SR5v9S+22iVJHk3ytdbfunGcjzSXP7SUxiDJJcDngfdW1YtJzgF+GfjzqvpYknOr6jvt2H8NvFBVn0yyD9hYVd9K8vaq+rMknwS+VFWfaY/nWVZVfzmuc5NmOYORxuP9wK6qehGgqub+nZJLk/y3Fig/C1zS6v8D2J7k54FlrfYI8BtJfh34UcNFJwsDRhqPsPCfMdgO/GJV/XXgXwFvBaiqXwD+BYMnVn+tzXT+A/AB4C+BLyR5f8+BS4tlwEjjsQf4YJJzAdolsmE/BBxI8mYGMxjace+sqr1V9VvAi8CaJD8GfKOqbmfw5Op3jeQMpNexfNwDkE5HVbU/ya3AHyV5Ffgq8M2hQ/4lsBf4U2Afg8AB+J22iB8GIfV14CbgQ0n+L/Bt4MMjOQnpdbjIL0nqwktkkqQuDBhJUhcGjCSpCwNGktSFASNJ6sKAkSR1YcBIkrr4/+BHgNnVlM+bAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# checking the class category \n",
    "palette = ['navy', 'teal', 'lightskyblue', \"lightblue\"]\n",
    "\n",
    "sns.countplot(fraud[\"class\"], order = fraud[\"class\"].value_counts().index, palette =palette )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### safe to assume that 0 correspoonds to no_fraud and 1 to fraud\n",
    "#### let's plot percentage of fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136961</td>\n",
       "      <td>90.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14151</td>\n",
       "      <td>9.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   counts      %\n",
       "0  136961  90.64\n",
       "1   14151   9.36"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_unique_count(fraud, \"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>class</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Algeria</th>\n",
       "      <td>89.3</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angola</th>\n",
       "      <td>95.8</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Argentina</th>\n",
       "      <td>90.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Australia</th>\n",
       "      <td>91.1</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Austria</th>\n",
       "      <td>92.4</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Azerbaijan</th>\n",
       "      <td>91.3</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bangladesh</th>\n",
       "      <td>91.9</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belarus</th>\n",
       "      <td>97.2</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Belgium</th>\n",
       "      <td>86.3</td>\n",
       "      <td>13.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bolivia</th>\n",
       "      <td>75.5</td>\n",
       "      <td>24.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bosnia and Herzegowina</th>\n",
       "      <td>96.7</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brazil</th>\n",
       "      <td>90.9</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bulgaria</th>\n",
       "      <td>98.8</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canada</th>\n",
       "      <td>88.3</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chile</th>\n",
       "      <td>84.7</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>91.3</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colombia</th>\n",
       "      <td>94.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Costa Rica</th>\n",
       "      <td>86.7</td>\n",
       "      <td>13.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Croatia (LOCAL Name: Hrvatska)</th>\n",
       "      <td>91.1</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cyprus</th>\n",
       "      <td>95.3</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Czech Republic</th>\n",
       "      <td>90.3</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Denmark</th>\n",
       "      <td>84.1</td>\n",
       "      <td>15.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dominican Republic</th>\n",
       "      <td>96.1</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ecuador</th>\n",
       "      <td>73.6</td>\n",
       "      <td>26.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Egypt</th>\n",
       "      <td>86.6</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>El Salvador</th>\n",
       "      <td>92.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estonia</th>\n",
       "      <td>97.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>European Union</th>\n",
       "      <td>94.1</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Finland</th>\n",
       "      <td>90.4</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>90.5</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Georgia</th>\n",
       "      <td>93.8</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Germany</th>\n",
       "      <td>92.8</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greece</th>\n",
       "      <td>85.7</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guatemala</th>\n",
       "      <td>95.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hong Kong</th>\n",
       "      <td>87.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hungary</th>\n",
       "      <td>91.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>88.5</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indonesia</th>\n",
       "      <td>91.2</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iran (ISLAMIC Republic Of)</th>\n",
       "      <td>89.2</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iraq</th>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ireland</th>\n",
       "      <td>77.1</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Israel</th>\n",
       "      <td>95.6</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italy</th>\n",
       "      <td>91.5</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japan</th>\n",
       "      <td>90.2</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jordan</th>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kazakhstan</th>\n",
       "      <td>93.5</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kenya</th>\n",
       "      <td>92.5</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Korea Republic of</th>\n",
       "      <td>90.9</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kuwait</th>\n",
       "      <td>76.7</td>\n",
       "      <td>23.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Latvia</th>\n",
       "      <td>90.6</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lebanon</th>\n",
       "      <td>89.3</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lithuania</th>\n",
       "      <td>81.1</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Luxembourg</th>\n",
       "      <td>61.1</td>\n",
       "      <td>38.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Macedonia</th>\n",
       "      <td>95.8</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malaysia</th>\n",
       "      <td>94.8</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Malta</th>\n",
       "      <td>81.8</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mexico</th>\n",
       "      <td>87.2</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Moldova Republic of</th>\n",
       "      <td>94.6</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Morocco</th>\n",
       "      <td>96.8</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Namibia</th>\n",
       "      <td>56.5</td>\n",
       "      <td>43.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Netherlands</th>\n",
       "      <td>92.7</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New Zealand</th>\n",
       "      <td>77.7</td>\n",
       "      <td>22.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nigeria</th>\n",
       "      <td>95.5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Norway</th>\n",
       "      <td>87.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oman</th>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>96.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pakistan</th>\n",
       "      <td>95.7</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Panama</th>\n",
       "      <td>95.2</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paraguay</th>\n",
       "      <td>91.4</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peru</th>\n",
       "      <td>73.9</td>\n",
       "      <td>26.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Philippines</th>\n",
       "      <td>94.4</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poland</th>\n",
       "      <td>94.7</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Portugal</th>\n",
       "      <td>95.6</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Puerto Rico</th>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Qatar</th>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romania</th>\n",
       "      <td>94.9</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russian Federation</th>\n",
       "      <td>91.7</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Saudi Arabia</th>\n",
       "      <td>81.1</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Serbia</th>\n",
       "      <td>98.6</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Seychelles</th>\n",
       "      <td>87.4</td>\n",
       "      <td>12.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Singapore</th>\n",
       "      <td>93.3</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slovakia (SLOVAK Republic)</th>\n",
       "      <td>95.3</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slovenia</th>\n",
       "      <td>97.7</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South Africa</th>\n",
       "      <td>91.2</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spain</th>\n",
       "      <td>92.9</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sri Lanka</th>\n",
       "      <td>58.1</td>\n",
       "      <td>41.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sudan</th>\n",
       "      <td>92.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sweden</th>\n",
       "      <td>88.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Switzerland</th>\n",
       "      <td>91.2</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Syrian Arab Republic</th>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taiwan; Republic of China (ROC)</th>\n",
       "      <td>92.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thailand</th>\n",
       "      <td>93.5</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trinidad and Tobago</th>\n",
       "      <td>90.9</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tunisia</th>\n",
       "      <td>73.7</td>\n",
       "      <td>26.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Turkey</th>\n",
       "      <td>92.6</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ukraine</th>\n",
       "      <td>88.3</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United Arab Emirates</th>\n",
       "      <td>86.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United Kingdom</th>\n",
       "      <td>89.4</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <td>90.4</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unknown_Country</th>\n",
       "      <td>91.4</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Uruguay</th>\n",
       "      <td>93.8</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Venezuela</th>\n",
       "      <td>86.9</td>\n",
       "      <td>13.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Viet Nam</th>\n",
       "      <td>93.3</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "class                                0     1\n",
       "country_name                                \n",
       "Algeria                           89.3  10.7\n",
       "Angola                            95.8   4.2\n",
       "Argentina                         90.0  10.0\n",
       "Australia                         91.1   8.9\n",
       "Austria                           92.4   7.6\n",
       "Azerbaijan                        91.3   8.7\n",
       "Bangladesh                        91.9   8.1\n",
       "Belarus                           97.2   2.8\n",
       "Belgium                           86.3  13.7\n",
       "Bolivia                           75.5  24.5\n",
       "Bosnia and Herzegowina            96.7   3.3\n",
       "Brazil                            90.9   9.1\n",
       "Bulgaria                          98.8   1.2\n",
       "Canada                            88.3  11.7\n",
       "Chile                             84.7  15.3\n",
       "China                             91.3   8.7\n",
       "Colombia                          94.0   6.0\n",
       "Costa Rica                        86.7  13.3\n",
       "Croatia (LOCAL Name: Hrvatska)    91.1   8.9\n",
       "Cyprus                            95.3   4.7\n",
       "Czech Republic                    90.3   9.7\n",
       "Denmark                           84.1  15.9\n",
       "Dominican Republic                96.1   3.9\n",
       "Ecuador                           73.6  26.4\n",
       "Egypt                             86.6  13.4\n",
       "El Salvador                       92.0   8.0\n",
       "Estonia                           97.6   2.4\n",
       "European Union                    94.1   5.9\n",
       "Finland                           90.4   9.6\n",
       "France                            90.5   9.5\n",
       "Georgia                           93.8   6.2\n",
       "Germany                           92.8   7.2\n",
       "Greece                            85.7  14.3\n",
       "Guatemala                         95.0   5.0\n",
       "Hong Kong                         87.0  13.0\n",
       "Hungary                           91.0   9.0\n",
       "India                             88.5  11.5\n",
       "Indonesia                         91.2   8.8\n",
       "Iran (ISLAMIC Republic Of)        89.2  10.8\n",
       "Iraq                             100.0   NaN\n",
       "Ireland                           77.1  22.9\n",
       "Israel                            95.6   4.4\n",
       "Italy                             91.5   8.5\n",
       "Japan                             90.2   9.8\n",
       "Jordan                           100.0   NaN\n",
       "Kazakhstan                        93.5   6.5\n",
       "Kenya                             92.5   7.5\n",
       "Korea Republic of                 90.9   9.1\n",
       "Kuwait                            76.7  23.3\n",
       "Latvia                            90.6   9.4\n",
       "Lebanon                           89.3  10.7\n",
       "Lithuania                         81.1  18.9\n",
       "Luxembourg                        61.1  38.9\n",
       "Macedonia                         95.8   4.2\n",
       "Malaysia                          94.8   5.2\n",
       "Malta                             81.8  18.2\n",
       "Mexico                            87.2  12.8\n",
       "Moldova Republic of               94.6   5.4\n",
       "Morocco                           96.8   3.2\n",
       "Namibia                           56.5  43.5\n",
       "Netherlands                       92.7   7.3\n",
       "New Zealand                       77.7  22.3\n",
       "Nigeria                           95.5   4.5\n",
       "Norway                            87.0  13.0\n",
       "Oman                             100.0   NaN\n",
       "Other                             96.5   3.5\n",
       "Pakistan                          95.7   4.3\n",
       "Panama                            95.2   4.8\n",
       "Paraguay                          91.4   8.6\n",
       "Peru                              73.9  26.1\n",
       "Philippines                       94.4   5.6\n",
       "Poland                            94.7   5.3\n",
       "Portugal                          95.6   4.4\n",
       "Puerto Rico                      100.0   NaN\n",
       "Qatar                            100.0   NaN\n",
       "Romania                           94.9   5.1\n",
       "Russian Federation                91.7   8.3\n",
       "Saudi Arabia                      81.1  18.9\n",
       "Serbia                            98.6   1.4\n",
       "Seychelles                        87.4  12.6\n",
       "Singapore                         93.3   6.7\n",
       "Slovakia (SLOVAK Republic)        95.3   4.7\n",
       "Slovenia                          97.7   2.3\n",
       "South Africa                      91.2   8.8\n",
       "Spain                             92.9   7.1\n",
       "Sri Lanka                         58.1  41.9\n",
       "Sudan                             92.0   8.0\n",
       "Sweden                            88.0  12.0\n",
       "Switzerland                       91.2   8.8\n",
       "Syrian Arab Republic             100.0   NaN\n",
       "Taiwan; Republic of China (ROC)   92.0   8.0\n",
       "Thailand                          93.5   6.5\n",
       "Trinidad and Tobago               90.9   9.1\n",
       "Tunisia                           73.7  26.3\n",
       "Turkey                            92.6   7.4\n",
       "Ukraine                           88.3  11.7\n",
       "United Arab Emirates              86.0  14.0\n",
       "United Kingdom                    89.4  10.6\n",
       "United States                     90.4   9.6\n",
       "Unknown_Country                   91.4   8.6\n",
       "Uruguay                           93.8   6.2\n",
       "Venezuela                         86.9  13.1\n",
       "Viet Nam                          93.3   6.7"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check distribution of fraud in \"uknown countries\"\n",
    "pd.options.display.max_rows = 999\n",
    "(fraud.groupby([\"country_name\"])[\"class\"].\\\n",
    "value_counts(normalize=True)*100).round(1).unstack([\"class\"]) #let's prepare a df to plot what we need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unknown countries have a about 8.6% of fraud, which does not diverge too much from the mean avg, for the purpose of this exercise we can drop the column later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NGQCKIADMZORL</th>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZUSVMDEZRBDTX</th>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CQTUVBYIWWWBC</th>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KIPFSCNUGOLDP</th>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ITUMJCKWEYNDD</th>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLMAILITCBCOY</th>\n",
       "      <td>15</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GZMOUDIAZTTUO</th>\n",
       "      <td>15</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TZZDLDMKAXGXV</th>\n",
       "      <td>15</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VLNELJEFKHYNR</th>\n",
       "      <td>15</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BALITCTPUJLHB</th>\n",
       "      <td>15</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               counts     %\n",
       "NGQCKIADMZORL      20  0.01\n",
       "ZUSVMDEZRBDTX      20  0.01\n",
       "CQTUVBYIWWWBC      20  0.01\n",
       "KIPFSCNUGOLDP      20  0.01\n",
       "ITUMJCKWEYNDD      20  0.01\n",
       "...               ...   ...\n",
       "MLMAILITCBCOY      15  0.01\n",
       "GZMOUDIAZTTUO      15  0.01\n",
       "TZZDLDMKAXGXV      15  0.01\n",
       "VLNELJEFKHYNR      15  0.01\n",
       "BALITCTPUJLHB      15  0.01\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## let's look at device ID, some seem to appear more than once\n",
    "id_count = show_unique_count(fraud, \"device_id\").head(100)\n",
    "id_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create a row called device_id_count\n",
    "fraud['device_id_count'] = fraud.groupby('device_id')['device_id'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>signup_time</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>device_id</th>\n",
       "      <th>source</th>\n",
       "      <th>browser</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>class</th>\n",
       "      <th>country_name</th>\n",
       "      <th>device_id_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22058</td>\n",
       "      <td>2015-02-24 22:55:49</td>\n",
       "      <td>2015-04-18 02:47:11</td>\n",
       "      <td>34</td>\n",
       "      <td>QVPSPJUOCKZAR</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>7.327584e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>Japan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>333320</td>\n",
       "      <td>2015-06-07 20:39:50</td>\n",
       "      <td>2015-06-08 01:38:54</td>\n",
       "      <td>16</td>\n",
       "      <td>EOGFQPIZPYXFZ</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>3.503114e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1359</td>\n",
       "      <td>2015-01-01 18:52:44</td>\n",
       "      <td>2015-01-01 18:52:45</td>\n",
       "      <td>15</td>\n",
       "      <td>YSSKYOSJHPPLJ</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Opera</td>\n",
       "      <td>M</td>\n",
       "      <td>53</td>\n",
       "      <td>2.621474e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150084</td>\n",
       "      <td>2015-04-28 21:13:25</td>\n",
       "      <td>2015-05-04 13:54:50</td>\n",
       "      <td>44</td>\n",
       "      <td>ATGTXKYKUDUQN</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>41</td>\n",
       "      <td>3.840542e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown_Country</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221365</td>\n",
       "      <td>2015-07-21 07:09:52</td>\n",
       "      <td>2015-09-09 18:40:53</td>\n",
       "      <td>39</td>\n",
       "      <td>NAUITBZFJKHWW</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>4.155831e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id          signup_time        purchase_time  purchase_value  \\\n",
       "0    22058  2015-02-24 22:55:49  2015-04-18 02:47:11              34   \n",
       "1   333320  2015-06-07 20:39:50  2015-06-08 01:38:54              16   \n",
       "2     1359  2015-01-01 18:52:44  2015-01-01 18:52:45              15   \n",
       "3   150084  2015-04-28 21:13:25  2015-05-04 13:54:50              44   \n",
       "4   221365  2015-07-21 07:09:52  2015-09-09 18:40:53              39   \n",
       "\n",
       "       device_id source browser sex  age    ip_address  class  \\\n",
       "0  QVPSPJUOCKZAR    SEO  Chrome   M   39  7.327584e+08      0   \n",
       "1  EOGFQPIZPYXFZ    Ads  Chrome   F   53  3.503114e+08      0   \n",
       "2  YSSKYOSJHPPLJ    SEO   Opera   M   53  2.621474e+09      1   \n",
       "3  ATGTXKYKUDUQN    SEO  Safari   M   41  3.840542e+09      0   \n",
       "4  NAUITBZFJKHWW    Ads  Safari   M   45  4.155831e+08      0   \n",
       "\n",
       "      country_name  device_id_count  \n",
       "0            Japan                1  \n",
       "1    United States                1  \n",
       "2    United States               12  \n",
       "3  Unknown_Country                1  \n",
       "4    United States                1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking\n",
    "fraud.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/seaborn/distributions.py:369: UserWarning: Default bandwidth for data is 0; skipping density estimation.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## let's see if there is a diff of distribution in age according class\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(10, 4))  # 2 row, 2 columns\n",
    "\n",
    "ax1.set_title('Device ID count distribution no fraud')\n",
    "ax2.set_title('Device ID count distribution fraud')\n",
    "\n",
    "sns.distplot(fraud[fraud[\"class\"] ==0]['device_id_count'], color = \"blue\", bins=15, ax=ax1)\n",
    "sns.distplot(fraud[fraud[\"class\"] ==1]['device_id_count'], color = \"red\", bins=15, ax=ax2)\n",
    "      \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we treat signup_time and purchase_time? \n",
    "- signup time --> let's keep time only, under the assumption that some sign up times might be more suspicious than others. We can transform it to a timestamp to use it in the model\n",
    "- purchase time --> let's replace it by the time difference between sign up and purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fraud[\"signup_time\"] = pd.to_datetime(fraud['signup_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fraud[\"purchase_time\"] = pd.to_datetime(fraud['purchase_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fraud[\"time_delta\"] = (fraud['purchase_time'] - fraud['signup_time']).dt.seconds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# creating a signup column with integers to process it\n",
    "fraud['signup_time_abs'] = fraud['signup_time'].dt.hour.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAEYCAYAAABftDB3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZxU1Zn/8c/TzSbS0CDN2iigaAQXUEJco5nEKCYGszhxmUgcDXFGZ8kyiWb5JfklzjiT9ee4IEmMxiyELBPREEniMmoMKiqyKdoRWQShQfa96ef3x7llF0V1V3VTVbfq1vf9et3Xrbrrc6u7Tz917rnnmLsjIiIiIlLtauIOQERERESkHCgxFhERERFBibGIiIiICKDEWEREREQEUGIsIiIiIgIoMRYRERERAZQYl5SZLTGzc+OOIx9m9pqZvaeE5zvSzLabWW2BjjfdzL4cvT7XzFYX4rjR8c42s2WFOl4Slfr3RyQOKtM7PJ/K9BipDO46JcYFFBUCqanVzHalvb/C3ce5+6MliOOrZrbPzLZF08tmdquZDT2E4/3kEOL5uJntT/sslpvZj8zs2NQ27r7S3fu4+/48jvVErnO6+7Xu/vWuxpxxTjezY9KO/bi7H1eIY2ecZ2R0rt9lLP+JmX31EI6X/nv5QsECFkk4lent7q8yPb/zqAyuQEqMCygqBPq4ex9gJXBR2rKfljicX7h7HTAA+CAwBHi2qwVpAfwl+lz6Ae8BdkXxnFDoExWqhiJGp5nZmQU8Xn3a7+HJmSvNrFsBzyWSGCrTO6QyPX8qgyuIEuMSSr+1EX1j/2VUG7jNzBaZ2bFmdqOZrTezVWb23rR9+5nZD81srZm9bmbfyKewcPd97r4E+CjQDHwm7ZjvN7MFZrbZzJ40s5OyxHwB8AXgo+nfds3sKjN7MYr9VTP7ZD6fgbvvd/e/uvs/Av8LfDU6Xuqbdbfo/cej426LaiOuMLPjgenA6VEsm6Nt7zazO8xsjpntAN4VLftGxrV8wcw2RD+HK9KWP2pm16S9f6sGw8weixa/EJ3zo5ZxG8/Mjo+OsdnCrdUPpK2728xuM7PfRdfylJkdneNj+i/gG+2tNLNPmFmTmb1pZrPNbFiO42Xuf66ZrTazz5vZG8CPzKy/mT1gZs1mtil63Zi2zwG35TJrnMzsY2a2wsw2mtkXOxOPSKVSma4yPc8y/QAqg8ubEuN4XQTcC/QHngfmEn4mw4H/C9yZtu09QAtwDDABeC9wDXmKbmfdB5wNYGanAHcBnwSOiM4128x6Zuz3IPDvhNqK9G+764H3A32Bq4DvRsfsjN+k4klnZocDtwCToxqSM4AF7v4icC1RTYW716ftdjlwE1AHZLstNwQYSPhspwIzzCznrTN3f2f08uTonL/IiLU7cD/wB2AQ8E/ATzOOfRnwNcLPuSmKsyO3AcdalvZhZvY3wH8AfwsMBVYAM3NdRxZDCDVPRwHTCL93P4reH0mo/bk1nwOZ2VjgDuBjwDDC71NjhzuJJJPKdJXp+VIZXKZiTYzN7K7om/TiAh1vf/RteYGZzS7EMYvscXef6+4twC+BBuBmd99HSHZGmlm9mQ0GJgP/6u473H098F3g0k6ebw3hDxHgE8Cd7v5U9I3/HmAPcFo+B3L330W1BO7u/0soRA4qEDsRT6ZW4AQzO8zd10Y1JB25z93/7O6t7r67nW2+7O57onh/R0guD9VpQB/Cz22vuz8MPEAoOFN+4+5PRz/nnwLjcxxzN6GgzVZrfAVwl7s/5+57gBsJtS0jOzjehqjmY7OZfTZa1gp8Jfo8drn7Rnf/tbvvdPdt0fnPyRFnykeAB9z9sSimL0fHF6k2KtNVpmejMriCxF1jfDdwQQGPt8vdx0fTB3JvHrt1aa93ARu87UGFXdG8D+EbZHdgbeqPi1AbMKiT5xsOvBm9Pgr4TNof62ZgBOHbZk5mNtnM5lm4nb8ZuJDw7b2r8bzF3XcQbhNeS7jm35nZ23Ica1WO9Zui46asIM9rzWEYsMrd0wuhFYRrS3kj7fVOws80l+8Dg83soiznW5F64+7bgY0Z58s00N3ro+lb0bLm9H82ZtbbzO6MbsVtBR4D6i2/tn3DSPv8o895Yx77iSSNynSV6dmoDK4gsSbG7v4YGX9EZna0mT1oZs+a2eN5/PFUg1WEb/7pf1x93X1cvgcwsxrCbb7H0455U9rx6t29t7v/PMvunnGsnsCvgW8Bg6PbX3MA6+R1fTAtngNPGGpdziM0F3iJkCgeFEt7MWbRP7qdl3IkoXYDYAfQO23dkBzHSrcGGBF9vunHfr0TxzhIVMP0NeDrHPi5riH8AwTeukV5RBfOl/l5fQY4DniHu/cFUrcbU+fu6DNaS/gHnIqpdxSTiGSnMr3KyvQsVAaXqbhrjLOZAfyTu58KfBa4vRP79jKz+dG33ouLE17puftawm2tb5tZXzOrib5A5LzNYmbdLTzg8HPCH9J3olXfB641s3dYcLiZvc/M6rIcZh3hFmDq96UH0JPw4EeLmU0mtI/LycxqzWyUmf03cC4h+cvcZrCZfSAq9PYA24FUrcs6oNHMeuRzvgxfM7MeZnY2oS3dL6PlC4APRd/YjwGuzthvHTC6nWM+RSiwPhd91ucS/ll1pd1vpnsJn3P6XZWfAVeZ2fjon9m/A0+5+2uHeK46Qo3WZjMbAHwlY/0C4NLoGicSbt2l/Ap4v5mdFf1c/i/lWbaIlAWV6VVbpndEZXCZKKsPzsz6EBrl/9LMFhBuLQ2N1n3IzBZnmeamHeJId59IaLT/Pevkk6Jl7kpC4bUU2ET4Q+iom56Pmtl2YDMwm3Bb5VR3XwPg7vMJbdJujY7XBHy8nWOlCpuNZvZc1P7pn4FZ0b6XR+foyOlRPFuBRwkPeLzd3Rdl2baG8O15DeGOwjnAP0brHgaWAG+Y2YYc50z3RhTrGkKbsGvd/aVo3XeBvYTC8p5ofbqvAvdEtycPaMPm7nuBDxDaC24gfJG7Mu3YXRbdgv0KaW323P0hQvuxXxNqCY6m8+0Ss/kecBjhGuYBD2as/3J0rk2Ef3w/S4tpCXBdtGxttE3BOt8XSSiV6UHVlOk5qAwuE+ae625FkQMIDw094O4nmFlfYJm7H3K/jGZ2d3TcXx3qsUREREQk+cqqxtjdtwLLzewSgOh20EGdYWdjoQ/AntHrgcCZhG/iIiIiIiI5xd1d28+BvwDHWejs+mpCd1RXW+h0fAkwJc/DHQ/Mj/Z7hNDVihJjEREREclL7E0pRERERETKQVk1pRARERERiUu3uE48cOBAHzlyZFynFxHpsmeffXaDuzfEHUcpqKwWkUrU1XI6tsR45MiRzJ8/P67Ti4h0mZmtyL1VMqisFpFK1NVyWk0pRERERETIIzE2s7vMbL2ZLW5n/RVmtjCansy3ezURERERkXKST43x3Rw4JG2m5cA57n4S8HXCkM4iIiIiIhUlZ2Ls7o8RhnBsb/2T7r4pejsPaCxQbCIiiWBmF5jZMjNrMrMbsqw3M7slWr/QzE7Jta+ZDTCzP5rZK9G8f7T8CDN7xMy2m9mtGec51cwWRce6xcysmNctIlJpCt3G+Grg9+2tNLNpZjbfzOY3NzcX+NQiIuXHzGqB24DJwFjgMjMbm7HZZGBMNE0D7shj3xuAh9x9DPBQ9B5gN/Bl4LNZwrkjOn7qXB3dDRQRqToFS4zN7F2ExPjz7W3j7jPcfaK7T2xoqIqejkREJgFN7v6qu+8FZnLwiJ5TgB97MA+oN7OhOfadAtwTvb4HuBjA3Xe4+xOEBPkt0fH6uvtfPIzs9OPUPiIiEhQkMTazk4AfAFPcfWMhjikikhDDgVVp71dHy/LZpqN9B7v7WoBoPiiPOFbniAPQ3T0RqV6HnBib2ZHAb4CPufvLhx6SiEiiZGvH63luk8++hYwjLNTdPRGpUjkH+DCznwPnAgPNbDXwFaA7gLtPB/4PcARwe/QcR4u7TyxWwCL52LABHn0UnnwSFi6ElSth/XpobYWaGhg0CIYNg+OPh/HjYdIkOOkkqK2NO3JJoNXAiLT3jcCaPLfp0cG+68xsqLuvjZpJrM8jjvSHo7PFISJS1XImxu5+WY711wDXFCwikS7atg3uuw9+9jP4wx9g/37o1SskvOPHw5Ah0K0btLSEJHn1avj5z2H69LB/XR2ccQacfTacdVZIlg87LN5rcodNm2DVKli3DrZubZt27Ajx9ekDI0bAMcfA6NFK7svQM8AYMxsFvA5cClyesc1s4Hozmwm8A9gSJbzNHew7G5gK3BzN7+soiOh428zsNOAp4ErgvwtxgWVnxiH0GjptWuHiEJGKE9uQ0OXiUMpPgMsvh4cfhj/9CVasgB49oG9fGDcOTjwxTIMHQ76dIu3bFxK2FSvCtHIl7NoV1vXqBUccAQMGhPkRR4Saz4aGsK49LS3wxhvw+uthWru2bVq3DnbvDjWpqam2NiRbqamuLlzDkCFt0+jRYXlcUj+3lhZYsgSefhpeeCF8fgMGwHnnhWR4xIiQDGdK/e9zh+XLYd48ePxxeOIJ+NKXwrru3WHixJAon3lmSDxHjCjsdbe2hp/Ba68dPK1cGRLiHTvyP16fPnDaaXDOOTB5MkyYEGrIJT7u3mJm1wNzgVrgLndfYmbXRuunA3OAC4EmYCdwVUf7Roe+GZhlZlcDK4FLUuc0s9eAvkAPM7sYeK+7LwX+gdA3/WGEHoTa7UVIRKQaWXg4ufQmTpzo8+fPj+Xc6Q4lMW5qgnvvDUnnYYfBmDEhUdu4MSQ7KQMHtiXJjY1QXx8S5W3bQs3mm2+Gfd58EzZvDslaulQN4P797cfSq1dIyHv2DImgO+zdCzt3wpYtBx/TLGzft29I5s1CAmUWzrNnT9u0e3eYZ2pshLFjw3T88eHLwLhx4fqKacOGkLy+8EJoJrFzJxx+eEhiJ00KSfuhJIM7dsBf/wqvvBLmr7124GdfXx8S5IaGts+wrq5t3qdP+BnU1LRN27eHmt9Nm0ISv2VL28+8peXA89fVtX356d8/vO7fH/r1C79nvXqFqUePsO+uXeE469aFL1N//Wv4cpU6VurnMnZsiE0VYofOzJ6tliZj5VJWd4pqjEWqXlfL6aqvMe6qRx+FX/wCjj46JMdnnx2S0pQNG2DRojAtXBjmP/zhwbV/NTUh6TniCDjuuINrhPv3DzWXEJKzHTvapu3bQ3KdPu3dG2pNa2pCcta7dzhGfX3b1K9fSJg6kzzu3h2Ov3VrSN7Xrw9J1osvhv9BO3e2bTt8eEiUGxth6NBwrl69QtLd0hKuY//+ttfZlqU+m1TCvnUrrFkDL70Er74a1vfuHZpJTJwYkr5CNSE4/PBw3JNOCu/37g01t6lENpXgrlgRPpfUtGtXqAHuSK9e4fh1dSG5Hj++7WedmtJ/j3Lp3j0kywMGhBrtM88My7duhaVLQ236okWhRtwMjjoKFi8O5z3qqFD7P3hw2F81yyIiUu2UGHdBU1Nom3riiXD11SFRSyVrmXr1CrWYkyYdWIsLIQHq1Sv/hKS2tq2GstRStZTpD6inKlZaW0OSuGRJ2/TSSyFpfuONjmu64cCa1dQE4fNKTT17hqR+4ED40IdCrXCp2tP26BG+AB19dMfbuYfEfs+e8Jm4t8179AgJbKna//btG5pUnHZa289n8eLwM7nrroO/oHXrFj7bVHI+YEB4n958ZujQtte9e4f9WlraviitWNHWDGT16nCOfftCwn7OOfCe98TzuysiIpIvJcad1NoKM2eGWthPfKJztXtmYfvO7FPOst2t7N8/PLh21lnhfSpZ3Lu3rfY3fTLLv/11uTMLNbipGv5yUVMDo0aF6aKLwu/whg2h1nvr1nAnYMuWcAdix47wZaapqe2ORLbWVqmfW7Ya8u7dw92CurrwReCRR+CWW+DII+GKK2DkyK5fi+5yi4hIMSkx7qTHHw+31adNS06CW0zlmixWs1R3dYNyDQdBSHy3bw+J85YtIZHesiV80XFva67Tp09bTXO/fgfeBWlpCe21770XvvnNkByfcUbxrk9ERKSrlBh3ws6d8NvfhrbAp5wSdzQixVdT09Z8Z8SI3Ntn061baHP+hS/A978fEuTRo0OTDBERkXKix2064fnnQ3L8wQ8m5/a/SKn06RPa5PfsGR5cjalDHBERkXYpMe6E558Pt4sPpY2kSDXr2ze0c166NPTWIiIiUk6UGOdp167wRP/48aotFjkU554beriYNSt3jyUiIiKlpMQ4T4sWhYeI1LZY5NDU1oZa4w0bQu8XIiIi5UKJcZ6eey48bT96dNyRiFS+E04IPZU891zckYiIiLRRYpyHPXvaRgvT6GAih65nzzBM9YIFuUcLFBERKRWleXl46aUwgteECXFHIpIcEyaEUfNWrIg7EhERkUCJcR6WLw81xcccE3ckIslx0kmhvbGaU4iISLlQYpyHFStg2DCN3iZSSL17w9veFrpBVJ/GIiJSDpQY5+AeEuOjjoo7EpHkmTABmpth7dq4IxEREVFinNObb8KOHXDkkXFHIpI8xx4b5suXxxuHiIgIKDHOKfVgkGqMRQqvoQF69dIDeCIiUh6UGOewcmV48K6xMe5IRJKnpibcjVm5Mu5IRERElBjnpAfvRIrryCNh9WoNDy0iIvFTYtwB91CTpWYUIsVz1FGhn3A9gCciInFTYtyBTZtg+3Y9eCdSTKm/L7UzFhGRuCkx7oAevBMpvkGDwgN4amcsIiJxU2LcgVWrwAyGD487EpHkqqmBESNUYywiIvFTYtyB9evhiCOgR4+4IxFJNj2AJyIi5UCJcQeam0M/qyJSXKkH8N54I+5IRESkmuVMjM3sLjNbb2aL21lvZnaLmTWZ2UIzO6XwYcZDibFIaaTa8audsYiIxCmfGuO7gQs6WD8ZGBNN04A7Dj2s+O3cGYaCVmIsUnwNDaGt8fr1cUciIiLVLGdi7O6PAW92sMkU4McezAPqzWxooQKMS3NzmCsxFim+2loYMKDt705ERCQOhWhjPBxYlfZ+dbTsIGY2zczmm9n85jL/D6jEWKS0GhqUGIuISLwKkRhblmWebUN3n+HuE919YkOZZ5ypf9ADB8Ybh0i1UGIsIiJxK0RivBoYkfa+EVhTgOPGqrkZ+vYNAw+ISPE1NIR2/Tt3xh2JiIhUq0IkxrOBK6PeKU4Dtrj72gIcN1bqkUKktFJ/b6o1FhGRuHTLtYGZ/Rw4FxhoZquBrwDdAdx9OjAHuBBoAnYCVxUr2FJqbobjjos7CpHqMWhQmDc3axh2ERGJRz69Ulzm7kPdvbu7N7r7D919epQUE/VGcZ27H+3uJ7r7/OKHXVz79sHmzWpfLFJKqb+3JHbZZmYXmNmyqL/3G7Ksb7c/+Pb2NbMBZvZHM3slmvdPW3djtP0yMzs/bfllZrYoOseDZqZSTkQkjUa+y2LjRnBXUwqRUurZM7Tr37Ah7kgKy8xqgdsIfb6PBS4zs7EZm2XtDz7HvjcAD7n7GOCh6D3R+kuBcYQ+6G83s1oz6wb8P+Bd7n4SsBC4vigXLSJSoZQYZ6Gu2kTikdCeKSYBTe7+qrvvBWYS+n9P115/8B3tOwW4J3p9D3Bx2vKZ7r7H3ZcTmrlNIvQgZMDhZmZAXxLwoLSISCEpMc5CibFIPBKaGOfT13t723S07+DUg87RfFBHx3L3fcA/AIsICfFY4IfZAq6kPudFRApJiXEWzc3htm5dXdyRiFSXQYNg0ybYuzfuSAoqn77e29sm737icx3LzLoTEuMJwDBCU4obsx2gkvqcFxEpJCXGWWzYEGquLNu/FxEpmlQOlrB2xvn09d7eNh3tuy5qbkE0Tz222N4+4wHc/a/u7sAs4IyuXZKISDIpMc5i0yaor487CpHqk9C+jJ8BxpjZKDPrQXgwbnbGNu31B9/RvrOBqdHrqcB9acsvNbOeZjaK8EDf08DrwFgzS1UBnwe8WOiLFRGpZDn7Ma5GW7aoH1WROCQxMXb3FjO7HpgL1AJ3ufsSM7s2Wt9uf/Dt7Rsd+mZglpldDawELon2WWJms4ClQAtwnbvvB9aY2deAx8xsH7AC+HjRPwARkQqixDjD/v2wbZtqjEXicPjhYRj2hDWlwN3nEJLf9GXT0147cF2++0bLNwLvbmefm4CbsiyfDkw/eA8REQE1pTjIli2hD2MlxiKlZwb9+4cBdkREREpNiXGG1D9kJcYi8aivV2IsIiLxUGKcQYmxSLyUGIuISFyUGGdQYiwSr/r60KSptTXuSEREpNooMc6waRN06wZ9+sQdiUh1qq8PSfG2bXFHIiIi1UaJcYYtW6BfPw3uIRKX1N2aTZvijUNERKqPEuMMmzerGYVInFJ/f2pnLCIipabEOIMSY5F49e8f5kqMRUSk1JQYZ1BiLBKvujqoqVFiLCIipafEOM2uXbBnjxJjkTjV1IR2/kqMRUSk1JQYp1FXbSLlQX0Zi4hIHJQYp1FiLFIelBiLiEgclBinUWIsUh7q69Vdm4iIlJ4S4zRKjEXKQ3097N4dJhERkVJRYpxm82bo3Rt69Ig7EpHqpr6MRUQkDkqM06irNpHyoL6MRUQkDkqM02zeHLqJEpF4qcZYRETioMQ4zZYtqjEWKQdKjEVEJA55JcZmdoGZLTOzJjO7Icv6fmZ2v5m9YGZLzOyqwodaXO6wbVsYdUtE4tWzJxx2mHqmEBGR0sqZGJtZLXAbMBkYC1xmZmMzNrsOWOruJwPnAt82s4p6hG33bmhpUWIsUi7Ul7GIiJRaPjXGk4Amd3/V3fcCM4EpGds4UGdmBvQB3gRaChppkW3fHuZKjEXKQ79+sHVr3FGIiEg1yScxHg6sSnu/OlqW7lbgeGANsAj4F3dvzTyQmU0zs/lmNr+5ubmLIRdH6h+wEmOR8tC3rxJjEREprXwSY8uyzDPenw8sAIYB44FbzazvQTu5z3D3ie4+saGhodPBFtO2bWHe96CoRSQOdXVtf5ciIiKlkE9ivBoYkfa+kVAznO4q4DceNAHLgbcVJsTSSP0DVo2xSHno2xf27AmTiIhIKeSTGD8DjDGzUdEDdZcCszO2WQm8G8DMBgPHAa8WMtBiSyXGffrEG4eIBKm7N2pOISIipdIt1wbu3mJm1wNzgVrgLndfYmbXRuunA18H7jazRYSmF5939w1FjLvgtm0L3UN17x53JCICBybGZdbySkREEipnYgzg7nOAORnLpqe9XgO8t7ChlZb6MBYpL6nEWO2MRUSkVDTyXWTrViXGIuUk9feophQiIlIqSowj27crMRYpJ0qMRUSk1JQYR9SUQqS8dOsGvXsrMRYRkdJRYgy0tioxFilHffuqjbGIiJSOEmNg505wV2IsUm40+p2IiJSSEmM0HLRIuaqrU2IsIiKlo8QYjXonUq6SUmNsZheY2TIzazKzG7KsNzO7JVq/0MxOybWvmQ0wsz+a2SvRvH/auhuj7ZeZ2flpy3uY2Qwze9nMXjKzDxfzukVEKo0SY5QYi5Srvn1h927Yty/uSLrOzGqB24DJwFjgMjMbm7HZZGBMNE0D7shj3xuAh9x9DPBQ9J5o/aXAOOAC4PboOABfBNa7+7HR8f634BcsIlLBlBijxFikXCVkkI9JQJO7v+rue4GZwJSMbaYAP/ZgHlBvZkNz7DsFuCd6fQ9wcdryme6+x92XA03RcQD+HvgPAHdvrbQRSkVEik2JMeGfrhn06RN3JCKSLiF9GQ8HVqW9Xx0ty2ebjvYd7O5rAaL5oI6OZWb10fuvm9lzZvZLMxucLWAzm2Zm881sfnNzcz7XKCKSCEqMCYlxnz5Qo09DpKykaowrPDG2LMs8z23y2Tff83UDGoE/u/spwF+Ab2U7gLvPcPeJ7j6xoaEhx+lERJJDqSDqw1ikXCWkxng1MCLtfSOwJs9tOtp3XdTcgmi+PsexNgI7gf+Jlv8SOAUREXmLEmOUGIuUq4TUGD8DjDGzUWbWg/Bg3OyMbWYDV0a9U5wGbImaR3S072xgavR6KnBf2vJLzaynmY0iPND3tLs7cD9wbrTdu4GlBb5WEZGK1i3uAMrBtm0wYkTu7USktHr0gF69KvvhO3dvMbPrgblALXCXuy8xs2uj9dOBOcCFhAfldgJXdbRvdOibgVlmdjWwErgk2meJmc0iJL0twHXuvj/a5/PAvWb2PaA5dR4REQmUGNPWxlhEyk8S+jJ29zmE5Dd92fS01w5cl+++0fKNhFrfbPvcBNyUZfkK4J2diV1EpJpUfVOKlpYwJHTqlq2IlBeNficiIqVS9Ymx+jAWKW99+1Z2UwoREakcSoyVGIuUtSQ0pRARkcpQ9Ynx9u1hrsRYpDzV1cGOHbB/f+5tRUREDkXVJ8apmiglxiLlKfW3mfoSKyIiUixVnxinmlLo4TuR8pRKjNXOWEREik2J8TaorQ19pYpI+VFiLCIipaLEOBr1zizuSEQkGyXGIiJSKkqMNRy0SFlTYiwiIqWixFiJsUhZ690bamqUGIuISPEpMd6mB+9EyllNTRiyXYmx5OXNN2HWLLjpJti0Ke5oRKTC5JUYm9kFZrbMzJrM7IZ2tjnXzBaY2RIz+9/Chlk8qjEWKX8a/U7yMncuHHMMPPwwrFkDd98Nra1xRyUiFSRnYmxmtcBtwGRgLHCZmY3N2KYeuB34gLuPAy4pQqwFt2MH7N2rxFik3NXVafQ7ycEd/u3fYOBA+NKX4NJL4aWX4KGH4o5MRCpItzy2mQQ0ufurAGY2E5gCLE3b5nLgN+6+EsDd1xc60GJYH0WpxFikvNXVQXNz3FFIWXvqKVi0CO68M7wfPhwWL4bf/hZOOgkGD443PhGpCPk0pRgOrEp7vzpalu5YoL+ZPWpmz5rZlYUKsJiUGItUhro6NaWQHO68MzRGv+yy8N4MLr88jCX+9NPxxiYiFSOfxDhbD7+e8b4bcCrwPuB84MtmduxBBzKbZmbzzWx+cxlU/ygxFqkMdXWwZw/s2hV3JFKWNm+GX/wiJMLpBXq/fnD00bBgQXyxiUhFyScxXg2MSHvfCKzJss2D7r7D3TcAjwEnZx7I3We4+0R3n9jQ0NDVmAtGibFIZfJMiEcAACAASURBVEj9jZbB92kpR/feG741ffKTB68bPx5Wr4YNG0ofl4hUnHwS42eAMWY2ysx6AJcCszO2uQ8428y6mVlv4B3Ai4UNtfCUGItUhtTf6PqKeHpBSu5nP4MJE+CUUw5eN358mKvWWETykDMxdvcW4HpgLiHZneXuS8zsWjO7NtrmReBBYCHwNPADd19cvLALY/166NkTevSIOxIR6YgSY2nXjh0wfz5ccEH29Q0N0NgIzz9f2rhEpCLl0ysF7j4HmJOxbHrG+28C3yxcaMXX3KzaYpFKoMRY2jVvHrS0wDvf2f42J58Mc+aEPv80opOIdKCqR75bv16JsUglUGIs7XrssTA84hlntL/NhAmhn+NFi0oXl4hUJCXGSoxFyl7PntC9uxJjyeKxx0I74o5qghsbQ1duTU2li0tEKpISYyXGImXPLOQ9SozlAHv3hqYUHTWjgPALNGoULF9emrhEpGJVbWLc2qo2xiKVpK5OibFkmD8fdu/OnRgDjB4Na9eGh/VERNpRtYnx5s3heQ0lxiKVoU8f9WMsGR57LMzPOiv3tqNHh/lrrxUtHBGpfFWbGKdqnvSAskhlUI2xHOTxx+H440OXbLmMHBmaVLz6atHDEpHKVfWJsWqMRSpDKjH2zAHppTq5w5NP5ldbDNCrFwwfrsRYRDpUtYlx6pasEmORytC3b3jWauvWuCORsrBiRWgTd+qp+e+TegCvtbV4cYlIRavaxFg1xiKVRX0ZywFSQzynhnzOx+jRsGsXrFtXnJhEpOJVfWLcp0+8cYhIfpQYywFeeCG0GT7hhPz3ST2Ap+YUItKOqk6MBwyA2tq4IxGRfCgxlgMsWADHHguHH57/PoMGQe/e6s9YRNpV1YnxoEFxRyEi+VJiLAdYsKBzzSggDB09YgSsWlWcmESk4ikxFpGKkGr2pMRY2Lw59Ed88smd37exEV5/HfbvL3hYIlL5lBiLSEXo3h369avMQT7M7AIzW2ZmTWZ2Q5b1Zma3ROsXmtkpufY1swFm9kczeyWa909bd2O0/TIzOz/L+Wab2eJiXGtJLFwY5p2tMYZQY7xvn75hiUhWSoxFpGIMGlR5+YyZ1QK3AZOBscBlZjY2Y7PJwJhomgbckce+NwAPufsY4KHoPdH6S4FxwAXA7dFxUvF8CNhe+Cstoa70SJHS2Bjmq1cXLh4RSYyqTIz37YM331RiLFJpKjExBiYBTe7+qrvvBWYCUzK2mQL82IN5QL2ZDc2x7xTgnuj1PcDFactnuvsed18ONEXHwcz6AJ8GvlGMCy2ZF14Io90NGdL5fYcODU9dq52xiGRRlYnxxo1hns8ooiJSPio0MR4OpGdhq6Nl+WzT0b6D3X0tQDRPfdXvaJ+vA98GdnblQspG6sE7s87v260bDBumGmMRyaoqE+PUP1bVGItUlgpNjLNlb5kDW7e3TT775nU+MxsPHOPu/5Njf8xsmpnNN7P5zeXWqHvfPli8uGvNKFIaG1VjLCJZKTEWkYoxaBBs2FBxHQqsBkakvW8E1uS5TUf7rouaWxDNU18Z2tvndOBUM3sNeAI41swezRawu89w94nuPrGh3G6tNTWFscFPPLHrx2hsDGOLa3xxEcmgxFhEKsagQeDe1hyqQjwDjDGzUWbWg/Bg3OyMbWYDV0a9U5wGbImaR3S072xgavR6KnBf2vJLzaynmY0iPND3tLvf4e7D3H0kcBbwsrufW4wLLqqlS8N83LiuH2NE9L1BzSlEJEO3uAOIgxJjkcqU+putpF5l3L3FzK4H5gK1wF3uvsTMro3WTwfmABcSHpTbCVzV0b7RoW8GZpnZ1cBK4JJonyVmNgtYCrQA17l7ZdWxd2Tp0tC2+G1v6/oxUj1TrFoFYzM7CBGRala1iXG3blBfH3ckItIZqbv65dbsNRd3n0NIftOXTU977cB1+e4bLd8IvLudfW4CbuognteAE/IIvfwsXQojR4ahnbvq8MOhf3/VGIvIQaq2KUVDQxgdVEQqR3qNsVSppUsLU8urB/BEJIuqTA0r6TasiLRRYlzlWlpg2bLCJcbr1oVeLkREIlWZGDc3qw9jkUo0YEC406PEuEotXw579hQuMW5thTfeOPRjiUhiVGVirBpjkcpUWwsDByoxrlqpHikKkRgPj8Y8UTtjEUmjxFhEKkqFDvIhhfDii2F+/PGHfqxBg8JT2K+/fujHEpHEyCsxNrMLzGyZmTWZ2Q0dbPd2M9tvZh8pXIiFtXMnbN+uxFikUikxrmJLl4Y+iOvqDv1YtbVhaGglxiKSJmdibGa1wG3AZGAscJmZHXQfK9ruPwn9bZatVDdPSoxFKpMS4ypWqB4pUoYPV1MKETlAPjXGk4Amd3/V3fcCM4EpWbb7J+DXtA1LWpY0uIdIZWtoUGJclVpbQ1OKQjSjSNHQ0CKSIZ/EeDiQ3tnj6mjZW8xsOPBBYDodMLNpZjbfzOY3x9RDvxJjkco2aFDIY/bsiTsSKamVK0NbuELXGIOaU4jIW/JJjC3LMs94/z3g87mGHXX3Ge4+0d0nNsTUX1oqMVZ3bSKVKfWlttJGv5NDVMgeKVKUGItIhnyGhF4NjEh73wisydhmIjDTzAAGAheaWYu7/7YgURbQ2rVhPnRovHGISNekD/LR2BhvLFJCqcS4kE0p+vYNk9oZi0gkn8T4GWCMmY0CXgcuBS5P38DdR6Vem9ndwAPlmBRDSIz79YPDDos7EhHpisGDw1zjMlSZpUthyJAwykshDR+uGmMReUvOphTu3gJcT+ht4kVglrsvMbNrzezaYgdYaGvXqrZYpJINGxbmqbs/UiUK3SNFSmNj+GXa32FLQBGpEvnUGOPuc4A5GcuyPmjn7h8/9LCKR4mxSGUbMiTM12Q26JLkcg+J8dSphT/28OGwb19otJ765RKRqlV1I9+tWaPEWKSS9ewJRxyhxLiqvP46bNtWvBpjUDtjEQGqLDF2V42xSBIMHaqmFFWlGD1SpAwZAjU1SoxFBKiyxHjz5tD3aaqNoohUpmHDVGNcVV58McyLkRh37x6e6NQvlIhQZYmxumoTSQYlxlVm6VIYOLB4HdA3NqrGWEQAJcYiUoGGDg3dtbW2xh2JlESxeqRIGT4cNm6EXbuKdw4RqQhKjEWk4gwbFnrX0uh3VcAdliwpbmKcegBP/RmLVD0lxiJScdSXcRVZvx42bSrsiHeZNDS0iESqLjHu3Rvq6uKOREQORerLrdoZV4Fi9kiR0r9/+OegdsYiVa+qEuNUH8ZmcUciIociVWOsxLgKlCIxNgu/VKoxFql6VZUYr12rrtpEkiA1QJmaUlSBxYtDjW6x28A1NobE2L245xGRslZ1ibHaF4tUPo1+V0UWL4YTTij+rb7hw2H3bli+vLjnEZGypsRYRCrSsGGqMU4895AYjxtX/HMdeWSYP/dc8c8lImWrahLj7dvDpMRYJBmGDlWNceKtWROGLD3hhOKfa/hwqK2F+fOLfy4RKVtVkxirqzaRZNHod1Vg8eIwL0Vi3L17SI6VGItUNSXGIlKRhg3T6HeJl0qMS9GUAmDkSHj2WT2AJ1LFlBiLSEUaOlSj3yXe4sWhC5KBA0tzviOPDE03Xn21NOcTkbJTNYlx6parEmORZFBfxlUg1SNFqRx1VJirOYVI1aqaxHjtWujRAwYMiDsSESmE1Jdc9UyRUK2tsGRJaRPjYcNCX4BKjEWqVtUkxitXhrtkGvVOJBlSNcYarCyhli+HXbtKmxh36wYnn6zEWKSKVU1i/Npr4bkKEUmGYcOgpgZWrYo7EimKJUvCvJSJMcCpp4a+jPVUp0hVqqrEONV8TEQqX/fuYRTfShiozMwuMLNlZtZkZjdkWW9mdku0fqGZnZJrXzMbYGZ/NLNXonn/tHU3RtsvM7Pzo2W9zex3ZvaSmS0xs5uLfd2HJNUjxdixpT3vxImwdSs0NZX2vCJSFqoiMd61C9atU42xSNKMGhW+9JYzM6sFbgMmA2OBy8wsM9ubDIyJpmnAHXnsewPwkLuPAR6K3hOtvxQYB1wA3B4dB+Bb7v42YAJwpplNLvwVF8gLL4RCu66utOd9+9vDfN680p5XRMpCVSTGK1aEuRJjkWQZObIiaownAU3u/qq77wVmAlMytpkC/NiDeUC9mQ3Nse8U4J7o9T3AxWnLZ7r7HndfDjQBk9x9p7s/AhAd6zmgsRgXXBDPPw+nnJJ7u0IbNw7q6+Hxx0t/bhGJnRJjEalYo0aF7tr27Ik7kg4NB9JbQq+OluWzTUf7Dnb3tQDRfFC+5zOzeuAiQk3zQcxsmpnNN7P5zXF0FL11K7zyCkyYUPpz19TAmWcqMRapUlWRGKdutSoxFkmWkSPDIGUrV8YdSYey9YWTObRae9vks2+nzmdm3YCfA7e4e9aRLNx9hrtPdPeJDQ0NOU5XBAsWhHkcNcYA73wnLFsG69fHc34RiU3VJMbdu2twD5GkGTUqzMu8nfFqYETa+0Ygc1iS9rbpaN91UXMLonkqi8t1vhnAK+7+vU5fSak891yYx5UYn312mKvWWKTq5JUY5/FE9RXRk9QLzexJMzu58KF23WuvwYgRUFubc1MRqSCpu0Bl3s74GWCMmY0ysx6EB+NmZ2wzG7gy6p3iNGBL1Dyio31nA1Oj11OB+9KWX2pmPc1sFOGBvqcBzOwbQD/gX4txoQXz/POhJmPIkHjOf+qpcNhhSoxFqlC3XBukPRV9HqEm4hkzm+3uS9M2Ww6c4+6boqecZwDvKEbAXaE+jEWSafjwMCZDOdcYu3uLmV0PzAVqgbvcfYmZXRutnw7MAS4kPCi3E7iqo32jQ98MzDKzq4GVwCXRPkvMbBawFGgBrnP3/WbWCHwReAl4zsJoR7e6+w+K/iF01nPPxVdbDGGY1NNOU2IsUoVyJsakPRUNYGapp6LfSozd/cm07edRZk86r1gBk8u3UyIR6aLa2jCiZZnXGOPucwjJb/qy6WmvHbgu332j5RuBd7ezz03ATRnLVpO9/XF52bkTli6FD34w3jjOPhu+8Y3wIGDfvvHGIiIlk09TinyeqE53NfD7bCvieNJ5925Yu1Y1xiJJVQl9GUsnLFoURp2Ls8YYQmLc2gpPPpl7WxFJjHwS47yfijazdxES489nWx/Hk86pp9WVGIskU4X0ZSz5ivvBu5TTTw9PbT+UtUc7EUmofBLjfJ6oxsxOAn4ATIlu8ZWFVE2ShoMWSaZRo8LIlrt2xR2JFMTzz8OAAeGJ6Tgdfjiccw488EC8cYhISeWTGOd8otrMjgR+A3zM3V8ufJhdpz6MRZIt9bet5hQJ8cwzobbYyqA59EUXwUsvQVNT3JGISInkTIzdvQVIPRX9IjAr9UR16qlq4P8ARwC3m9kCM5tftIg7acWK8NT6sGFxRyIixVAhfRlLPrZuhYULw8hz5eCii8L8/vvjjUNESiafXinyeaL6GuCawoZWGKk+jLvldaUiUmkqpC9jyce8eeGBt7POijuSYNQoGDcuJMaf+lTc0YhICSR+5LuXX4bRo+OOQkSKZcgQ6NlTiXEiPPEE1NTAO8qmG3z4wAfgscdg06a4IxGREkh0YtzaCkuWwIknxh2JiBRLTQ2MGROagkqFe+IJGD8e6urijqTNRRfB/v3w4INxRyIiJZDoxPjVV8OT6iecEHckIlJMJ50UmqZKBdu3D556qnyaUaRMmgQNDfCb38QdiYiUQKIT48WLw1w1xiLJduKJoc/yzZvjjkS6bMGCMOpduSXGtbVwxRVw332wfn3c0YhIkSU6MV60KMzHjo03DhEprpNOCvPUl2GpQE88Eebl0iNFumnTQo32PffEHYmIFFniE+PRo6FPn7gjEZFiSiXGak5RwZ54IhTY5di35vHHhyGiZ8wAzzrwq4gkRKIT48WL1YxCpBoMHw719W13iaTCtLbC44+XZ21xyrRpYaCPRx+NOxIRKaLEJsZ79oSu2vTgnUjymekBvIr23HPQ3AznnRd3JO378Iehf3+44464IxGRIkpsYvzSS6GHHdUYi1SHE08MNca6012BHngg9Ls3eXLckbTvsMNCrfGvfhUeFBSRREpsYpy6paoaY5HqcNJJsG1bGAZeKsz998Ppp8PAgXFH0rEbboABA+Azn9E3MJGESnRi3L07HHts3JGISCnoAbwK9frroSnF+98fdyS51dfDV74CDz8Mv/td3NGISBEkNjFevDg8SNy9e9yRiEgpjBsX5kqMK8ycOWF+0UXxxpGva68NNS6f+Qzs2BF3NCJSYIlMjN1DEzA1oxCpHnV1obcvJcYV5v77YeTIyulwvnt3uO220EPF1KmhRw0RSYxEJsYvvwxr1oRuJ0WkekycCE8+qeafFWPXLvjTn0IzCrO4o8nfe94D//Vf8Otfw9e/Hnc0IlJAiUyM//jHMC/nnn9EpPDOOy80WV26NO5IJC+//nVIjj/0obgj6bxPfzrUGH/1q/ClL4VukESk4iU2MR49Go4+Ou5IRKSUzj8/zOfOjTcOydOMGXDMMXDOOXFH0nlmcOedcPXVcNNN8L73wcqVcUclIococYnxvn3wyCOqLRapRiNGhIdulRhXgKVLw2h3n/hE6MO4EvXsCT/4QUjwH3kk1MZccw3Mm6caZJEK1S3uAArt6adDX6ZKjEWq0/nnw/Tp4Q79YYfFHY206/vfDw+yffzjcUdy6D7xifCL981vhuv64Q9Df8ennx6+qY0aBf36tU19+7b/ZcA9TK2tbVOu9ylmxZtSx88Wbz7LMmNsL95syzu7LPW57N9/4OfUmWWHun9Xl5mFgqtXr4Pnmcv69AldCNbVVVYb/TKXuMT4j38M5c3f/E3ckYhIHM4/H773PXjssbamFVJmdu+Ge+6BD34QBg2KO5rCOPJI+O//hq99Df7wB/j97+H558PDhXv2xB2dJFlNTUiQU1P//uH22VFHtU1jx8KQIXFHWhESmRhPnBh+L0Sk+rzzneEO99y5SozL1l13waZN8MlPxh3JwWbMKMxxzjwzTK2t4Tbmrl1t0+7d2fdx77jWNlXLnHqdXkuaqqVNnxdyWXp8+eiodrm9ea5zZ75vb3nqs0n/nLIt62ibQuyfK45s27lDSwvs3RvahrY37d0bvnDt2gU7d4Yp9Xr5cnj2Wdiy5cDPpr6+LVEeNQrGjMl/sIdp0/LbLgESlRivXw9PPRVG7RSR6tS7d0iOf/97+Pa3dYex7GzeHEaPe9e7wpR0NTVtTShEcjGDHj3CdKhaWsIX0I0bYfVqWLEiPCC6cGFImHv0CE19TjgBTjxRNYqRRCXGt94avpx/7GNxRyIicbrkklDB8fDD8O53xx2NHOCmm8I/6u98R99aRIqpWzdoaAjT297Wtnz3bnjlFVi0KAwT/MILYfkxx4R28aeeWtUPaCQmMd6+PSTGF18Mxx0XdzQiEqcrrwyVkv/+70qMy8pf/wq33AJXXQXjx8cdjUh16tUr1BCfeGKoOV67NgwXPG8e3HsvzJwZ/j7POCMk1JXaa0wXJSYx/uEPwx2Dz30u7khEJG49e8JnPgOf/WxoXvWOd8QdkbBzJ3z0o+GH841vxB2NiEC4azNsWJgmT4bXXoO//AWeeSZMRxwR2spfeCE0NsYdbUkk4mvAvn3hrtzZZ8Npp8UdjYiUg09+MjSZ+4//iDsSobU1jBL33HPws5/B0KFxRyQimczCQ3mXXx6GPL/mmtBrzOzZ4YG9970PfvvbkHQlWMXXGLuHmqGVK+GOO+KORkTKRZ8+8C//EkbsnTUL/vZv446oSu3bB//6r/CrX4WnId///rgjEpFcuneHt789TM3NoceLH/0odLE4eHDof/zqq0PPFglT8TXG3/lO6Dry058ONf0iIimf+xycdVZ4IPfhh+OOpgqtXg3nngu33x7atXzqU3FHJCKd1dAQmj+tWAH33x9uzX/rW3DssTBhQnig49lnOx7YpYLklRib2QVmtszMmszsoM7QLLglWr/QzE4pfKgH2rIFvvCFUNZ+5CNhwCERkXSHHRbuAo4ZEx7M/f7347kLeChlaHv7mtkAM/ujmb0Szfunrbsx2n6ZmZ2ftvxUM1sUrbvFrEjdQqxYAf/8z+Ef58KF4WGeb35TvVCIVLJu3cIdn9/+FlatCn/TffqEpHnixDCoyNSpcNttYRjiCh3YJmdTCjOrBW4DzgNWA8+Y2Wx3X5q22WRgTDS9A7gjmhfU0qXhQZpnnoFf/ALefBP+7u9Cf+xV9tCkiOSpf3948MHQlGLatNB07sMfhlNOgUmTYOTI4p7/UMrQHPveADzk7jdHCfMNwOfNbCxwKTAOGAb8ycyOdff90XGnAfOAOcAFwO8LesFvvhm6Btq/PxTQX/xi6AZKRJJj6NBQM/nZz4amFnPmhNrkuXPhxz8O23TvDuPGhUI2fRS+AQPCMNZ9+4ape/cDh0Lfuzf0ptDcDE1N8PLLoQCfNKkkl5ZPG+NJQJO7vwpgZjOBKUB6oT4F+LG7OzDPzOrNbKi7ry1ksNdcEx6WrKsL/cJ/9auhFl9EpCONjfDnP8Pvfgc33wzf/W4oe6+4An7yk6KfvstlKDCyg32nAOdG+98DPAp8Plo+0933AMvNrAmYZGavAX3d/S/RsX4MXEyhE+MBA0LV/LnnhhokEUm2hoZQUzx1akhuV68ONcbPPBPuGL38chiWeMeOrh2/Z88wpHUZJcbDgVVp71dzcG1wtm2GAwckxmY2jVBbAbDdzJZ1KtrItm3h9ujs2V3Z+yADgQ0FOVL5Seq1JfW6ILnXVpDrKvQIwj/9aZi64KhObHsoZWhH+w5OVT64+1ozG5R2rHlZjrUvep25/CCFKqtjlJS/oyRch66hPBzaNcQ5fPuePeFBv6uvhs5dR2fK6bfkkxhnaxSW2cI6n21w9xlAgQaiLwwzm+/uE+OOoxiSem1JvS5I7rUl9brydChlaF5la6GPVY5ldWck5fctCdehaygPSbgGKM115NMydzWQfj+sEVjThW1ERKrRoZShHe27LmpuQTRfn8exGrMsFxGRSD6J8TPAGDMbZWY9CA91ZDZimA1cGT1ZfRqwpdDti0VEKtShlKEd7TsbmBq9ngrcl7b8UjPraWajCA/0PR0db5uZnRb1RnFl2j4iIkIeTSncvcXMrgfmArXAXe6+xMyujdZPJzzdfCHQBOwEripeyAVXsbcL85DUa0vqdUFyry2p15XToZSh7e0bHfpmYJaZXQ2sBC6J9lliZrMID+i1ANdFPVIA/ANwN3AY4aG7wj54Vz6S8vuWhOvQNZSHJFwDlOA6zBPSIbOIiIiIyKFQ778iIiIiIigxFhEREREBqjwxzjVMazkwsxFm9oiZvWhmS8zsX6LlBRsONnpI5xfR8qfMbGQJr6/WzJ43swcSdl31ZvYrM3sp+tmdnoRrM7NPRb+Hi83s52bWKwnXJclRTuV6ksrvJJTVSSiXK7UMNrO7zGy9mS1OW1aSuM1sanSOV8ws9cBy+9y9KifCgyx/BUYDPYAXgLFxx5UlzqHAKdHrOuBlYCzwX8AN0fIbgP+MXo+NrqUnMCq6xtpo3dPA6YT+TH8PTI6W/yMwPXp9KfCLEl7fp4GfAQ9E75NyXfcA10SvewD1lX5thMEglgOHRe9nAR+v9OvSlJyJMivXSVD5TQLKaiq8XKaCy2DgncApwOK0ZUWPGxgAvBrN+0ev+3cYazF++Sphij7YuWnvbwRujDuuPOK+DzgPWAYMjZYNBZZluw7C0+ynR9u8lLb8MuDO9G2i190Io8pYCa6lEXgI+BvaCtskXFdfQuFlGcsr+tpoG4VtQHTOB4D3Vvp1aUrOVO7leqWW30koq5NQLld6GUwY4j49MS563OnbROvuBC7rKM5qbkrR3hCsZSu6NTABeIqM4WCB9OFg2xtatr3hYN/ax91bgC3AEcW4hgzfAz4HtKYtS8J1jQaagR9Ftx5/YGaHU+HX5u6vA98idA22ltDX7h+o8OuSRCnbcr3Cy+8klNUVXy4nsAwuRdydLhOqOTHuylCrsTGzPsCvgX91960dbZplmXewvKN9isbM3g+sd/dn890ly7Kyu65IN8ItozvcfQKwg3CbqD0VcW1R+68phFtbw4DDzezvOtoly7Kyuy5JlLL8/ank8jtBZXXFl8tVVAYXMu5OX081J8YVM4y1mXUnFKo/dfffRIsLORzsW/uYWTegH/Bm4a/kAGcCHzCz14CZwN+Y2U+o/OtKnXe1uz8Vvf8VoUCu9Gt7D7Dc3ZvdfR/wG+AMKv+6JDnKrlxPQPmdlLI6CeVy0srgUsTd6TKhmhPjfIZpjV30xOUPgRfd/Ttpqwo5HGz6sT4CPOxRY5xicfcb3b3R3UcSPvuH3f3vKv26omt7A1hlZsdFi95NGIWs0q9tJXCamfWO4nk38GICrkuSo6zK9SSU30kpqxNSLietDC5F3HOB95pZ/6jG/b3RsvYVokF1pU6EIVhfJjzx+MW442knxrMI1f4LgQXRdCGh7cxDwCvRfEDaPl+MrmkZ0ROb0fKJwOJo3a20jXzYC/glYTjap4HRJb7Gc2l7oCMR1wWMB+ZHP7ffEp6GrfhrA74GvBTFdC/hqeGKvy5NyZnKqVxPWvld6WV1EsrlSi2DgZ8T2kXvI9TiXl2quIG/j5Y3AVflilVDQouIiIiIUN1NKURERERE3qLEWEREREQEJcYiIiIiIoASYxERERERQImxiIiIiAigxFhEREREBFBiLCVmZvVm9o/R62Fm9qsSnnt7vtuY2Ugzu7z4UYmIlBeV01LNlBhLqdUD/wjg7mvc/SMxx9OekYAKXBGpRiqnpWp1izsAqTo3A0eb2QLCaDfHu/sJZvZx4GKgFjgB+DbQA/gYsAe40N3fNLOjgduABmAn8Al3fynbiaKhJH9G+D1/MGPdvwF/Sxg16H/c/StZ4jw+ivMe4H8Iowwdlh+G4QAAAelJREFUHq2/3t2f7PKnICJSvlROS9VSjbGU2g3AX919PPBvGetOIHz7nwTcBOx09wnAXwhjogPMAP7J3U8FPgvc3sG5/h9wh7u/HXgjtdDM3ksYe30SYYjQU83snVnifNzdx7v7d4H1wHnufgrwUeCWzl22iEjFUDktVUs1xlJOHnH3bcA2M9sC3B8tXwScZGZ9gDOAX5pZap+eHRzvTODD0et7gf+MXr83mp6P3vchFMCPdXCs7sCtZjYe2A8cm+9FiYgkiMppSTQlxlJO9qS9bk1730r4Xa0BNke1GPnyLMsM+A93v7MTx/kUsA44OYpjdyf2FRFJCpXTkmhqSiGltg2o68qO7r4VWG5mlwBYcHIHu/wZuDR6fUXa8rnA30c1G5jZcDMblCPOfsBad28ltKer7co1iIhUAJXTUrWUGEtJuftG4M9mthj4ZhcOcQVwtZm9ACwBpnSw7b8A15nZM4QCMxXDHwgPe/zFzBYBv+LgfwILgRYze8HMPkVoIzfVzOYRbs/t6ELsIiJlT+W0VDNzz3YHQ0RERESkuqjGWEREREQEPXwnCWBmXwQuyVj8S3e/KY54RETkQCqnpVKoKYWIiIiICGpKISIiIiICKDEWEREREQGUGIuIiIiIAEqMRUREREQA+P/oZfPN7IisrQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## let's see if there is a diff of distribution in age according class\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(10, 4))  # 2 row, 2 columns\n",
    "\n",
    "ax1.set_title('Time Delta Distribution No Fraud')\n",
    "ax2.set_title('Time Delta Distribution Fraud')\n",
    "\n",
    "sns.distplot(fraud[fraud[\"class\"] ==0]['time_delta'], color = \"blue\", bins=15, ax=ax1)\n",
    "sns.distplot(fraud[fraud[\"class\"] ==1]['time_delta'], color = \"red\", bins=15, ax=ax2)\n",
    "      \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It seems quite evident here that frauds tend to have lower delta between sign up and purchase than no fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## let's see if there is a diff of distribution in age according class\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(10, 4))  # 2 row, 2 columns\n",
    "\n",
    "ax1.set_title('Sign Up Time Distribution No Fraud')\n",
    "ax2.set_title('Sign Up Time Distribution Fraud')\n",
    "\n",
    "sns.distplot(fraud[fraud[\"class\"] ==0]['signup_time_abs'], color = \"blue\", bins=15, ax=ax1)\n",
    "sns.distplot(fraud[fraud[\"class\"] ==1]['signup_time_abs'], color = \"red\", bins=15, ax=ax2)\n",
    "      \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does not seem to be any obvious difference in between signup time with fraud and without"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>signup_time</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>device_id</th>\n",
       "      <th>source</th>\n",
       "      <th>browser</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>class</th>\n",
       "      <th>country_name</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>signup_time_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22058</td>\n",
       "      <td>2015-02-24 22:55:49</td>\n",
       "      <td>2015-04-18 02:47:11</td>\n",
       "      <td>34</td>\n",
       "      <td>QVPSPJUOCKZAR</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>7.327584e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>Japan</td>\n",
       "      <td>13882</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>333320</td>\n",
       "      <td>2015-06-07 20:39:50</td>\n",
       "      <td>2015-06-08 01:38:54</td>\n",
       "      <td>16</td>\n",
       "      <td>EOGFQPIZPYXFZ</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>3.503114e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>17944</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1359</td>\n",
       "      <td>2015-01-01 18:52:44</td>\n",
       "      <td>2015-01-01 18:52:45</td>\n",
       "      <td>15</td>\n",
       "      <td>YSSKYOSJHPPLJ</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Opera</td>\n",
       "      <td>M</td>\n",
       "      <td>53</td>\n",
       "      <td>2.621474e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150084</td>\n",
       "      <td>2015-04-28 21:13:25</td>\n",
       "      <td>2015-05-04 13:54:50</td>\n",
       "      <td>44</td>\n",
       "      <td>ATGTXKYKUDUQN</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>41</td>\n",
       "      <td>3.840542e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown_Country</td>\n",
       "      <td>60085</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221365</td>\n",
       "      <td>2015-07-21 07:09:52</td>\n",
       "      <td>2015-09-09 18:40:53</td>\n",
       "      <td>39</td>\n",
       "      <td>NAUITBZFJKHWW</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>4.155831e+08</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>41461</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151107</th>\n",
       "      <td>345170</td>\n",
       "      <td>2015-01-27 03:03:34</td>\n",
       "      <td>2015-03-29 00:30:47</td>\n",
       "      <td>43</td>\n",
       "      <td>XPSKTWGPWINLR</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>28</td>\n",
       "      <td>3.451155e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>77233</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151108</th>\n",
       "      <td>274471</td>\n",
       "      <td>2015-05-15 17:43:29</td>\n",
       "      <td>2015-05-26 12:24:39</td>\n",
       "      <td>35</td>\n",
       "      <td>LYSFABUCPCGBA</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>32</td>\n",
       "      <td>2.439047e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>67270</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151109</th>\n",
       "      <td>368416</td>\n",
       "      <td>2015-03-03 23:07:31</td>\n",
       "      <td>2015-05-20 07:07:47</td>\n",
       "      <td>40</td>\n",
       "      <td>MEQHCSJUBRBFE</td>\n",
       "      <td>SEO</td>\n",
       "      <td>IE</td>\n",
       "      <td>F</td>\n",
       "      <td>26</td>\n",
       "      <td>2.748471e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>Japan</td>\n",
       "      <td>28816</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151110</th>\n",
       "      <td>207709</td>\n",
       "      <td>2015-07-09 20:06:07</td>\n",
       "      <td>2015-09-07 09:34:46</td>\n",
       "      <td>46</td>\n",
       "      <td>CMCXFGRHYSTVJ</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>37</td>\n",
       "      <td>3.601175e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>48519</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151111</th>\n",
       "      <td>138208</td>\n",
       "      <td>2015-06-10 07:02:20</td>\n",
       "      <td>2015-07-21 02:03:53</td>\n",
       "      <td>20</td>\n",
       "      <td>ZINIADFCLHYPG</td>\n",
       "      <td>Direct</td>\n",
       "      <td>IE</td>\n",
       "      <td>M</td>\n",
       "      <td>38</td>\n",
       "      <td>4.103825e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown_Country</td>\n",
       "      <td>68493</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151112 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id         signup_time       purchase_time  purchase_value  \\\n",
       "0         22058 2015-02-24 22:55:49 2015-04-18 02:47:11              34   \n",
       "1        333320 2015-06-07 20:39:50 2015-06-08 01:38:54              16   \n",
       "2          1359 2015-01-01 18:52:44 2015-01-01 18:52:45              15   \n",
       "3        150084 2015-04-28 21:13:25 2015-05-04 13:54:50              44   \n",
       "4        221365 2015-07-21 07:09:52 2015-09-09 18:40:53              39   \n",
       "...         ...                 ...                 ...             ...   \n",
       "151107   345170 2015-01-27 03:03:34 2015-03-29 00:30:47              43   \n",
       "151108   274471 2015-05-15 17:43:29 2015-05-26 12:24:39              35   \n",
       "151109   368416 2015-03-03 23:07:31 2015-05-20 07:07:47              40   \n",
       "151110   207709 2015-07-09 20:06:07 2015-09-07 09:34:46              46   \n",
       "151111   138208 2015-06-10 07:02:20 2015-07-21 02:03:53              20   \n",
       "\n",
       "            device_id  source browser sex  age    ip_address  class  \\\n",
       "0       QVPSPJUOCKZAR     SEO  Chrome   M   39  7.327584e+08      0   \n",
       "1       EOGFQPIZPYXFZ     Ads  Chrome   F   53  3.503114e+08      0   \n",
       "2       YSSKYOSJHPPLJ     SEO   Opera   M   53  2.621474e+09      1   \n",
       "3       ATGTXKYKUDUQN     SEO  Safari   M   41  3.840542e+09      0   \n",
       "4       NAUITBZFJKHWW     Ads  Safari   M   45  4.155831e+08      0   \n",
       "...               ...     ...     ...  ..  ...           ...    ...   \n",
       "151107  XPSKTWGPWINLR     SEO  Chrome   M   28  3.451155e+09      1   \n",
       "151108  LYSFABUCPCGBA     SEO  Safari   M   32  2.439047e+09      0   \n",
       "151109  MEQHCSJUBRBFE     SEO      IE   F   26  2.748471e+09      0   \n",
       "151110  CMCXFGRHYSTVJ     SEO  Chrome   M   37  3.601175e+09      0   \n",
       "151111  ZINIADFCLHYPG  Direct      IE   M   38  4.103825e+09      0   \n",
       "\n",
       "           country_name  time_delta  signup_time_abs  \n",
       "0                 Japan       13882             22.0  \n",
       "1         United States       17944             20.0  \n",
       "2         United States           1             18.0  \n",
       "3       Unknown_Country       60085             21.0  \n",
       "4         United States       41461              7.0  \n",
       "...                 ...         ...              ...  \n",
       "151107    United States       77233              3.0  \n",
       "151108      Netherlands       67270             17.0  \n",
       "151109            Japan       28816             23.0  \n",
       "151110    United States       48519             20.0  \n",
       "151111  Unknown_Country       68493              7.0  \n",
       "\n",
       "[151112 rows x 14 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look at age "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9060962af0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEGCAYAAABrQF4qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXiU1d3/8fc3+0ZIwhKWLATZZAmrEHZRVGitio9ttY9YtYJUbWnVitrHp5t9rLVaq1VWpXWtS6uCP6tCAYMsSsKm7GkgC0tICARICNnO748ZMI2BTMIkZ2bu7+u6cpGZuSf5DMuHkzPnPrcYY1BKKRW4gmwHUEop1bq06JVSKsBp0SulVIDToldKqQCnRa+UUgEuxHaAxnTs2NH06NHDdgyllPIb2dnZJcaYTo095pNF36NHD7KysmzHUEopvyEieed6TKdulFIqwGnRK6VUgNOiV0qpAKdFr5RSAU6LXimlApwWvVJKBTgteqWUCnBa9EopFeC06JVSKsD55JmxynsWLMj22teaOXO4176WUqrt6IheKaUCnBa9UkoFOC16pZQKcDpH73DFxeXs3FnCnj2lhIQEkZrant69O9CtWzvb0ZRSXqJF71DHj5/mrbe28/nn+wGIjQ2ntraONWsKAJgwIYXrr7+YyMhQmzGVUl6gRe9A69YV8MYb26iurmPq1F5kZCSRmBgNQGnpKVau3Mfy5bls3VrEHXcMo3fvDpYTK6UuhBa9g9TU1PHGG9vIzMyjT58Ebr45ncTEmP84pkOHKG64oT8jRnTjxRc38ac/fcZdd11C//6NXrhGKeUH9M1Yhzh2rJKnnlpHZmYeV111ET/96eivlXx9PXrEcf/9Y0hMjOG55zawefOhNkyrlPImLXoHyMkp5be/XU1h4XFmzhzG9ddfTFCQNPm82Nhw7r03g+TkWObPz2bp0l1tkFYp5W1a9AGsurqWDz/M4ckn1xEREcycOWMZPrxbs75GdHQYs2ePIiUllhtueIsPP8xppbRKqdaiRR+gsrIOcMklC3nnnZ0MGZLIQw+Np3v32BZ9rcjIUH7841EMGNCJ6677m47slfIzWvQBpry8ivvu+4hRoxZx+HA5s2YN5847RxAVdWHLJKOjw1i2bDqDBiUybdobLF68yUuJlVKtTYs+gGzYsJ+BA+fy1FPrmTFjGNu3383QoV299vU7dIhixYpbuOyyNG6/fQmPPpqJMcZrX18p1Tq06APEa699wfjxizHGkJl5K/PmXU1cXITXv0+7duG8//73+O//HsQjj6zkppv+TkVFtde/j1LKe3QdfQD4/e/XMGfOciZMSOXtt79Np07RrfJ96m95PH58ChUV1bz55jbWrStk9uxRxMSEefR1dLtjpdqWjuj93Acf7GHOnOV897sDWLZsequVfEMiwpQpvfjhDy/h4METPPnkOo4fP90m31sp1Tw6ovdBnl4spKSkgt/+djXJybGMG5fCX/6yuZWTfd3gwYncc89InntuA3/4w1ruu2807dt7f8pIKdVyOqL3U7W1dcyf7/oP4c47hxMWFmwtS79+HZk9exRHj1bywgubqKvTN2iV8iUeFb2ITBGRXSKSIyIPNvK4iMgz7se3isiwBo8Hi8gmEXnfW8GdLjMzj/z8MqZPT2+z6Zrz6dUrge9+dwC7dh1h2bJc23GUUvU0WfQiEgw8B0wF+gM3iUj/BodNBXq7P2YCcxs8PhvYccFpFeBaK7906W769evI0KFdbMc5a+zYZIYN68J77+0kP7/MdhyllJsnI/qRQI4xJtcYUwX8Dbi2wTHXAi8Zl/VAnIh0BRCRJOCbwCIv5na0f/4zh4qKam64oT8iTe9Z01ZEhJtvTqddu3D+8pfNOoWjlI/wpOi7AwX1bhe67/P0mKeBB4C6830TEZkpIlkiklVcXOxBLGcqLi5nxYq9jBmTTHJyy7Y0aE3R0WHccMPF7N9/guzsA7bjKKXwrOgbGzI2HKo1eoyIXA0cNsY0uYzEGLPAGDPCGDOiUyfd+/xc3n9/N0FBwjXX9LUd5ZyGD+9Gt27tWLp0N7W15/3/XSnVBjwp+kIgud7tJKDhUO1cx4wFrhGRfbimfC4TkVdanNbhiovL+fzzA0yc2KNVznr1lqAg4Vvf6kNRkSuvUsouT4p+A9BbRNJEJAy4EVjS4JglwC3u1TcZQJkx5qAx5iFjTJIxpof7eSuMMTd78wU4yT//mUNQkHDllT1tR2nS0KFdSE6O5f33dVSvlG1NFr0xpga4B/gI18qZN40x20RklojMch/2AZAL5AALgbtaKa9jHTlSwbp1hYwbl+IXJySJuEb1JSUVZGcftB1HKUfz6MxYY8wHuMq8/n3z6n1ugLub+BqrgFXNTqgA+OijfyMCV111ke0oHhs0KJHOnaNYuXIfI0c2fP9eKdVW9MxYP1BWVsmaNQWMHp1MQkKk7TgeCwoSLr20B7m5R8nLO2Y7jlKOpUXvB5Yv30ttbR1TpvjPaP6MMWOSCQ8PZuXKfbajKOVYWvQ+rqKimszMPEaM6OYTWx00V2RkKBkZSWzYcIATJ3R3S6Vs0KL3catW7aOyssav5uYbmjSpBzU1daxenW87ilKOpEXvw6qqalmxYi8DB3YiObm97Tgt1rVrOy6+uCOZmXm61FIpC7TofdiaNfmcOFHFVVf1sh3lgk2alMbRo5Vs3nzIdhSlHEeL3kfV1tbx8ce5XHRRPL17J9iOc8EGDepMx45RrFixz3YUpRxHi95HbdhwgNLSU0yZ0sundqhsKddSy1RyckrZskVH9Uq1JS16H1RXZ/jwwxy6dWvHwIGdbcfxmjFjkgkLC+bZZz+3HUUpR9Gi90FbtxZx8OBJpky5iKAg/x/NnxEdHcaoUd159dUvOHKkwnYcpRxDi97HGOMazXfoEMmIEd1sx/G6SZN6UFlZwwsvbLIdRSnH0KL3MatW7WPv3mNcddVFBAcH3h9P9+6xTJrUg+ef36BLLZVqI4HXJH7uscc+JTY2nDFjkps+2E/96EcjycsrY+nS3bajKOUIWvQ+JCvrAMuW5TJ5chqhocG247Sab32rLykp7fVNWaXaiBa9D3nssU+Ji4tgwoRU21FaVUhIEHfdNYIVK/aybdth23GUCnha9D5ix45i3nlnB3fffQmRkaG247S6O+4YRlRUKE88sdZ2FKUCnha9j3j88TVERIQwe/Yo21HaRIcOUdx553BeeWUre/cetR1HqYCmRe8D8vPLePXVL5gxY5hfbkXcUvffP4bg4CAef3yN7ShKBTQteh/whz+4pi/uu2+M5SRtq1u3dvzgB0NZvHgz+/cftx1HqYClRW/Z4cPlLFy4kenT00lJ8d+tiFvqgQfGUldnzv5np5TyPi16y558ci2nT9fwwANjbUexokePOG6+OZ3587M5fLjcdhylApIWvUWHDp3k2Wc/53vfG0S/fh1tx7HmoYfGUVlZwx//uM52FKUCkha9RY89tpqqqlp++ctLbUexqk+fDnz3uwP58583UFp6ynYcpQKOFr0lBQVlzJuXzW23DaFXL/+/sMiFevjhcZw8WcWzz35mO4pSAUeL3pLf/CYTgEcemWg5iW8YNCiRa6/ty5/+9BknTpy2HUepgKJFb0FOTikvvriJmTOHOXKlzbk8/PB4jh6t1C2MlfIyLXoLfv3rTwgLC+bhh8fbjuJTRo7szvjxKTz99HpqanQLY6W8RYu+jW3fXswrr2zlnntG0rVrO9txfM79948hL6+Mv/99u+0oSgWMENsBnOYXv1hFdHSYY9fNAyxYkH3Ox+rqDImJ0Tz44HKOHats8sLoM2cO93Y8pQKOjujb0NatRbz99nZ++tMMOnaMsh3HJwUFCZdf3pN9+8rYs6fUdhylAoKO6L3ofCNVgBde2Eh4eDDx8RFNHutko0cn8d57O/nXv/bSp08H23GU8ns6om8jJSUVZGUdZMKEVKKjw2zH8WlhYcGMG5fC1q1FHD2qJ1ApdaG06NvIsmW5iMDll6fZjuIXJkxIxRjD6tX5tqMo5fe06NvAiROnWbMmn1GjkoiPj7Qdxy907BjFgAGdWb06n9paXWqp1IXQom8Dq1blUV1dx5VX9rQdxa9cemkqx4+fZvPmQ7ajKOXXtOhbWW1tHatX5zFwYGddN99MAwZ0pkOHSFatyrMdRSm/pkXfyrZsKaKs7DQTJ6bajuJ3goKECRNS2b37CAcOnLAdRym/5VHRi8gUEdklIjki8mAjj4uIPON+fKuIDHPfHyEin4vIFhHZJiK/8vYL8HWffJJHQkIkAwd2th3FL40dm0xISBCZmTqqV6qlmix6EQkGngOmAv2Bm0Skf4PDpgK93R8zgbnu+08DlxljBgNDgCkikuGl7D6vqOgkO3eWMH58CkFB5z/DUzWuXbtwhg3ryrp1hVRW1tiOo5Rf8mREPxLIMcbkGmOqgL8B1zY45lrgJeOyHogTka7u2yfdx4S6P4y3wvu6zMx8goKEsWOTbUfxa5demkplZQ2ff77fdhSl/JInRd8dKKh3u9B9n0fHiEiwiGwGDgPLjDGNXllCRGaKSJaIZBUXF3ua32dVV9eybl0BQ4d2oX37CNtx/FrPnvEkJcXyySf7MMYx4wSlvMaTom9szqHhv7ZzHmOMqTXGDAGSgJEiMrCxb2KMWWCMGWGMGdGpUycPYvm2LVuKKC+vZty4FNtR/J6IMHFiKoWFJ8jNPWo7jlJ+x5OiLwTqzz0kAQeae4wx5hiwCpjS7JR+aO3aAuLjIxx90W9vGjmyOxERIbrUUqkW8KToNwC9RSRNRMKAG4ElDY5ZAtziXn2TAZQZYw6KSCcRiQMQkUhgMrDTi/l90tGjp9i+vZiMjCR9E9ZLIiJCGD06iY0bD+qlBpVqpiaL3hhTA9wDfATsAN40xmwTkVkiMst92AdALpADLATuct/fFVgpIltx/YexzBjzvpdfg8/57LP9GOPahVF5z4QJqdTU1LFmTUHTByulzvJom2JjzAe4yrz+ffPqfW6Auxt53lZg6AVm9CvGGNauLaBXrwQSE2Nsxwko3bq1o0+fDmRm5nHllRfpT0tKeUjPjPWy3NxjFBWV62i+lVx6aSpHjpxi27bDtqMo5Te06L1s7doCwsKCGT68q+0oAWnIkC7Exobrm7JKNYMWvRedPl1DVtYBhg/vSmRkqO04ASk4OIjx41PYtu0wxcXltuMo5Re06L1o48aDVFbW6JmwrWz8+BREhMxMvSiJUp7QoveiNWsK6Nw5ml69EmxHCWjx8ZGkpyeyZk2+7n+jlAe06L1kz54j7NlTytixyYjoapDWdumlqZSXV/PWW9tsR1HK52nRe8nixZsRgYwMXW3TFvr27UhiYjRz52bZjqKUz9Oi94Kamjr++tctDBzYmbg43cCsLZy5KMm6dYVs2nTQdhylfJoWvRd8/PG/OXDgBGPG6JuwbWn06CQiIkKYPz/bdhSlfJoWvRe88MImOnWKIj090XYUR4mODuPGGwfy6qtf6P43Sp2HFv0FKi4uZ8mSXUyfnk5IiP52trVZs4Zz8mQVr776he0oSvksbaYL9MorW6mpqeP22x21pY/PGDmyO0OGdGHevCy9KIlS56BFfwGMMbzwwiZGjerOgAF68W8bRIRZs4azZUuRXmpQqXPQor8An322n23birnttiG2ozja9743iJiYMH1TVqlz0KK/AHPnZhETE8b3vjfIdhRHa9cunBtvHMCbb27TN2WVaoQWfQsdOVLBG298yfTp6bRrF247juPdfvtQysurefNNPVNWqYa06Fto8eLNnD5dyw9/OMJ2FIXrjOR+/Try4oubbUdRyudo0bdAXZ1h3rwsxo1LYdAgXTvvC0SE228fwtq1BezcWWI7jlI+RYu+BZYt+zf//vdR7rpLR/O+5JZbBhMcLLz44ibbUZTyKVr0LTB3bhadOkVx/fUX246i6klMjOHqq/vw0ktbqKmpsx1HKZ+hRd9M+fllLF26mzvuGEZ4uEfXVldt6NZbh1BUVM6yZf+2HUUpn6FF30wLF2ZjjGHmzOG2o6hGfOMbvUlIiOSll7bajqKUz9Cib4aqqloWLtzIN7/Zhx494mzHUY0ICwvmxhsH8O67Ozl+XNfUKwVa9M3y7rs7KSoq1yWVPm769MFUVtbw9tvbbUdRyido0TfD889vIC0tjquuush2FHUeo0Z1p3fvBF5+WadvlAIteo/t3FnCJ5/kceedwwkO1t82XyYiTJ+ezqpV+8jLO2Y7jlLWaWN5aOHCbEJCgrj1Vt3AzB/cfHM6gO5TrxRa9B45fbqGv/51C9dd14/ExBjbcZQH0tLiGT8+hZdf3qr71CvH06L3wDvv7OTIkVPMmDHMdhTVDNOnp7NzZwlZWQdsR1HKKi16DyxYkE2PHnFMntzTdhTVDN/+9gDCw4P1TVnleFr0Tdiz5wgrV+5jxoxhBAWJ7TiqGeLiIrjmmr68/vqXVFfX2o6jlDVa9E1YtGgjwcGiV5HyU9Onp1NSUsGHH+bYjqKUNY7frGXBgnNffq6mpo65c7MYNKgzS5fubsNUylPn+/MDqK2tIyYmjF/96hMOHjx53mN1WwsVqHREfx5bthzixIkqxo1LsR1FtVBwcBCXXNKNLVuKqKioth1HKSu06M9j9ep84uMjGDCgs+0o6gJkZCRRU1NHdrauvlHOpEV/DiUlFezYUcK4cSn6JqyfS01tT5cuMaxfv992FKWs0KI/h08/zUcExo5Nth1FXSARISMjiZycUkpKKmzHUarNeVT0IjJFRHaJSI6IPNjI4yIiz7gf3yoiw9z3J4vIShHZISLbRGS2t19Aa6irM6xfX8iAAZ2Jj4+0HUd5wahR3QH47LNCy0mUantNFr2IBAPPAVOB/sBNItK/wWFTgd7uj5nAXPf9NcB9xpiLgQzg7kae63Nycko5erTybDko/5eQEEmfPh1Yv75Qt0RQjuPJiH4kkGOMyTXGVAF/A65tcMy1wEvGZT0QJyJdjTEHjTEbAYwxJ4AdgM+354YNBwgNDSI9PdF2FOVFGRlJHD5cQU5Oqe0oSrUpT4q+O1BQ73YhXy/rJo8RkR7AUOCzxr6JiMwUkSwRySouLvYgVuuora1j48aDDB7chYgIx59mEFBGjOhKZGQIn3ySZzuKUm3Kk6JvbMlJw599z3uMiMQAfwd+Yow53tg3McYsMMaMMMaM6NSpkwexWseOHSWcPFnFJZd0s5ZBtY7w8BBGj05m48aDeplB5SieFH0hUH/pSRLQcEHyOY8RkVBcJf+qMeYfLY/aNjZsOEBkZAgDBtj7z0a1nokTU6mtNaxZU9D0wUoFCE+KfgPQW0TSRCQMuBFY0uCYJcAt7tU3GUCZMeagiAjwArDDGPOUV5O3gurqWjZvPsTQoV0JDQ22HUe1gi5dYujbtwOZmXnU1embssoZmix6Y0wNcA/wEa43U980xmwTkVkiMst92AdALpADLATuct8/FpgOXCYim90f3/D2i/CWPXtKqaysYfjwrrajqFY0cWIqpaWn+PLLw7ajKNUmPHq30RjzAa4yr3/fvHqfG+DuRp73KY3P3/uknJxSRKBXrwTbUVQrGjKkC+3bh/PJJ/t0ZZVyBD0ztp49e46QktJeV9sEuODgIMaNS2HbtmKKi8ttx1Gq1WnRu1VX17J37zEdzTvE+PEpiAiZmfm2oyjV6rTo3fLyyqiurqNPnw62o6g2EB8fyeDBiaxdW6BXn1IBT4vebc8e19mSOqJ3jokTUzl5sors7IO2oyjVqrTo3XJyjtC1awwxMWG2o6g20rdvRxITo/VMWRXwtOhx7VaZk3OU3r11NO8kQUHChAmp5OYeJS/vmO04SrUaLXqgsPA4lZU19O6t8/NOM3ZsMuHhwaxcuc92FKVajRY9rmWVoPPzThQZGUpGRhIbNhzQpZYqYGnRA/n5ZcTFRZCQoBcZcaJJk3pQU1PHwoUbbUdRqlVo0QNFReV06RJjO4aypGvXdlx8cUeef36DLrVUAcnxRW+MoaionMTEaNtRlEWTJqWxf/8J3n13p+0oSnmd44v+5MkqKiqq6dxZi97JBg3qTFpaHM8887ntKEp5neOLvqjI9QacTt04W1CQcM89I/n003w2bz5kO45SXqVFX3QSQKduFLffPpSoqFCefbbRq10q5be06IvKCQ4WXXGjiIuLYPr0dF599QtKSipsx1HKa7Toi8rp3Dma4GDH/1Yo4Ec/Gsnp07UsXJhtO4pSXuP4disqOqlvxKqzBgzozOTJPXnmmc85daradhylvMLRRV9bW0dxcYXOz6v/8POfj+fQoZN6ApUKGI4u+vz8Mmpq6khM1BU36iuXXtqDCRNSefzxNVRW1tiOo9QFc3TR79rl2uNGR/SqoV/8YiIHDpzghRd0VK/8n6OLfvfuM0WvI3r1nyZN6sHYscn87nc6qlf+z/FFHxkZQrt2erER9Z9EhF//ehKFhcf54x/X2Y6j1AVxdNHv2nWExMRoRMR2FOWDLrssjWnT+vHoo6spLDxuO45SLeboot+9+widO+u0jTq3J5+8ktraOubMWW47ilIt5tiir6qqpaCgjM6do2xHUT4sLS2en/1sDK+99gWffppvO45SLeLYot+//zjGQHy8bn2gzu/BB8eRnBzL3Xd/QE1Nne04SjWbY4v+zJyr7nGjmhIdHcYf/3gVW7cW8ec/6zbGyv84tugLClxFHx8fYTmJ8gfXX38xU6b04n//dyUHDpywHUepZnFw0ZcBOnWjPCMiPPvsVKqqarn//o9tx1GqWRxc9Mdp3z6ciIgQ21GUn+jVK4E5c8by+utfsmLFXttxlPKYo4s+Obm97RjKzzz44DjS0uK4++4PqKrSC4kr/+DYoi8sPE5ycqztGMrPREaG8uc/f4OdO0t46ik9Y1b5B8cWfUFBmRa9apFvfKM3113Xj9/8JpP8/DLbcZRqkiOLvrKyhuLiCpKStOhVyzz99FXU1RkefFDPmFW+z5FFf2YNvc7Rq5ZKTY3j/vtH8/rrX7J+faHtOEqdl8OLXkf0quXmzBlHly4x3HvvRxhjbMdR6pwcWfRn1tDriF5diJiYMB59dBLr1hXy9tvbbcdR6pw8KnoRmSIiu0QkR0QebORxEZFn3I9vFZFh9R57UUQOi8iX3gx+Ic6cFatz9OpC3XrrENLTE5kzZ7leoET5rCaLXkSCgeeAqUB/4CYR6d/gsKlAb/fHTGBuvcf+AkzxRlhvKSgoIyEhkqioUNtRlJ8LDg7iySevZO/eYzz77Ge24yjVKE9G9COBHGNMrjGmCvgbcG2DY64FXjIu64E4EekKYIzJBEq9GfpCuU6W0tG88o7Jk3ty9dV9ePTR1RQXl9uOo9TXeFL03YGCercL3fc19xif4TpZSufnlfc88cQVlJdX8ctfrrIdRamv8WSjl8aus9dwiYEnx5z/m4jMxDXtQ0pKSnOe2mwFBccZPTqpVb+H8j8LFmRf0PPHj09l3rxs7rxzBOnpiV5KpdSF82REXwgk17udBBxowTHnZYxZYIwZYYwZ0alTp+Y8tVkqKqopLT2lI3rldddc04eoqFB++MP/R12dLrdUvsOTot8A9BaRNBEJA24EljQ4Zglwi3v1TQZQZow56OWsXvHV0kqdo1feFR0dxn/918WsXVvA4sWbbMdR6qwmi94YUwPcA3wE7ADeNMZsE5FZIjLLfdgHQC6QAywE7jrzfBF5HVgH9BWRQhH5gZdfQ7PoWbGqNY0encT48Sk88MBySkoqbMdRCvBsjh5jzAe4yrz+ffPqfW6Au8/x3JsuJKC36Rp61ZpEhLlzv8mQIfOZPftDXn31etuRlHLembFndhvUqRvVWgYM6Mz//M94XnvtCz1jVvkExxV9Xt4xunSJITxcryylWs/DD49n+PCuzJr1PocOnbQdRzmc44o+P/84KSk6P69aV2hoMC+9NI2TJ6uYOXOpbnqmrHJg0ZeRmqpFr1pf//6deOyxy1m6dDeLF2+2HUc5mKOK3hhDfn6ZjuhVm5k9O4OJE1P5yU8+ZN++Y7bjKIdyVNEXF1dQWVmjRa/aTFCQsHjxtRgDt932np5IpaxwVNGfWXGjUzeqLaWlxfP001exatU+nnhije04yoEctfTkTNHriF61psb2zDHGMGxYVx5+eAVHjpyiV68Ej77WzJnDvR1POZAjR/Ra9KqtiQi33JJOQkIkixZt5OTJKtuRlIM4qujz8o4RFRVKQkKk7SjKgSIjQ5k5cxgnTlSxaNFGamvrbEdSDuGoos/PP05qantEGttVWanWl5oax003DWTHjhJee+0LXV+v2oTj5uh12kbZNm5cCiUlFfzznzl07BjN1Km9bEdSAc5RRZ+Xd4yhQ7vYjqEU11zTl5KSCt59dyehoUFMntzTdiQVwBxT9KdOVVNcXKFLK5VPCAoSbr11CLW1dbz11naqqmqZOrWXTiuqVuGYOfoz2xPr1I3yFSEhQdxxxzAyMpJ4771dvPnmNn2DVrUKx4zodWml8kXBwUF8//uDiYkJY/nyXA4ePMmMGcOIjg6zHU0FEMeM6PPyXPuMaNErXxMUJHz72/255ZZ0du8+wu9+t0a3NlZe5Ziiz88vQ0SvLKV819ixKdx772hOnarmd7/7lG3bDtuOpAKEg4r+ON26tSM0NNh2FKXOqVevBB56aBwdOkTx7LOf8/vfr9G19uqCOabo8/KO6bSN8gsdOkTxs5+NYdiwrsyZs5zvfOdtTpw4bTuW8mOOKHpjDF9+eZh+/TrajqKURyIiQpgxYxhPPHEF//jHDkaNWsSuXSW2Yyk/5YiiLyoqp7i4gsGDE21HUcpjIsL9949h2bLpFBdXMHLkIt57b6ftWMoPOaLot2w5BMDgwXpWrPI/l12WRnb2TPr06cB1173BI4+s0PX2qlkcUvRFADqiV34rJaU9q1ffxu23D+HRR1dz9dWvU1p6ynYs5SccU/TJybHEx+v2xMp/RUSEsGjRNcyffzX/+lcuI0YsOPvTqlLn44gzY7dsOUR6uo7mlf9p7GpVAPfeO5r587O45JKFTJ+ezqhRSU1+Lb1alXMF/Ij+9Okadu4s0WkbFVB69gdKOGUAAAoaSURBVIzn5z+fQI8ecbz44mbeeONLnbdX5xTwRb99ezG1tUbfiFUBJzY2nJ/+NIPLL09jxYp9PPXUep23V40K+KLXN2JVIAsODuI73xnAD34wlIKCMn75y1WsWrWPujo9m1Z9JeDn6LdsOURkZAi9eiXYjqJUqxk5sjs9e8bzyitbef31L1m/vpDvfGcAPXvG246mfIAjRvSDBiUSHBzwL1U5XMeOUcyePYpbbx3MkSOnePzxNSxatJGiIt0J0+kCekRvjGHLliKuv76f7ShKtQkRYfToZIYO7cqHH+awfHkuWVkHGDmyO6NGddf3qhwqoIe5BQXHKS09pX+5leNERIRw3XX9+L//u5zJk3uyceNBhgyZz6hRi1iwIJvDh8ttR1RtKKBH9C+/vAWAK67QCy8rZ4qNDeeGG/qfvR7t/PnZ3Hnn+8ya9T5jx6YwbVo/pk3rR1qazuUHsoAd0dfU1DF/fjaTJ/ekb1/dtVI5W3R0GD/5SQbbt9/Fpk138sgjEzh+/DT33fcxPXs+w5Ah8/jVr1axdWuR7n8fgMQX/1BHjBhhsrKyLuhrvPvuTqZNe4N//OM7TJt28TmPO9eZh0o5QXFxOZs3H2LTpkPk5h7FGNebukOHdmHgwM5cdFH81y7Wo2fY+iYRyTbGjGjssYCdunn++Q0kJcXyrW/1tR1FKZ/VqVM0V1xxEVdccRFlZZVs2VLE5s2HWLFiL8uW5RIaGkTPnvEkJcWe/Th9uobw8ICtjoAUkH9au3cfYdmyXH7zm0mEhATs7JRSXtW+fQQTJqQyYUIqlZU17N59hO3bi9m79yiZmXlUV7u2WHj88TWkpcXRs2c8PXvGN/g8nri4CMuvRDXkUdGLyBTgT0AwsMgY87sGj4v78W8AFcCtxpiNnjzX2/Lzy7j11ncJDQ3ijjuGtea3UipgRUSEkJ6eeHYzwLo6w+HD5RQWHqdTpyhyco6Sm3uUDRsOfG3bhdjYcLp3b0e3bu3o3j2Wbt1i3L+2O3t/ly4xev3mNtRk0YtIMPAccAVQCGwQkSXGmO31DpsK9HZ/jALmAqM8fK7XvP32dmbMWEpNTR0vvzyNLl1iWuPbKOU4QUFCly4xZ/9NpabGcfnlaQCcOlVNSUkFxcUVlJRUUFp6irKySnJzj7Jp0yGOHav82pYMItCuXTi9eiXQuXM07duHExsbTvv24bRvH3H213btwggPDyEsLJjw8GDCw0MICQlCxHXOQMNfz3zt5j7mftgnHgsKEq//+Xkyoh8J5Bhjct3B/gZcC9Qv62uBl4zrnd31IhInIl2BHh481ytKS08xY8ZS+vTpwGuvXc9FF+mWB0q1hcjIUJKT25Oc3L7Rx+vqDCdPVnHsWCVlZZUcPVp59vNjxyrZubOYU6dq3B/VZ6eInCgxMZpDh+73+tf1pOi7AwX1bhfiGrU3dUx3D58LgIjMBGa6b54UkV0eZPuazz+HXr1mtOSpTekI+PPVmTW/Xf6eH/z/Nfh8/qIiEPnZuR5uKn/quR7wpOgb+zmi4ZrMcx3jyXNddxqzAFjgQR4rRCTrXEuX/IHmt8vf84P/vwYn5/ek6AuB5Hq3k4ADHh4T5sFzlVJKtSJP1h5uAHqLSJqIhAE3AksaHLMEuEVcMoAyY8xBD5+rlFKqFTU5ojfG1IjIPcBHuJZIvmiM2SYis9yPzwM+wLW0MgfX8srbzvfcVnklrc9np5U8pPnt8vf84P+vwbH5fXILBKWUUt6jp40qpVSA06JXSqkAp0XfgIgki8hKEdkhIttEZLb7/gQRWSYie9y/+uQG3iISISKfi8gWd/5fue/3i/xniEiwiGwSkffdt/0t/z4R+UJENotIlvs+v3kN7pMe3xaRne5/C6P9Jb+I9HX/vp/5OC4iP/GX/GeIyE/d/4a/FJHX3f+2W/QatOi/rga4zxhzMZAB3C0i/YEHgX8ZY3oD/3Lf9kWngcuMMYOBIcAU90oof8l/xmxgR73b/pYfYJIxZki9tc/+9Br+BHxojOkHDMb1Z+EX+Y0xu9y/70OA4bgWiLyDn+QHEJHuwI+BEcaYgbgWs9xIS1+DMUY/zvMBvIdrr55dQFf3fV2BXbazeZA9CtiI62xkv8mP63yLfwGXAe+77/Ob/O6M+4CODe7zi9cAxAJ7cS/W8Lf8DTJfCazxt/x8tatAAq7Vke+7X0uLXoOO6M9DRHoAQ4HPgETjOjcA96+d7SU7P/e0x2bgMLDMGONX+YGngQeA+pue+FN+cJ0B/rGIZLu39wD/eQ09gWJgsXv6bJGIROM/+eu7EXjd/bnf5DfG7Af+AOQDB3Gdm/QxLXwNWvTnICIxwN+BnxhjjtvO0xzGmFrj+rE1CRgpIgNtZ/KUiFwNHDbG+Pulv8YaY4bh2tn1bhGZYDtQM4QAw4C5xpihQDk+PM1xLu6TNK8B3rKdpbncc+/XAmlANyBaRG5u6dfTom+EiITiKvlXjTH/cN9d5N6RE/evh23l85Qx5hiwCpiC/+QfC1wjIvuAvwGXicgr+E9+AIwxB9y/HsY1PzwS/3kNhUCh+ydBgLdxFb+/5D9jKrDRGFPkvu1P+ScDe40xxcaYauAfwBha+Bq06BsQEQFeAHYYY56q99AS4Pvuz7+Pa+7e54hIJxGJc38eiesvzE78JL8x5iFjTJIxpgeuH7tXGGNuxk/yA4hItIi0O/M5rrnVL/GT12CMOQQUiMiZ63Bejmtrcb/IX89NfDVtA/6VPx/IEJEodyddjusN8Ra9Bj0ztgERGQesBr7gqznih3HN078JpOD6Q/i2MabUSsjzEJF04K+43qUPAt40xvxaRDrgB/nrE5FLgfuNMVf7U34R6YlrFA+uaZDXjDG/9bPXMARYhGtjwlxc25oE4T/5o3C9mdnTGFPmvs9vfv8B3Eujv4trJeAm4A4ghha8Bi16pZQKcDp1o5RSAU6LXimlApwWvVJKBTgteqWUCnBa9EopFeC06JVSKsBp0SulVIDToleqHhF5170R2bYzm5GJyA9EZLeIrBKRhSLyZ/f9nUTk7yKywf0x1m56pRqnJ0wpVY+IJBhjSt3bR2wArgLW4Nrr5QSwAthijLlHRF4DnjfGfCoiKcBHxnUdA6V8SojtAEr5mB+LyDT358nAdOCTM6eZi8hbQB/345OB/q6tSACIFZF2xpgTbRlYqaZo0Svl5t5bZzIw2hhTISKrcF3o4Vyj9CD3safaJqFSLaNz9Ep9pT1w1F3y/XBdSjIKmCgi8SISAvxXveM/Bu45c8O9EZhSPkeLXqmvfAiEiMhW4DfAemA/8H+4di9djmu73jL38T8GRojIVhHZDsxq+8hKNU3fjFWqCSISY4w56R7RvwO8aIx5p6nnKeUrdESvVNN+6b4G75e4Lpr9ruU8SjWLjuiVUirA6YheKaUCnBa9UkoFOC16pZQKcFr0SikV4LTolVIqwP1/nrqtSbC721kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## let's plot age to see if there are any outliers\n",
    "\n",
    "sns.distplot(fraud['age'], color = \"navy\", bins=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution is less normalized when there is fraud, however we can take out outliers, especially under 60s\n",
    "- let's take out those under 3 stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(10, 4))  # 2 row, 2 columns\n",
    "\n",
    "ax1.set_title('age distribution no fraud')\n",
    "ax2.set_title('age distribution fraud')\n",
    "\n",
    "sns.distplot(fraud[fraud[\"class\"] ==0]['age'], color = \"blue\", bins=15, ax=ax1)\n",
    "sns.distplot(fraud[fraud[\"class\"] ==1]['age'], color = \"red\", bins=15, ax=ax2)\n",
    "      \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fraud_clean = fraud[(fraud[\"age\"].abs()-fraud[\"age\"].mean()) <= (3*fraud[\"age\"].std())]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f906378f400>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(fraud_clean['age'], color = \"navy\", bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>signup_time</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>device_id</th>\n",
       "      <th>source</th>\n",
       "      <th>browser</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>class</th>\n",
       "      <th>country_name</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>signup_time_abs</th>\n",
       "      <th>device_id_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150559.000000</td>\n",
       "      <td>150559</td>\n",
       "      <td>150559</td>\n",
       "      <td>150559.000000</td>\n",
       "      <td>150559</td>\n",
       "      <td>150559</td>\n",
       "      <td>150559</td>\n",
       "      <td>150559</td>\n",
       "      <td>150559.000000</td>\n",
       "      <td>1.505590e+05</td>\n",
       "      <td>150559.000000</td>\n",
       "      <td>150559</td>\n",
       "      <td>150559.000000</td>\n",
       "      <td>150559.000000</td>\n",
       "      <td>150559.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>150559</td>\n",
       "      <td>150132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137470</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-06-30 03:58:38</td>\n",
       "      <td>2015-09-10 09:04:53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KIPFSCNUGOLDP</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>60400</td>\n",
       "      <td>61223</td>\n",
       "      <td>87967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-01-01 00:00:42</td>\n",
       "      <td>2015-01-01 00:00:44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-18 04:40:29</td>\n",
       "      <td>2015-12-16 02:56:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>200184.206305</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.935201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.036756</td>\n",
       "      <td>2.152262e+09</td>\n",
       "      <td>0.093664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40940.477972</td>\n",
       "      <td>11.490519</td>\n",
       "      <td>1.684635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>115370.362863</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.321234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.459321</td>\n",
       "      <td>1.248566e+09</td>\n",
       "      <td>0.291362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26049.968544</td>\n",
       "      <td>6.917197</td>\n",
       "      <td>2.617998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>5.209350e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100662.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.085948e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18099.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>199987.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.154931e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40871.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>300100.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>3.243308e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63499.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>400000.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>4.294850e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86399.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              user_id          signup_time        purchase_time  \\\n",
       "count   150559.000000               150559               150559   \n",
       "unique            NaN               150559               150132   \n",
       "top               NaN  2015-06-30 03:58:38  2015-09-10 09:04:53   \n",
       "freq              NaN                    1                    3   \n",
       "first             NaN  2015-01-01 00:00:42  2015-01-01 00:00:44   \n",
       "last              NaN  2015-08-18 04:40:29  2015-12-16 02:56:05   \n",
       "mean    200184.206305                  NaN                  NaN   \n",
       "std     115370.362863                  NaN                  NaN   \n",
       "min          2.000000                  NaN                  NaN   \n",
       "25%     100662.500000                  NaN                  NaN   \n",
       "50%     199987.000000                  NaN                  NaN   \n",
       "75%     300100.000000                  NaN                  NaN   \n",
       "max     400000.000000                  NaN                  NaN   \n",
       "\n",
       "        purchase_value      device_id  source browser     sex            age  \\\n",
       "count    150559.000000         150559  150559  150559  150559  150559.000000   \n",
       "unique             NaN         137470       3       5       2            NaN   \n",
       "top                NaN  KIPFSCNUGOLDP     SEO  Chrome       M            NaN   \n",
       "freq               NaN             20   60400   61223   87967            NaN   \n",
       "first              NaN            NaN     NaN     NaN     NaN            NaN   \n",
       "last               NaN            NaN     NaN     NaN     NaN            NaN   \n",
       "mean         36.935201            NaN     NaN     NaN     NaN      33.036756   \n",
       "std          18.321234            NaN     NaN     NaN     NaN       8.459321   \n",
       "min           9.000000            NaN     NaN     NaN     NaN      18.000000   \n",
       "25%          22.000000            NaN     NaN     NaN     NaN      27.000000   \n",
       "50%          35.000000            NaN     NaN     NaN     NaN      33.000000   \n",
       "75%          49.000000            NaN     NaN     NaN     NaN      39.000000   \n",
       "max         154.000000            NaN     NaN     NaN     NaN      58.000000   \n",
       "\n",
       "          ip_address          class   country_name     time_delta  \\\n",
       "count   1.505590e+05  150559.000000         150559  150559.000000   \n",
       "unique           NaN            NaN            103            NaN   \n",
       "top              NaN            NaN  United States            NaN   \n",
       "freq             NaN            NaN          57836            NaN   \n",
       "first            NaN            NaN            NaN            NaN   \n",
       "last             NaN            NaN            NaN            NaN   \n",
       "mean    2.152262e+09       0.093664            NaN   40940.477972   \n",
       "std     1.248566e+09       0.291362            NaN   26049.968544   \n",
       "min     5.209350e+04       0.000000            NaN       1.000000   \n",
       "25%     1.085948e+09       0.000000            NaN   18099.000000   \n",
       "50%     2.154931e+09       0.000000            NaN   40871.000000   \n",
       "75%     3.243308e+09       0.000000            NaN   63499.000000   \n",
       "max     4.294850e+09       1.000000            NaN   86399.000000   \n",
       "\n",
       "        signup_time_abs  device_id_count  \n",
       "count     150559.000000    150559.000000  \n",
       "unique              NaN              NaN  \n",
       "top                 NaN              NaN  \n",
       "freq                NaN              NaN  \n",
       "first               NaN              NaN  \n",
       "last                NaN              NaN  \n",
       "mean          11.490519         1.684635  \n",
       "std            6.917197         2.617998  \n",
       "min            0.000000         1.000000  \n",
       "25%            5.000000         1.000000  \n",
       "50%           12.000000         1.000000  \n",
       "75%           17.000000         1.000000  \n",
       "max           23.000000        20.000000  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_clean.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dropping useless columns \n",
    "useless= [\"purchase_time\", \"ip_address\", \"user_id\", \"device_id\", \"signup_time\"]\n",
    "fraud_clean = fraud_clean.drop(columns = useless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dropping unknown countries\n",
    "fraud_clean = fraud_clean[fraud_clean[\"country_name\"] !=\"Unknown_Country\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>source</th>\n",
       "      <th>browser</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "      <th>country_name</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>signup_time_abs</th>\n",
       "      <th>device_id_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>128670.000000</td>\n",
       "      <td>128670</td>\n",
       "      <td>128670</td>\n",
       "      <td>128670</td>\n",
       "      <td>128670.000000</td>\n",
       "      <td>128670.000000</td>\n",
       "      <td>128670</td>\n",
       "      <td>128670.000000</td>\n",
       "      <td>128670.000000</td>\n",
       "      <td>128670.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>51778</td>\n",
       "      <td>52380</td>\n",
       "      <td>75164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36.932440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.023751</td>\n",
       "      <td>0.094972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40873.792477</td>\n",
       "      <td>11.493215</td>\n",
       "      <td>1.701251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.316886</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.455853</td>\n",
       "      <td>0.293177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26077.686100</td>\n",
       "      <td>6.910413</td>\n",
       "      <td>2.656169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17976.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40792.500000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63463.750000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>154.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86399.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        purchase_value  source browser     sex            age          class  \\\n",
       "count    128670.000000  128670  128670  128670  128670.000000  128670.000000   \n",
       "unique             NaN       3       5       2            NaN            NaN   \n",
       "top                NaN     SEO  Chrome       M            NaN            NaN   \n",
       "freq               NaN   51778   52380   75164            NaN            NaN   \n",
       "mean         36.932440     NaN     NaN     NaN      33.023751       0.094972   \n",
       "std          18.316886     NaN     NaN     NaN       8.455853       0.293177   \n",
       "min           9.000000     NaN     NaN     NaN      18.000000       0.000000   \n",
       "25%          22.000000     NaN     NaN     NaN      27.000000       0.000000   \n",
       "50%          35.000000     NaN     NaN     NaN      32.000000       0.000000   \n",
       "75%          49.000000     NaN     NaN     NaN      39.000000       0.000000   \n",
       "max         154.000000     NaN     NaN     NaN      58.000000       1.000000   \n",
       "\n",
       "         country_name     time_delta  signup_time_abs  device_id_count  \n",
       "count          128670  128670.000000    128670.000000    128670.000000  \n",
       "unique            102            NaN              NaN              NaN  \n",
       "top     United States            NaN              NaN              NaN  \n",
       "freq            57836            NaN              NaN              NaN  \n",
       "mean              NaN   40873.792477        11.493215         1.701251  \n",
       "std               NaN   26077.686100         6.910413         2.656169  \n",
       "min               NaN       1.000000         0.000000         1.000000  \n",
       "25%               NaN   17976.000000         6.000000         1.000000  \n",
       "50%               NaN   40792.500000        12.000000         1.000000  \n",
       "75%               NaN   63463.750000        17.000000         1.000000  \n",
       "max               NaN   86399.000000        23.000000        20.000000  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_clean.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>source</th>\n",
       "      <th>browser</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "      <th>country_name</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>signup_time_abs</th>\n",
       "      <th>device_id_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>Japan</td>\n",
       "      <td>13882</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>17944</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Opera</td>\n",
       "      <td>M</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>United States</td>\n",
       "      <td>41461</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>7331</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   purchase_value source browser sex  age  class   country_name  time_delta  \\\n",
       "0              34    SEO  Chrome   M   39      0          Japan       13882   \n",
       "1              16    Ads  Chrome   F   53      0  United States       17944   \n",
       "2              15    SEO   Opera   M   53      1  United States           1   \n",
       "4              39    Ads  Safari   M   45      0  United States       41461   \n",
       "5              42    Ads  Chrome   M   18      0         Canada        7331   \n",
       "\n",
       "   signup_time_abs  device_id_count  \n",
       "0             22.0                1  \n",
       "1             20.0                1  \n",
       "2             18.0               12  \n",
       "4              7.0                1  \n",
       "5              6.0                1  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing for Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import  OneHotEncoder, StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>source</th>\n",
       "      <th>browser</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>country_name</th>\n",
       "      <th>time_delta</th>\n",
       "      <th>signup_time_abs</th>\n",
       "      <th>device_id_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>39</td>\n",
       "      <td>Japan</td>\n",
       "      <td>13882</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>F</td>\n",
       "      <td>53</td>\n",
       "      <td>United States</td>\n",
       "      <td>17944</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Opera</td>\n",
       "      <td>M</td>\n",
       "      <td>53</td>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Safari</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>United States</td>\n",
       "      <td>41461</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42</td>\n",
       "      <td>Ads</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>M</td>\n",
       "      <td>18</td>\n",
       "      <td>Canada</td>\n",
       "      <td>7331</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   purchase_value source browser sex  age   country_name  time_delta  \\\n",
       "0              34    SEO  Chrome   M   39          Japan       13882   \n",
       "1              16    Ads  Chrome   F   53  United States       17944   \n",
       "2              15    SEO   Opera   M   53  United States           1   \n",
       "4              39    Ads  Safari   M   45  United States       41461   \n",
       "5              42    Ads  Chrome   M   18         Canada        7331   \n",
       "\n",
       "   signup_time_abs  device_id_count  \n",
       "0             22.0                1  \n",
       "1             20.0                1  \n",
       "2             18.0               12  \n",
       "4              7.0                1  \n",
       "5              6.0                1  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## X variables\n",
    "X = fraud_clean.drop(columns=\"class\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "4    0\n",
       "5    0\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = fraud_clean[\"class\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    test_size = 0.2,\n",
    "                                                    stratify = y , ## Statify splitting when you're training a classification model !\n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create pipeline for numeric features\n",
    "numeric_features = [0,4,6,7,8] # Positions of numeric columns in X_train/X_test\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create pipeline for categorical features\n",
    "categorical_features = [1, 2,3,5] # Positions of categorical columns in X_train/X_test\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "    ('encoder', OneHotEncoder(drop='first')) # first column will be dropped to avoid creating correlations between features\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Preprocessings on train set\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Preprocessings on test set\n",
    "X_test = preprocessor.transform(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model - LOGREG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### def function that prints scores\n",
    "\n",
    "def print_scores(model_name, X_train = X_train, X_test = X_test, y_test = y_test, y_train = y_train): \n",
    "    \n",
    "    from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
    "    \n",
    "    print(\"scores for default model on test set\")\n",
    "    print(\"\")\n",
    "    print('Accuracy Score : {}'.format(str(accuracy_score(y_test,model_name.predict(X_test)))))\n",
    "    print('Precision Score : {}'.format(str(precision_score(y_test,model_name.predict(X_test)))))\n",
    "    print('Recall Score : {}' .format(str(recall_score(y_test,model_name.predict(X_test)))))\n",
    "    print('F1 Score : {}'.format(str(f1_score(y_test,model_name.predict(X_test)))))\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"scores for default model on train set\")\n",
    "    print(\"\")\n",
    "    print('Accuracy Score : {}'.format(str(accuracy_score(y_train,model_name.predict(X_train)))))\n",
    "    print('Precision Score : {}'.format(str(precision_score(y_train,model_name.predict(X_train)))))\n",
    "    print('Recall Score : {}' .format(str(recall_score(y_train,model_name.predict(X_train)))))\n",
    "    print('F1 Score : {}'.format(str(f1_score(y_train,model_name.predict(X_train)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores for default model on test set\n",
      "\n",
      "Accuracy Score : 0.9513872697598508\n",
      "Precision Score : 0.9094028826355525\n",
      "Recall Score : 0.5421440261865794\n",
      "F1 Score : 0.6793129966675212\n",
      "\n",
      "\n",
      "scores for default model on train set\n",
      "\n",
      "Accuracy Score : 0.9506198025957877\n",
      "Precision Score : 0.9139177985535368\n",
      "Recall Score : 0.5299713584288053\n",
      "F1 Score : 0.6708967303334412\n"
     ]
    }
   ],
   "source": [
    "print_scores(lr_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "## cross val score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv_score= cross_val_score(lr_clf, X_train, y_train, cv=10, scoring= \"f1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66926576 0.67658473 0.66535433 0.66666667 0.66449935 0.65889968\n",
      " 0.6756931  0.67101828 0.66623377 0.68789809]\n",
      "\n",
      "0.670211374873337\n",
      "0.007730414899224172\n"
     ]
    }
   ],
   "source": [
    "print(cv_score)\n",
    "print(\"\")\n",
    "print(cv_score.mean())\n",
    "print(cv_score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def function that shows confusion matrix\n",
    "def show_confusion_matrix(model_name,X_train = X_train , X_test = X_test, y_test = y_test , y_train = y_train ):\n",
    "    import matplotlib.pyplot as plt \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2,figsize=(10, 4))  \n",
    "\n",
    "    ax1.set_title('Confusion Matrix of the test set')\n",
    "    ax1.set_xlabel(\"Predicted Values\")\n",
    "    ax1.set_ylabel(\"Actual Values\")\n",
    "    \n",
    "    ax2.set_title('Confusion Matrix of the train set')\n",
    "    ax2.set_xlabel(\"Predicted Values\")\n",
    "    ax2.set_ylabel(\"Actual Values\")\n",
    "    \n",
    "    cfm_test = confusion_matrix(y_test,model_name.predict(X_test))\n",
    "    cfm_train = confusion_matrix(y_train,model_name.predict(X_train))\n",
    "    sns.heatmap(cfm_test, annot=True, fmt=\"g\", cmap=\"seismic\", ax=ax1, )\n",
    "    sns.heatmap(cfm_train, annot=True, fmt=\"g\", cmap=\"seismic\", ax=ax2)\n",
    "    \n",
    "    \n",
    "    plt.tight_layout(), plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_confusion_matrix(lr_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Randomized Gridsearch CV on LOGREG\n",
    "- For time processing reason, we're not doing a random serach rather than a full gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "[CV] solver=saga, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=10000.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=10000.0, total=   5.0s\n",
      "[CV] solver=saga, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=10000.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=10000.0, total=   4.9s\n",
      "[CV] solver=saga, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=10000.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=10000.0, total=   5.3s\n",
      "[CV] solver=saga, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=10000.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=10000.0, total=   4.8s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=None, C=0.0006951927961775605 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight=None, C=0.0006951927961775605, total=   0.2s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=None, C=0.0006951927961775605 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight=None, C=0.0006951927961775605, total=   0.2s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=None, C=0.0006951927961775605 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight=None, C=0.0006951927961775605, total=   0.1s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=None, C=0.0006951927961775605 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight=None, C=0.0006951927961775605, total=   0.2s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight=None, C=0.23357214690901212 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight=None, C=0.23357214690901212, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight=None, C=0.23357214690901212 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight=None, C=0.23357214690901212, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight=None, C=0.23357214690901212 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight=None, C=0.23357214690901212, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight=None, C=0.23357214690901212 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight=None, C=0.23357214690901212, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=4.281332398719396 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=4.281332398719396, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=4.281332398719396 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=4.281332398719396, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=4.281332398719396 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=4.281332398719396, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=4.281332398719396 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=4.281332398719396, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.012742749857031334 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.012742749857031334, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.012742749857031334 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.012742749857031334, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.012742749857031334 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.012742749857031334, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.012742749857031334 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.012742749857031334, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=None, C=78.47599703514607 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=None, C=78.47599703514607, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=None, C=78.47599703514607 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=None, C=78.47599703514607, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=None, C=78.47599703514607 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=None, C=78.47599703514607, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=None, C=78.47599703514607 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=None, C=78.47599703514607, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=None, C=0.0001 .......\n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=None, C=0.0001, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=None, C=0.0001 .......\n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=None, C=0.0001, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=None, C=0.0001 .......\n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=None, C=0.0001, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=None, C=0.0001 .......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1312, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=newton-cg, penalty=l1, class_weight=None, C=0.0001, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=10000.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=10000.0, total=  10.0s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=10000.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=10000.0, total=   5.4s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=10000.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=10000.0, total=   5.5s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=10000.0 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=10000.0, total=   4.7s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=3792.690190732246 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=3792.690190732246, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=3792.690190732246 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=3792.690190732246, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=3792.690190732246 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=3792.690190732246, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=3792.690190732246 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=3792.690190732246, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight=balanced, C=0.615848211066026 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight=balanced, C=0.615848211066026, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight=balanced, C=0.615848211066026 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight=balanced, C=0.615848211066026, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight=balanced, C=0.615848211066026 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight=balanced, C=0.615848211066026, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight=balanced, C=0.615848211066026 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight=balanced, C=0.615848211066026, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=balanced, C=0.004832930238571752 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight=balanced, C=0.004832930238571752, total=   0.3s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=balanced, C=0.004832930238571752 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight=balanced, C=0.004832930238571752, total=   0.6s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=balanced, C=0.004832930238571752 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight=balanced, C=0.004832930238571752, total=   0.6s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=balanced, C=0.004832930238571752 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight=balanced, C=0.004832930238571752, total=   0.5s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.23357214690901212 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.23357214690901212, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.23357214690901212 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.23357214690901212, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.23357214690901212 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.23357214690901212, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.23357214690901212 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.23357214690901212, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.08858667904100823 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.08858667904100823 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.08858667904100823 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.08858667904100823 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.00026366508987303583 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.00026366508987303583, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.00026366508987303583 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.00026366508987303583, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.00026366508987303583 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.00026366508987303583, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.00026366508987303583 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.00026366508987303583, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.23357214690901212 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.23357214690901212, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.23357214690901212 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.23357214690901212, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.23357214690901212 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.23357214690901212, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.23357214690901212 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.23357214690901212, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=None, C=1.623776739188721 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=lbfgs, penalty=l2, class_weight=None, C=1.623776739188721, total=   1.0s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=None, C=1.623776739188721 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=lbfgs, penalty=l2, class_weight=None, C=1.623776739188721, total=   0.9s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=None, C=1.623776739188721 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=lbfgs, penalty=l2, class_weight=None, C=1.623776739188721, total=   0.9s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=None, C=1.623776739188721 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=lbfgs, penalty=l2, class_weight=None, C=1.623776739188721, total=   0.9s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=0.615848211066026 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=0.615848211066026, total=   7.9s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=0.615848211066026 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=0.615848211066026, total=   6.1s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=0.615848211066026 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=0.615848211066026, total=   4.8s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=0.615848211066026 \n",
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=0.615848211066026, total=   4.5s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight=None, C=78.47599703514607 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight=None, C=78.47599703514607, total=   2.5s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight=None, C=78.47599703514607 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight=None, C=78.47599703514607, total=   2.1s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight=None, C=78.47599703514607 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight=None, C=78.47599703514607, total=   2.4s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight=None, C=78.47599703514607 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight=None, C=78.47599703514607, total=   2.6s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=545.5594781168514 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=545.5594781168514, total=   3.9s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=545.5594781168514 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=545.5594781168514, total=   3.9s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=545.5594781168514 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=545.5594781168514, total=   3.9s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=545.5594781168514 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=545.5594781168514, total=   3.9s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.23357214690901212 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.23357214690901212, total=   0.9s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.23357214690901212 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.23357214690901212, total=   0.9s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.23357214690901212 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.23357214690901212, total=   0.9s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.23357214690901212 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.23357214690901212, total=   0.9s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=0.00026366508987303583 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=0.00026366508987303583, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=0.00026366508987303583 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=0.00026366508987303583, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=0.00026366508987303583 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=0.00026366508987303583, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=0.00026366508987303583 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=0.00026366508987303583, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.0006951927961775605 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.0006951927961775605, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.0006951927961775605 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.0006951927961775605, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.0006951927961775605 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.0006951927961775605, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.0006951927961775605 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.0006951927961775605, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=balanced, C=545.5594781168514 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=balanced, C=545.5594781168514, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=balanced, C=545.5594781168514 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=balanced, C=545.5594781168514, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=balanced, C=545.5594781168514 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=balanced, C=545.5594781168514, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=balanced, C=545.5594781168514 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=balanced, C=545.5594781168514, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.0006951927961775605 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=lbfgs, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.0006951927961775605, total=   0.1s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.0006951927961775605 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.0006951927961775605, total=   0.1s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.0006951927961775605 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.0006951927961775605, total=   0.1s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.0006951927961775605 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.0006951927961775605, total=   0.1s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.08858667904100823 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.08858667904100823 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.08858667904100823 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.08858667904100823 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight=None, C=0.0018329807108324356 \n",
      "[CV]  solver=sag, penalty=l1, class_weight=None, C=0.0018329807108324356, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight=None, C=0.0018329807108324356 \n",
      "[CV]  solver=sag, penalty=l1, class_weight=None, C=0.0018329807108324356, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight=None, C=0.0018329807108324356 \n",
      "[CV]  solver=sag, penalty=l1, class_weight=None, C=0.0018329807108324356, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight=None, C=0.0018329807108324356 \n",
      "[CV]  solver=sag, penalty=l1, class_weight=None, C=0.0018329807108324356, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1312, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=lbfgs, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight=balanced, C=206.913808111479 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight=balanced, C=206.913808111479, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight=balanced, C=206.913808111479 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight=balanced, C=206.913808111479, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight=balanced, C=206.913808111479 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight=balanced, C=206.913808111479, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight=balanced, C=206.913808111479 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight=balanced, C=206.913808111479, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356 \n",
      "[CV]  solver=sag, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356 \n",
      "[CV]  solver=sag, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356 \n",
      "[CV]  solver=sag, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356 \n",
      "[CV]  solver=sag, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.08858667904100823 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.08858667904100823 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.08858667904100823 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.08858667904100823 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.012742749857031334 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.012742749857031334, total=   0.3s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.012742749857031334 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.012742749857031334, total=   0.2s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.012742749857031334 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.012742749857031334, total=   0.3s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.012742749857031334 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.012742749857031334, total=   0.3s\n",
      "[CV] solver=saga, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=29.763514416313132 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=29.763514416313132, total=   4.0s\n",
      "[CV] solver=saga, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=29.763514416313132 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=29.763514416313132, total=   4.0s\n",
      "[CV] solver=saga, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=29.763514416313132 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=29.763514416313132, total=   4.1s\n",
      "[CV] solver=saga, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=29.763514416313132 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=29.763514416313132, total=   4.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=10000.0 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=10000.0, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=10000.0 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=10000.0, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=10000.0 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=10000.0, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=10000.0 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=10000.0, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.23357214690901212 \n",
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.23357214690901212, total=   3.3s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.23357214690901212 \n",
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.23357214690901212, total=   3.1s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.23357214690901212 \n",
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.23357214690901212, total=   3.3s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.23357214690901212 \n",
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=0.23357214690901212, total=   3.4s\n",
      "[CV] solver=saga, penalty=l1, class_weight=balanced, C=545.5594781168514 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight=balanced, C=545.5594781168514, total=  10.2s\n",
      "[CV] solver=saga, penalty=l1, class_weight=balanced, C=545.5594781168514 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight=balanced, C=545.5594781168514, total=  10.1s\n",
      "[CV] solver=saga, penalty=l1, class_weight=balanced, C=545.5594781168514 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight=balanced, C=545.5594781168514, total=  10.2s\n",
      "[CV] solver=saga, penalty=l1, class_weight=balanced, C=545.5594781168514 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight=balanced, C=545.5594781168514, total=  10.1s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight=None, C=0.615848211066026 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight=None, C=0.615848211066026, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight=None, C=0.615848211066026 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight=None, C=0.615848211066026, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight=None, C=0.615848211066026 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight=None, C=0.615848211066026, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight=None, C=0.615848211066026 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight=None, C=0.615848211066026, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight=balanced, C=29.763514416313132 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight=balanced, C=29.763514416313132, total=   2.7s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight=balanced, C=29.763514416313132 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight=balanced, C=29.763514416313132, total=   3.5s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight=balanced, C=29.763514416313132 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight=balanced, C=29.763514416313132, total=   3.2s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight=balanced, C=29.763514416313132 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight=balanced, C=29.763514416313132, total=   3.0s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight=balanced, C=0.012742749857031334 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight=balanced, C=0.012742749857031334, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight=balanced, C=0.012742749857031334 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight=balanced, C=0.012742749857031334, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight=balanced, C=0.012742749857031334 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight=balanced, C=0.012742749857031334, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight=balanced, C=0.012742749857031334 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight=balanced, C=0.012742749857031334, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=11.288378916846883 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=11.288378916846883, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=11.288378916846883 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=11.288378916846883, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=11.288378916846883 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=11.288378916846883, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=11.288378916846883 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=11.288378916846883, total=   0.0s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=0.012742749857031334 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=0.012742749857031334, total=   1.0s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=0.012742749857031334 \n",
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=0.012742749857031334, total=   0.6s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=0.012742749857031334 \n",
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=0.012742749857031334, total=   0.5s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=0.012742749857031334 \n",
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=0.012742749857031334, total=   0.5s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight=balanced, C=1.623776739188721 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight=balanced, C=1.623776739188721, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight=balanced, C=1.623776739188721 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight=balanced, C=1.623776739188721, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight=balanced, C=1.623776739188721 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight=balanced, C=1.623776739188721, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight=balanced, C=1.623776739188721 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight=balanced, C=1.623776739188721, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=206.913808111479 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=206.913808111479, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=206.913808111479 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=206.913808111479, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=206.913808111479 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=206.913808111479, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=206.913808111479 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=206.913808111479, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=balanced, C=4.281332398719396 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=balanced, C=4.281332398719396, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=balanced, C=4.281332398719396 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=balanced, C=4.281332398719396, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=balanced, C=4.281332398719396 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=balanced, C=4.281332398719396, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=balanced, C=4.281332398719396 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=balanced, C=4.281332398719396, total=   0.0s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=78.47599703514607 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1312, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=78.47599703514607, total=  10.0s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=78.47599703514607 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=78.47599703514607, total=  10.0s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=78.47599703514607 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=78.47599703514607, total=  10.0s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=78.47599703514607 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=78.47599703514607, total=   9.9s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight=None, C=0.615848211066026 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight=None, C=0.615848211066026, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight=None, C=0.615848211066026 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight=None, C=0.615848211066026, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight=None, C=0.615848211066026 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight=None, C=0.615848211066026, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight=None, C=0.615848211066026 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight=None, C=0.615848211066026, total=   0.0s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=3792.690190732246 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=3792.690190732246, total=  10.3s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=3792.690190732246 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=3792.690190732246, total=  11.0s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=3792.690190732246 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=3792.690190732246, total=  12.5s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=3792.690190732246 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=3792.690190732246, total=  11.9s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.615848211066026 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.615848211066026, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.615848211066026 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.615848211066026, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.615848211066026 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.615848211066026, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.615848211066026 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.615848211066026, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=10000.0 \n",
      "[CV]  solver=sag, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=10000.0, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=10000.0 \n",
      "[CV]  solver=sag, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=10000.0, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=10000.0 \n",
      "[CV]  solver=sag, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=10000.0, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=10000.0 \n",
      "[CV]  solver=sag, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=10000.0, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=11.288378916846883 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=11.288378916846883, total=   4.7s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=11.288378916846883 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=11.288378916846883, total=   4.7s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=11.288378916846883 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=11.288378916846883, total=   4.6s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=11.288378916846883 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=11.288378916846883, total=   4.5s\n",
      "[CV] solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=4.281332398719396 \n",
      "[CV]  solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=4.281332398719396, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=4.281332398719396 \n",
      "[CV]  solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=4.281332398719396, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=4.281332398719396 \n",
      "[CV]  solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=4.281332398719396, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=4.281332398719396 \n",
      "[CV]  solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=4.281332398719396, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=3792.690190732246 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=3792.690190732246, total=   4.5s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=3792.690190732246 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=3792.690190732246, total=   4.6s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=3792.690190732246 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=3792.690190732246, total=   4.6s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=3792.690190732246 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=3792.690190732246, total=   4.5s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=206.913808111479 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=206.913808111479, total=   4.6s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=206.913808111479 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=206.913808111479, total=   4.6s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=206.913808111479 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=206.913808111479, total=   4.7s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=206.913808111479 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=206.913808111479, total=   4.8s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=545.5594781168514 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=545.5594781168514, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=545.5594781168514 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=545.5594781168514, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=545.5594781168514 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=545.5594781168514, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=545.5594781168514 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=545.5594781168514, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight=balanced, C=11.288378916846883 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight=balanced, C=11.288378916846883, total=   2.8s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight=balanced, C=11.288378916846883 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight=balanced, C=11.288378916846883, total=   2.9s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight=balanced, C=11.288378916846883 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight=balanced, C=11.288378916846883, total=   3.0s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight=balanced, C=11.288378916846883 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight=balanced, C=11.288378916846883, total=   3.2s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight=None, C=0.08858667904100823 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight=None, C=0.08858667904100823, total=   1.1s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight=None, C=0.08858667904100823 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight=None, C=0.08858667904100823, total=   1.0s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight=None, C=0.08858667904100823 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight=None, C=0.08858667904100823, total=   1.0s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight=None, C=0.08858667904100823 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight=None, C=0.08858667904100823, total=   1.1s\n",
      "[CV] solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=0.03359818286283781 \n",
      "[CV]  solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=0.03359818286283781, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=0.03359818286283781 \n",
      "[CV]  solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=0.03359818286283781, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=0.03359818286283781 \n",
      "[CV]  solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=0.03359818286283781, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=0.03359818286283781 \n",
      "[CV]  solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=0.03359818286283781, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=None, C=0.004832930238571752 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=lbfgs, penalty=l2, class_weight=None, C=0.004832930238571752, total=   0.3s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=None, C=0.004832930238571752 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight=None, C=0.004832930238571752, total=   0.2s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=None, C=0.004832930238571752 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight=None, C=0.004832930238571752, total=   0.3s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=None, C=0.004832930238571752 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight=None, C=0.004832930238571752, total=   0.2s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight=balanced, C=3792.690190732246 \n",
      "[CV]  solver=sag, penalty=l1, class_weight=balanced, C=3792.690190732246, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight=balanced, C=3792.690190732246 \n",
      "[CV]  solver=sag, penalty=l1, class_weight=balanced, C=3792.690190732246, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight=balanced, C=3792.690190732246 \n",
      "[CV]  solver=sag, penalty=l1, class_weight=balanced, C=3792.690190732246, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight=balanced, C=3792.690190732246 \n",
      "[CV]  solver=sag, penalty=l1, class_weight=balanced, C=3792.690190732246, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1312, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=lbfgs, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766, total=   0.9s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=lbfgs, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766, total=   0.9s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=lbfgs, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766, total=   0.9s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=lbfgs, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766, total=   0.9s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight=balanced, C=0.0001 .......\n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight=balanced, C=0.0001, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight=balanced, C=0.0001 .......\n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight=balanced, C=0.0001, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight=balanced, C=0.0001 .......\n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight=balanced, C=0.0001, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight=balanced, C=0.0001 .......\n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight=balanced, C=0.0001, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.0001 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.0001, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.0001 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.0001, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.0001 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.0001, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.0001 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.0001, total=   0.0s\n",
      "[CV] solver=saga, penalty=l1, class_weight=None, C=0.08858667904100823 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight=None, C=0.08858667904100823, total=   4.9s\n",
      "[CV] solver=saga, penalty=l1, class_weight=None, C=0.08858667904100823 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight=None, C=0.08858667904100823, total=   5.0s\n",
      "[CV] solver=saga, penalty=l1, class_weight=None, C=0.08858667904100823 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight=None, C=0.08858667904100823, total=   5.3s\n",
      "[CV] solver=saga, penalty=l1, class_weight=None, C=0.08858667904100823 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1312, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight=None, C=0.08858667904100823, total=   5.4s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight=balanced, C=1438.44988828766 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight=balanced, C=1438.44988828766, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight=balanced, C=1438.44988828766 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight=balanced, C=1438.44988828766, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight=balanced, C=1438.44988828766 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight=balanced, C=1438.44988828766, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight=balanced, C=1438.44988828766 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight=balanced, C=1438.44988828766, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight=balanced, C=4.281332398719396 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight=balanced, C=4.281332398719396, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight=balanced, C=4.281332398719396 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight=balanced, C=4.281332398719396, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight=balanced, C=4.281332398719396 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight=balanced, C=4.281332398719396, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight=balanced, C=4.281332398719396 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight=balanced, C=4.281332398719396, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=1.623776739188721 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=1.623776739188721, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=1.623776739188721 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=1.623776739188721, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=1.623776739188721 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=1.623776739188721, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=1.623776739188721 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=1.623776739188721, total=   0.0s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=4.281332398719396 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=4.281332398719396, total=  10.1s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=4.281332398719396 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=4.281332398719396, total=   8.2s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=4.281332398719396 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=4.281332398719396, total=   8.0s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=4.281332398719396 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1312, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=4.281332398719396, total=   8.2s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight=None, C=0.0006951927961775605 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight=None, C=0.0006951927961775605, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight=None, C=0.0006951927961775605 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight=None, C=0.0006951927961775605, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight=None, C=0.0006951927961775605 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight=None, C=0.0006951927961775605, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight=None, C=0.0006951927961775605 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight=None, C=0.0006951927961775605, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight=balanced, C=0.08858667904100823 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight=balanced, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight=balanced, C=0.08858667904100823 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight=balanced, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight=balanced, C=0.08858667904100823 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight=balanced, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight=balanced, C=0.08858667904100823 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight=balanced, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight=balanced, C=0.08858667904100823 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight=balanced, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight=balanced, C=0.08858667904100823 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight=balanced, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight=balanced, C=0.08858667904100823 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight=balanced, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight=balanced, C=0.08858667904100823 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight=balanced, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=None, C=0.23357214690901212 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=lbfgs, penalty=l2, class_weight=None, C=0.23357214690901212, total=   0.7s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=None, C=0.23357214690901212 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=lbfgs, penalty=l2, class_weight=None, C=0.23357214690901212, total=   0.7s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=None, C=0.23357214690901212 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=lbfgs, penalty=l2, class_weight=None, C=0.23357214690901212, total=   0.8s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=None, C=0.23357214690901212 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1312, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=lbfgs, penalty=l2, class_weight=None, C=0.23357214690901212, total=   0.7s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.23357214690901212 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.23357214690901212, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.23357214690901212 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.23357214690901212, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.23357214690901212 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.23357214690901212, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.23357214690901212 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.23357214690901212, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.004832930238571752 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.004832930238571752, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.004832930238571752 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.004832930238571752, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.004832930238571752 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.004832930238571752, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.004832930238571752 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.004832930238571752, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=3792.690190732246 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=3792.690190732246, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=3792.690190732246 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=3792.690190732246, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=3792.690190732246 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=3792.690190732246, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=3792.690190732246 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=3792.690190732246, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=1.623776739188721 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=1.623776739188721, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=1.623776739188721 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=1.623776739188721, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=1.623776739188721 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=1.623776739188721, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=1.623776739188721 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=1.623776739188721, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=78.47599703514607 \n",
      "[CV]  solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=78.47599703514607, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=78.47599703514607 \n",
      "[CV]  solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=78.47599703514607, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=78.47599703514607 \n",
      "[CV]  solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=78.47599703514607, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=78.47599703514607 \n",
      "[CV]  solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=78.47599703514607, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.004832930238571752 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.004832930238571752, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.004832930238571752 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.004832930238571752, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.004832930238571752 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.004832930238571752, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.004832930238571752 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.004832930238571752, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight=None, C=0.0001 .......\n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight=None, C=0.0001, total=   0.5s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight=None, C=0.0001 .......\n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight=None, C=0.0001, total=   0.5s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight=None, C=0.0001 .......\n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight=None, C=0.0001, total=   0.5s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight=None, C=0.0001 .......\n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight=None, C=0.0001, total=   0.5s\n",
      "[CV] solver=saga, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356, total=   4.0s\n",
      "[CV] solver=saga, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356, total=   4.0s\n",
      "[CV] solver=saga, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356, total=   4.0s\n",
      "[CV] solver=saga, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=0.0018329807108324356, total=   4.0s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=0.012742749857031334 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=0.012742749857031334, total=   0.2s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=0.012742749857031334 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=0.012742749857031334, total=   0.2s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=0.012742749857031334 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=0.012742749857031334, total=   0.2s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=0.012742749857031334 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=0.012742749857031334, total=   0.3s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.03359818286283781 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.03359818286283781, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.03359818286283781 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.03359818286283781, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.03359818286283781 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.03359818286283781, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.03359818286283781 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.03359818286283781, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, class_weight=None, C=0.03359818286283781 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight=None, C=0.03359818286283781, total=   1.2s\n",
      "[CV] solver=sag, penalty=l2, class_weight=None, C=0.03359818286283781 \n",
      "[CV]  solver=sag, penalty=l2, class_weight=None, C=0.03359818286283781, total=   1.1s\n",
      "[CV] solver=sag, penalty=l2, class_weight=None, C=0.03359818286283781 \n",
      "[CV]  solver=sag, penalty=l2, class_weight=None, C=0.03359818286283781, total=   1.2s\n",
      "[CV] solver=sag, penalty=l2, class_weight=None, C=0.03359818286283781 \n",
      "[CV]  solver=sag, penalty=l2, class_weight=None, C=0.03359818286283781, total=   1.2s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight=balanced, C=0.615848211066026 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight=balanced, C=0.615848211066026, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight=balanced, C=0.615848211066026 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight=balanced, C=0.615848211066026, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight=balanced, C=0.615848211066026 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight=balanced, C=0.615848211066026, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight=balanced, C=0.615848211066026 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight=balanced, C=0.615848211066026, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight=balanced, C=0.00026366508987303583 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight=balanced, C=0.00026366508987303583, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight=balanced, C=0.00026366508987303583 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight=balanced, C=0.00026366508987303583, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight=balanced, C=0.00026366508987303583 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight=balanced, C=0.00026366508987303583, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight=balanced, C=0.00026366508987303583 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight=balanced, C=0.00026366508987303583, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1312, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=newton-cg, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766, total=   4.0s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766, total=   3.9s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766, total=   3.8s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766, total=   3.9s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.00026366508987303583 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.00026366508987303583, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.00026366508987303583 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.00026366508987303583, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.00026366508987303583 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.00026366508987303583, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.00026366508987303583 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.00026366508987303583, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight=balanced, C=3792.690190732246 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight=balanced, C=3792.690190732246, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight=balanced, C=3792.690190732246 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight=balanced, C=3792.690190732246, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight=balanced, C=3792.690190732246 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight=balanced, C=3792.690190732246, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight=balanced, C=3792.690190732246 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight=balanced, C=3792.690190732246, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=545.5594781168514 \n",
      "[CV]  solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=545.5594781168514, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=545.5594781168514 \n",
      "[CV]  solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=545.5594781168514, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=545.5594781168514 \n",
      "[CV]  solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=545.5594781168514, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=545.5594781168514 \n",
      "[CV]  solver=sag, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=545.5594781168514, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=balanced, C=1438.44988828766 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=lbfgs, penalty=l2, class_weight=balanced, C=1438.44988828766, total=   0.8s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=balanced, C=1438.44988828766 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=lbfgs, penalty=l2, class_weight=balanced, C=1438.44988828766, total=   0.8s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=balanced, C=1438.44988828766 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=lbfgs, penalty=l2, class_weight=balanced, C=1438.44988828766, total=   0.8s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=balanced, C=1438.44988828766 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=lbfgs, penalty=l2, class_weight=balanced, C=1438.44988828766, total=   0.7s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight=None, C=0.03359818286283781 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight=None, C=0.03359818286283781, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight=None, C=0.03359818286283781 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight=None, C=0.03359818286283781, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight=None, C=0.03359818286283781 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight=None, C=0.03359818286283781, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight=None, C=0.03359818286283781 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight=None, C=0.03359818286283781, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.08858667904100823 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.08858667904100823 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.08858667904100823 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.08858667904100823 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=None, C=0.0006951927961775605 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=None, C=0.0006951927961775605, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=None, C=0.0006951927961775605 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=None, C=0.0006951927961775605, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=None, C=0.0006951927961775605 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=None, C=0.0006951927961775605, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=None, C=0.0006951927961775605 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=None, C=0.0006951927961775605, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=balanced, C=0.00026366508987303583 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight=balanced, C=0.00026366508987303583, total=   0.1s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=balanced, C=0.00026366508987303583 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight=balanced, C=0.00026366508987303583, total=   0.1s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=balanced, C=0.00026366508987303583 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight=balanced, C=0.00026366508987303583, total=   0.1s\n",
      "[CV] solver=lbfgs, penalty=l2, class_weight=balanced, C=0.00026366508987303583 \n",
      "[CV]  solver=lbfgs, penalty=l2, class_weight=balanced, C=0.00026366508987303583, total=   0.1s\n",
      "[CV] solver=saga, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766, total=   4.0s\n",
      "[CV] solver=saga, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766, total=   4.1s\n",
      "[CV] solver=saga, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766, total=   4.0s\n",
      "[CV] solver=saga, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=1438.44988828766, total=   4.1s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=4.281332398719396 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=4.281332398719396, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=4.281332398719396 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=4.281332398719396, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=4.281332398719396 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=4.281332398719396, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=4.281332398719396 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight={1: 0.8, 0: 0.2}, C=4.281332398719396, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight=None, C=0.0001 .............\n",
      "[CV]  solver=sag, penalty=l1, class_weight=None, C=0.0001, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight=None, C=0.0001 .............\n",
      "[CV]  solver=sag, penalty=l1, class_weight=None, C=0.0001, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight=None, C=0.0001 .............\n",
      "[CV]  solver=sag, penalty=l1, class_weight=None, C=0.0001, total=   0.0s\n",
      "[CV] solver=sag, penalty=l1, class_weight=None, C=0.0001 .............\n",
      "[CV]  solver=sag, penalty=l1, class_weight=None, C=0.0001, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight=None, C=0.00026366508987303583 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight=None, C=0.00026366508987303583, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight=None, C=0.00026366508987303583 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight=None, C=0.00026366508987303583, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight=None, C=0.00026366508987303583 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight=None, C=0.00026366508987303583, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight=None, C=0.00026366508987303583 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight=None, C=0.00026366508987303583, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight=balanced, C=78.47599703514607 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight=balanced, C=78.47599703514607, total=   2.9s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight=balanced, C=78.47599703514607 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight=balanced, C=78.47599703514607, total=   3.4s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight=balanced, C=78.47599703514607 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight=balanced, C=78.47599703514607, total=   3.6s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight=balanced, C=78.47599703514607 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight=balanced, C=78.47599703514607, total=   3.3s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=balanced, C=0.004832930238571752 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=balanced, C=0.004832930238571752, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=balanced, C=0.004832930238571752 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=balanced, C=0.004832930238571752, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=balanced, C=0.004832930238571752 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=balanced, C=0.004832930238571752, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=balanced, C=0.004832930238571752 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=balanced, C=0.004832930238571752, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=206.913808111479 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=206.913808111479, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=206.913808111479 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=206.913808111479, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=206.913808111479 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=206.913808111479, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=206.913808111479 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=206.913808111479, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=3792.690190732246 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=3792.690190732246, total=   3.9s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=3792.690190732246 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=3792.690190732246, total=   3.9s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=3792.690190732246 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=3792.690190732246, total=   3.9s\n",
      "[CV] solver=sag, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=3792.690190732246 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=3792.690190732246, total=   3.9s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.08858667904100823 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.08858667904100823 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.08858667904100823 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.08858667904100823 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.08858667904100823, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=0.23357214690901212 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=0.23357214690901212, total=   0.9s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=0.23357214690901212 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=0.23357214690901212, total=   1.0s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=0.23357214690901212 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=0.23357214690901212, total=   0.8s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=0.23357214690901212 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=0.23357214690901212, total=   0.9s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=78.47599703514607 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=78.47599703514607, total=   2.8s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=78.47599703514607 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=78.47599703514607, total=   2.4s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=78.47599703514607 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=78.47599703514607, total=   2.4s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=78.47599703514607 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight={1: 0.8, 0: 0.2}, C=78.47599703514607, total=   2.1s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.0001 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.0001, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.0001 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.0001, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.0001 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.0001, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.0001 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=0.0001, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=balanced, C=0.0018329807108324356 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=balanced, C=0.0018329807108324356, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=balanced, C=0.0018329807108324356 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=balanced, C=0.0018329807108324356, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=balanced, C=0.0018329807108324356 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=balanced, C=0.0018329807108324356, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l1, class_weight=balanced, C=0.0018329807108324356 \n",
      "[CV]  solver=newton-cg, penalty=l1, class_weight=balanced, C=0.0018329807108324356, total=   0.0s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=78.47599703514607 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=78.47599703514607, total=  10.6s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=78.47599703514607 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=78.47599703514607, total=  11.8s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=78.47599703514607 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=78.47599703514607, total=  11.5s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=78.47599703514607 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.67, 0: 0.33}, C=78.47599703514607, total=  10.9s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=10000.0 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=10000.0, total=   4.9s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=10000.0 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=10000.0, total=   5.5s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=10000.0 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=10000.0, total=   5.0s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=10000.0 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight={1: 0.75, 0: 0.25}, C=10000.0, total=   4.6s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight=None, C=11.288378916846883 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight=None, C=11.288378916846883, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight=None, C=11.288378916846883 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight=None, C=11.288378916846883, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight=None, C=11.288378916846883 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight=None, C=11.288378916846883, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=elasticnet, class_weight=None, C=11.288378916846883 \n",
      "[CV]  solver=lbfgs, penalty=elasticnet, class_weight=None, C=11.288378916846883, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=4.281332398719396 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=4.281332398719396, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=4.281332398719396 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=4.281332398719396, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=4.281332398719396 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=4.281332398719396, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=4.281332398719396 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.8, 0: 0.2}, C=4.281332398719396, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight=None, C=0.0018329807108324356 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight=None, C=0.0018329807108324356, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight=None, C=0.0018329807108324356 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight=None, C=0.0018329807108324356, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight=None, C=0.0018329807108324356 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight=None, C=0.0018329807108324356, total=   0.0s\n",
      "[CV] solver=lbfgs, penalty=l1, class_weight=None, C=0.0018329807108324356 \n",
      "[CV]  solver=lbfgs, penalty=l1, class_weight=None, C=0.0018329807108324356, total=   0.0s\n",
      "[CV] solver=saga, penalty=l1, class_weight=None, C=0.0006951927961775605 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1312, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight=None, C=0.0006951927961775605, total=   0.5s\n",
      "[CV] solver=saga, penalty=l1, class_weight=None, C=0.0006951927961775605 \n",
      "[CV]  solver=saga, penalty=l1, class_weight=None, C=0.0006951927961775605, total=   0.6s\n",
      "[CV] solver=saga, penalty=l1, class_weight=None, C=0.0006951927961775605 \n",
      "[CV]  solver=saga, penalty=l1, class_weight=None, C=0.0006951927961775605, total=   0.6s\n",
      "[CV] solver=saga, penalty=l1, class_weight=None, C=0.0006951927961775605 \n",
      "[CV]  solver=saga, penalty=l1, class_weight=None, C=0.0006951927961775605, total=   0.3s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.004832930238571752 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.004832930238571752, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.004832930238571752 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.004832930238571752, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.004832930238571752 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.004832930238571752, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.004832930238571752 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight={1: 0.67, 0: 0.33}, C=0.004832930238571752, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.012742749857031334 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.012742749857031334, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.012742749857031334 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.012742749857031334, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.012742749857031334 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.012742749857031334, total=   0.0s\n",
      "[CV] solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.012742749857031334 \n",
      "[CV]  solver=saga, penalty=elasticnet, class_weight={1: 0.75, 0: 0.25}, C=0.012742749857031334, total=   0.0s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.23357214690901212 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1312, in fit\n",
      "    raise ValueError(\"l1_ratio must be between 0 and 1;\"\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.23357214690901212, total=   4.9s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.23357214690901212 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.23357214690901212, total=   5.1s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.23357214690901212 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.23357214690901212, total=   5.0s\n",
      "[CV] solver=saga, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.23357214690901212 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=saga, penalty=l1, class_weight={1: 0.75, 0: 0.25}, C=0.23357214690901212, total=   5.1s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight=None, C=0.0006951927961775605 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight=None, C=0.0006951927961775605, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight=None, C=0.0006951927961775605 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight=None, C=0.0006951927961775605, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight=None, C=0.0006951927961775605 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight=None, C=0.0006951927961775605, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=elasticnet, class_weight=None, C=0.0006951927961775605 \n",
      "[CV]  solver=newton-cg, penalty=elasticnet, class_weight=None, C=0.0006951927961775605, total=   0.0s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=1438.44988828766 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=1438.44988828766, total=   3.9s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=1438.44988828766 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=1438.44988828766, total=   3.7s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=1438.44988828766 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=1438.44988828766, total=   4.5s\n",
      "[CV] solver=newton-cg, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=1438.44988828766 \n",
      "[CV]  solver=newton-cg, penalty=l2, class_weight={1: 0.67, 0: 0.33}, C=1438.44988828766, total=   4.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight=balanced, C=0.004832930238571752 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight=balanced, C=0.004832930238571752, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight=balanced, C=0.004832930238571752 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight=balanced, C=0.004832930238571752, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight=balanced, C=0.004832930238571752 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight=balanced, C=0.004832930238571752, total=   0.0s\n",
      "[CV] solver=sag, penalty=elasticnet, class_weight=balanced, C=0.004832930238571752 \n",
      "[CV]  solver=sag, penalty=elasticnet, class_weight=balanced, C=0.004832930238571752, total=   0.0s\n",
      "[CV] solver=sag, penalty=l2, class_weight=None, C=11.288378916846883 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight=None, C=11.288378916846883, total=   4.4s\n",
      "[CV] solver=sag, penalty=l2, class_weight=None, C=11.288378916846883 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight=None, C=11.288378916846883, total=   4.5s\n",
      "[CV] solver=sag, penalty=l2, class_weight=None, C=11.288378916846883 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight=None, C=11.288378916846883, total=   4.3s\n",
      "[CV] solver=sag, penalty=l2, class_weight=None, C=11.288378916846883 .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=1)]: Done 480 out of 480 | elapsed: 10.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  solver=sag, penalty=l2, class_weight=None, C=11.288378916846883, total=   4.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=4, random_state=0, shuffle=True),\n",
       "                   estimator=LogisticRegression(), n_iter=120,\n",
       "                   param_distributions={'C': array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                                        'class_weight': [{0: 0.33, 1: 0.67},\n",
       "                                                         {0: 0.25, 1: 0.75},\n",
       "                                                         {0: 0.2, 1: 0.8},\n",
       "                                                         'None', 'balanced'],\n",
       "                                        'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                                        'solver': ['newton-cg', 'lbfgs', 'sag',\n",
       "                                                   'saga']},\n",
       "                   scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random search cross validation\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=0) \n",
    "\n",
    "parameters= {\"C\": np.logspace(-4, 4, 20), \\\n",
    "             \"class_weight\": [{1:0.67, 0:0.33}, {1:0.75, 0:0.25}, {1:0.8, 0:0.2}, \"None\", \"balanced\"], \\\n",
    "            \"penalty\": [\"l1\", \"l2\", \"elasticnet\"], \\\n",
    "            \"solver\" : [\"newton-cg\", \"lbfgs\", \"sag\", \"saga\"]}\n",
    "\n",
    "model = LogisticRegression()\n",
    "model_rs = RandomizedSearchCV(model, parameters, cv=kfold, verbose=2, scoring=\"f1\", n_iter=120)\n",
    "model_rs.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",model_rs.best_params_)\n",
    "print(\"accuracy :\",model_rs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lg_clf_rs = model_rs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores for default model on test set\n",
      "\n",
      "Accuracy Score : 0.9524753244734593\n",
      "Precision Score : 0.9072715143428952\n",
      "Recall Score : 0.5564648117839607\n",
      "F1 Score : 0.6898300786203397\n",
      "\n",
      "\n",
      "scores for default model on train set\n",
      "\n",
      "Accuracy Score : 0.9513095515660216\n",
      "Precision Score : 0.9092783505154639\n",
      "Recall Score : 0.5413256955810147\n",
      "F1 Score : 0.6786355475763016\n"
     ]
    }
   ],
   "source": [
    "print_scores(lg_clf_rs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_confusion_matrix(lg_clf_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores for default model on test set\n",
      "\n",
      "Accuracy Score : 0.9153260278231133\n",
      "Precision Score : 0.5481993452164423\n",
      "Recall Score : 0.6166121112929623\n",
      "F1 Score : 0.5803966878490274\n",
      "\n",
      "\n",
      "scores for default model on train set\n",
      "\n",
      "Accuracy Score : 1.0\n",
      "Precision Score : 1.0\n",
      "Recall Score : 1.0\n",
      "F1 Score : 1.0\n"
     ]
    }
   ],
   "source": [
    "print_scores(dt_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Massive overfitting here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57866537 0.57101589 0.55142443 0.58870168 0.55652174 0.56110836\n",
      " 0.5697561  0.56801196 0.58541361 0.57980769]\n",
      "\n",
      "0.5710426830315208\n",
      "0.01165572875095475\n"
     ]
    }
   ],
   "source": [
    "cv_score= cross_val_score(dt_clf, X_train, y_train, cv=10, scoring= \"f1\")\n",
    "print(cv_score)\n",
    "print(\"\")\n",
    "print(cv_score.mean())\n",
    "print(cv_score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_confusion_matrix(dt_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Randomized Search on Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 50 candidates, totalling 200 fits\n",
      "[CV] min_samples_split=30, min_samples_leaf=6, max_depth=49, criterion=gini, class_weight={1: 0.67, 0: 0.33} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_split=30, min_samples_leaf=6, max_depth=49, criterion=gini, class_weight={1: 0.67, 0: 0.33}, total=   3.3s\n",
      "[CV] min_samples_split=30, min_samples_leaf=6, max_depth=49, criterion=gini, class_weight={1: 0.67, 0: 0.33} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_split=30, min_samples_leaf=6, max_depth=49, criterion=gini, class_weight={1: 0.67, 0: 0.33}, total=   3.3s\n",
      "[CV] min_samples_split=30, min_samples_leaf=6, max_depth=49, criterion=gini, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=6, max_depth=49, criterion=gini, class_weight={1: 0.67, 0: 0.33}, total=   3.3s\n",
      "[CV] min_samples_split=30, min_samples_leaf=6, max_depth=49, criterion=gini, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=6, max_depth=49, criterion=gini, class_weight={1: 0.67, 0: 0.33}, total=   3.5s\n",
      "[CV] min_samples_split=20, min_samples_leaf=31, max_depth=21, criterion=gini, class_weight=balanced \n",
      "[CV]  min_samples_split=20, min_samples_leaf=31, max_depth=21, criterion=gini, class_weight=balanced, total=   1.6s\n",
      "[CV] min_samples_split=20, min_samples_leaf=31, max_depth=21, criterion=gini, class_weight=balanced \n",
      "[CV]  min_samples_split=20, min_samples_leaf=31, max_depth=21, criterion=gini, class_weight=balanced, total=   2.0s\n",
      "[CV] min_samples_split=20, min_samples_leaf=31, max_depth=21, criterion=gini, class_weight=balanced \n",
      "[CV]  min_samples_split=20, min_samples_leaf=31, max_depth=21, criterion=gini, class_weight=balanced, total=   1.9s\n",
      "[CV] min_samples_split=20, min_samples_leaf=31, max_depth=21, criterion=gini, class_weight=balanced \n",
      "[CV]  min_samples_split=20, min_samples_leaf=31, max_depth=21, criterion=gini, class_weight=balanced, total=   1.7s\n",
      "[CV] min_samples_split=10, min_samples_leaf=39, max_depth=20, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=10, min_samples_leaf=39, max_depth=20, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   1.5s\n",
      "[CV] min_samples_split=10, min_samples_leaf=39, max_depth=20, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=10, min_samples_leaf=39, max_depth=20, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   1.4s\n",
      "[CV] min_samples_split=10, min_samples_leaf=39, max_depth=20, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=10, min_samples_leaf=39, max_depth=20, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   1.5s\n",
      "[CV] min_samples_split=10, min_samples_leaf=39, max_depth=20, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=10, min_samples_leaf=39, max_depth=20, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   1.5s\n",
      "[CV] min_samples_split=50, min_samples_leaf=33, max_depth=6, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=50, min_samples_leaf=33, max_depth=6, criterion=entropy, class_weight=balanced, total=   0.4s\n",
      "[CV] min_samples_split=50, min_samples_leaf=33, max_depth=6, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=50, min_samples_leaf=33, max_depth=6, criterion=entropy, class_weight=balanced, total=   0.4s\n",
      "[CV] min_samples_split=50, min_samples_leaf=33, max_depth=6, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=50, min_samples_leaf=33, max_depth=6, criterion=entropy, class_weight=balanced, total=   0.3s\n",
      "[CV] min_samples_split=50, min_samples_leaf=33, max_depth=6, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=50, min_samples_leaf=33, max_depth=6, criterion=entropy, class_weight=balanced, total=   0.4s\n",
      "[CV] min_samples_split=20, min_samples_leaf=45, max_depth=13, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=20, min_samples_leaf=45, max_depth=13, criterion=entropy, class_weight=balanced, total=   0.8s\n",
      "[CV] min_samples_split=20, min_samples_leaf=45, max_depth=13, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=20, min_samples_leaf=45, max_depth=13, criterion=entropy, class_weight=balanced, total=   0.9s\n",
      "[CV] min_samples_split=20, min_samples_leaf=45, max_depth=13, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=20, min_samples_leaf=45, max_depth=13, criterion=entropy, class_weight=balanced, total=   0.9s\n",
      "[CV] min_samples_split=20, min_samples_leaf=45, max_depth=13, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=20, min_samples_leaf=45, max_depth=13, criterion=entropy, class_weight=balanced, total=   0.7s\n",
      "[CV] min_samples_split=40, min_samples_leaf=12, max_depth=42, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=40, min_samples_leaf=12, max_depth=42, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   3.7s\n",
      "[CV] min_samples_split=40, min_samples_leaf=12, max_depth=42, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=40, min_samples_leaf=12, max_depth=42, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   3.6s\n",
      "[CV] min_samples_split=40, min_samples_leaf=12, max_depth=42, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=40, min_samples_leaf=12, max_depth=42, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   3.9s\n",
      "[CV] min_samples_split=40, min_samples_leaf=12, max_depth=42, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=40, min_samples_leaf=12, max_depth=42, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   3.8s\n",
      "[CV] min_samples_split=30, min_samples_leaf=37, max_depth=13, criterion=gini, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=37, max_depth=13, criterion=gini, class_weight={1: 0.8, 0: 0.2}, total=   1.1s\n",
      "[CV] min_samples_split=30, min_samples_leaf=37, max_depth=13, criterion=gini, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=37, max_depth=13, criterion=gini, class_weight={1: 0.8, 0: 0.2}, total=   0.9s\n",
      "[CV] min_samples_split=30, min_samples_leaf=37, max_depth=13, criterion=gini, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=37, max_depth=13, criterion=gini, class_weight={1: 0.8, 0: 0.2}, total=   0.8s\n",
      "[CV] min_samples_split=30, min_samples_leaf=37, max_depth=13, criterion=gini, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=37, max_depth=13, criterion=gini, class_weight={1: 0.8, 0: 0.2}, total=   0.6s\n",
      "[CV] min_samples_split=40, min_samples_leaf=26, max_depth=22, criterion=entropy, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  min_samples_split=40, min_samples_leaf=26, max_depth=22, criterion=entropy, class_weight={1: 0.67, 0: 0.33}, total=   1.3s\n",
      "[CV] min_samples_split=40, min_samples_leaf=26, max_depth=22, criterion=entropy, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  min_samples_split=40, min_samples_leaf=26, max_depth=22, criterion=entropy, class_weight={1: 0.67, 0: 0.33}, total=   1.6s\n",
      "[CV] min_samples_split=40, min_samples_leaf=26, max_depth=22, criterion=entropy, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  min_samples_split=40, min_samples_leaf=26, max_depth=22, criterion=entropy, class_weight={1: 0.67, 0: 0.33}, total=   1.5s\n",
      "[CV] min_samples_split=40, min_samples_leaf=26, max_depth=22, criterion=entropy, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  min_samples_split=40, min_samples_leaf=26, max_depth=22, criterion=entropy, class_weight={1: 0.67, 0: 0.33}, total=   1.6s\n",
      "[CV] min_samples_split=20, min_samples_leaf=13, max_depth=43, criterion=gini, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=20, min_samples_leaf=13, max_depth=43, criterion=gini, class_weight={1: 0.8, 0: 0.2}, total=   2.6s\n",
      "[CV] min_samples_split=20, min_samples_leaf=13, max_depth=43, criterion=gini, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=20, min_samples_leaf=13, max_depth=43, criterion=gini, class_weight={1: 0.8, 0: 0.2}, total=   2.5s\n",
      "[CV] min_samples_split=20, min_samples_leaf=13, max_depth=43, criterion=gini, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=20, min_samples_leaf=13, max_depth=43, criterion=gini, class_weight={1: 0.8, 0: 0.2}, total=   2.5s\n",
      "[CV] min_samples_split=20, min_samples_leaf=13, max_depth=43, criterion=gini, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=20, min_samples_leaf=13, max_depth=43, criterion=gini, class_weight={1: 0.8, 0: 0.2}, total=   2.6s\n",
      "[CV] min_samples_split=30, min_samples_leaf=28, max_depth=42, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=28, max_depth=42, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   2.5s\n",
      "[CV] min_samples_split=30, min_samples_leaf=28, max_depth=42, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_split=30, min_samples_leaf=28, max_depth=42, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   2.4s\n",
      "[CV] min_samples_split=30, min_samples_leaf=28, max_depth=42, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=28, max_depth=42, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   2.7s\n",
      "[CV] min_samples_split=30, min_samples_leaf=28, max_depth=42, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=28, max_depth=42, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   3.7s\n",
      "[CV] min_samples_split=50, min_samples_leaf=26, max_depth=46, criterion=gini, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=50, min_samples_leaf=26, max_depth=46, criterion=gini, class_weight={1: 0.75, 0: 0.25}, total=   2.9s\n",
      "[CV] min_samples_split=50, min_samples_leaf=26, max_depth=46, criterion=gini, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=50, min_samples_leaf=26, max_depth=46, criterion=gini, class_weight={1: 0.75, 0: 0.25}, total=   2.2s\n",
      "[CV] min_samples_split=50, min_samples_leaf=26, max_depth=46, criterion=gini, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=50, min_samples_leaf=26, max_depth=46, criterion=gini, class_weight={1: 0.75, 0: 0.25}, total=   2.2s\n",
      "[CV] min_samples_split=50, min_samples_leaf=26, max_depth=46, criterion=gini, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=50, min_samples_leaf=26, max_depth=46, criterion=gini, class_weight={1: 0.75, 0: 0.25}, total=   2.3s\n",
      "[CV] min_samples_split=20, min_samples_leaf=44, max_depth=18, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=20, min_samples_leaf=44, max_depth=18, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   0.9s\n",
      "[CV] min_samples_split=20, min_samples_leaf=44, max_depth=18, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=20, min_samples_leaf=44, max_depth=18, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   1.2s\n",
      "[CV] min_samples_split=20, min_samples_leaf=44, max_depth=18, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=20, min_samples_leaf=44, max_depth=18, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   1.2s\n",
      "[CV] min_samples_split=20, min_samples_leaf=44, max_depth=18, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=20, min_samples_leaf=44, max_depth=18, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   1.0s\n",
      "[CV] min_samples_split=20, min_samples_leaf=13, max_depth=52, criterion=gini, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=20, min_samples_leaf=13, max_depth=52, criterion=gini, class_weight={1: 0.75, 0: 0.25}, total=   2.6s\n",
      "[CV] min_samples_split=20, min_samples_leaf=13, max_depth=52, criterion=gini, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=20, min_samples_leaf=13, max_depth=52, criterion=gini, class_weight={1: 0.75, 0: 0.25}, total=   2.5s\n",
      "[CV] min_samples_split=20, min_samples_leaf=13, max_depth=52, criterion=gini, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=20, min_samples_leaf=13, max_depth=52, criterion=gini, class_weight={1: 0.75, 0: 0.25}, total=   2.4s\n",
      "[CV] min_samples_split=20, min_samples_leaf=13, max_depth=52, criterion=gini, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=20, min_samples_leaf=13, max_depth=52, criterion=gini, class_weight={1: 0.75, 0: 0.25}, total=   2.5s\n",
      "[CV] min_samples_split=20, min_samples_leaf=49, max_depth=52, criterion=gini, class_weight=balanced \n",
      "[CV]  min_samples_split=20, min_samples_leaf=49, max_depth=52, criterion=gini, class_weight=balanced, total=   2.0s\n",
      "[CV] min_samples_split=20, min_samples_leaf=49, max_depth=52, criterion=gini, class_weight=balanced \n",
      "[CV]  min_samples_split=20, min_samples_leaf=49, max_depth=52, criterion=gini, class_weight=balanced, total=   1.9s\n",
      "[CV] min_samples_split=20, min_samples_leaf=49, max_depth=52, criterion=gini, class_weight=balanced \n",
      "[CV]  min_samples_split=20, min_samples_leaf=49, max_depth=52, criterion=gini, class_weight=balanced, total=   1.9s\n",
      "[CV] min_samples_split=20, min_samples_leaf=49, max_depth=52, criterion=gini, class_weight=balanced \n",
      "[CV]  min_samples_split=20, min_samples_leaf=49, max_depth=52, criterion=gini, class_weight=balanced, total=   1.9s\n",
      "[CV] min_samples_split=50, min_samples_leaf=37, max_depth=37, criterion=gini, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  min_samples_split=50, min_samples_leaf=37, max_depth=37, criterion=gini, class_weight={1: 0.67, 0: 0.33}, total=   2.2s\n",
      "[CV] min_samples_split=50, min_samples_leaf=37, max_depth=37, criterion=gini, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  min_samples_split=50, min_samples_leaf=37, max_depth=37, criterion=gini, class_weight={1: 0.67, 0: 0.33}, total=   2.1s\n",
      "[CV] min_samples_split=50, min_samples_leaf=37, max_depth=37, criterion=gini, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  min_samples_split=50, min_samples_leaf=37, max_depth=37, criterion=gini, class_weight={1: 0.67, 0: 0.33}, total=   2.0s\n",
      "[CV] min_samples_split=50, min_samples_leaf=37, max_depth=37, criterion=gini, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  min_samples_split=50, min_samples_leaf=37, max_depth=37, criterion=gini, class_weight={1: 0.67, 0: 0.33}, total=   2.3s\n",
      "[CV] min_samples_split=40, min_samples_leaf=15, max_depth=13, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=40, min_samples_leaf=15, max_depth=13, criterion=entropy, class_weight=balanced, total=   0.6s\n",
      "[CV] min_samples_split=40, min_samples_leaf=15, max_depth=13, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=40, min_samples_leaf=15, max_depth=13, criterion=entropy, class_weight=balanced, total=   0.7s\n",
      "[CV] min_samples_split=40, min_samples_leaf=15, max_depth=13, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=40, min_samples_leaf=15, max_depth=13, criterion=entropy, class_weight=balanced, total=   0.7s\n",
      "[CV] min_samples_split=40, min_samples_leaf=15, max_depth=13, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=40, min_samples_leaf=15, max_depth=13, criterion=entropy, class_weight=balanced, total=   0.6s\n",
      "[CV] min_samples_split=30, min_samples_leaf=39, max_depth=36, criterion=entropy, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=39, max_depth=36, criterion=entropy, class_weight={1: 0.67, 0: 0.33}, total=   2.1s\n",
      "[CV] min_samples_split=30, min_samples_leaf=39, max_depth=36, criterion=entropy, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=39, max_depth=36, criterion=entropy, class_weight={1: 0.67, 0: 0.33}, total=   2.3s\n",
      "[CV] min_samples_split=30, min_samples_leaf=39, max_depth=36, criterion=entropy, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=39, max_depth=36, criterion=entropy, class_weight={1: 0.67, 0: 0.33}, total=   2.3s\n",
      "[CV] min_samples_split=30, min_samples_leaf=39, max_depth=36, criterion=entropy, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=39, max_depth=36, criterion=entropy, class_weight={1: 0.67, 0: 0.33}, total=   2.3s\n",
      "[CV] min_samples_split=30, min_samples_leaf=40, max_depth=19, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=30, min_samples_leaf=40, max_depth=19, criterion=entropy, class_weight=balanced, total=   1.1s\n",
      "[CV] min_samples_split=30, min_samples_leaf=40, max_depth=19, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=30, min_samples_leaf=40, max_depth=19, criterion=entropy, class_weight=balanced, total=   1.2s\n",
      "[CV] min_samples_split=30, min_samples_leaf=40, max_depth=19, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=30, min_samples_leaf=40, max_depth=19, criterion=entropy, class_weight=balanced, total=   1.3s\n",
      "[CV] min_samples_split=30, min_samples_leaf=40, max_depth=19, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=30, min_samples_leaf=40, max_depth=19, criterion=entropy, class_weight=balanced, total=   1.2s\n",
      "[CV] min_samples_split=20, min_samples_leaf=43, max_depth=11, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=20, min_samples_leaf=43, max_depth=11, criterion=entropy, class_weight=balanced, total=   0.5s\n",
      "[CV] min_samples_split=20, min_samples_leaf=43, max_depth=11, criterion=entropy, class_weight=balanced \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_split=20, min_samples_leaf=43, max_depth=11, criterion=entropy, class_weight=balanced, total=   0.6s\n",
      "[CV] min_samples_split=20, min_samples_leaf=43, max_depth=11, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=20, min_samples_leaf=43, max_depth=11, criterion=entropy, class_weight=balanced, total=   0.6s\n",
      "[CV] min_samples_split=20, min_samples_leaf=43, max_depth=11, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=20, min_samples_leaf=43, max_depth=11, criterion=entropy, class_weight=balanced, total=   0.5s\n",
      "[CV] min_samples_split=20, min_samples_leaf=24, max_depth=40, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=20, min_samples_leaf=24, max_depth=40, criterion=entropy, class_weight=balanced, total=   2.4s\n",
      "[CV] min_samples_split=20, min_samples_leaf=24, max_depth=40, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=20, min_samples_leaf=24, max_depth=40, criterion=entropy, class_weight=balanced, total=   2.4s\n",
      "[CV] min_samples_split=20, min_samples_leaf=24, max_depth=40, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=20, min_samples_leaf=24, max_depth=40, criterion=entropy, class_weight=balanced, total=   2.4s\n",
      "[CV] min_samples_split=20, min_samples_leaf=24, max_depth=40, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=20, min_samples_leaf=24, max_depth=40, criterion=entropy, class_weight=balanced, total=   2.5s\n",
      "[CV] min_samples_split=50, min_samples_leaf=7, max_depth=36, criterion=entropy, class_weight=None \n",
      "[CV]  min_samples_split=50, min_samples_leaf=7, max_depth=36, criterion=entropy, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=50, min_samples_leaf=7, max_depth=36, criterion=entropy, class_weight=None \n",
      "[CV]  min_samples_split=50, min_samples_leaf=7, max_depth=36, criterion=entropy, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=50, min_samples_leaf=7, max_depth=36, criterion=entropy, class_weight=None \n",
      "[CV]  min_samples_split=50, min_samples_leaf=7, max_depth=36, criterion=entropy, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=50, min_samples_leaf=7, max_depth=36, criterion=entropy, class_weight=None \n",
      "[CV]  min_samples_split=50, min_samples_leaf=7, max_depth=36, criterion=entropy, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=40, min_samples_leaf=8, max_depth=27, criterion=entropy, class_weight={1: 0.67, 0: 0.33} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_split=40, min_samples_leaf=8, max_depth=27, criterion=entropy, class_weight={1: 0.67, 0: 0.33}, total=   1.6s\n",
      "[CV] min_samples_split=40, min_samples_leaf=8, max_depth=27, criterion=entropy, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  min_samples_split=40, min_samples_leaf=8, max_depth=27, criterion=entropy, class_weight={1: 0.67, 0: 0.33}, total=   1.9s\n",
      "[CV] min_samples_split=40, min_samples_leaf=8, max_depth=27, criterion=entropy, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  min_samples_split=40, min_samples_leaf=8, max_depth=27, criterion=entropy, class_weight={1: 0.67, 0: 0.33}, total=   2.0s\n",
      "[CV] min_samples_split=40, min_samples_leaf=8, max_depth=27, criterion=entropy, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  min_samples_split=40, min_samples_leaf=8, max_depth=27, criterion=entropy, class_weight={1: 0.67, 0: 0.33}, total=   2.1s\n",
      "[CV] min_samples_split=20, min_samples_leaf=44, max_depth=27, criterion=entropy, class_weight=None \n",
      "[CV]  min_samples_split=20, min_samples_leaf=44, max_depth=27, criterion=entropy, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=20, min_samples_leaf=44, max_depth=27, criterion=entropy, class_weight=None \n",
      "[CV]  min_samples_split=20, min_samples_leaf=44, max_depth=27, criterion=entropy, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=20, min_samples_leaf=44, max_depth=27, criterion=entropy, class_weight=None \n",
      "[CV]  min_samples_split=20, min_samples_leaf=44, max_depth=27, criterion=entropy, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=20, min_samples_leaf=44, max_depth=27, criterion=entropy, class_weight=None \n",
      "[CV]  min_samples_split=20, min_samples_leaf=44, max_depth=27, criterion=entropy, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=20, min_samples_leaf=13, max_depth=57, criterion=entropy, class_weight={1: 0.75, 0: 0.25} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_split=20, min_samples_leaf=13, max_depth=57, criterion=entropy, class_weight={1: 0.75, 0: 0.25}, total=   2.8s\n",
      "[CV] min_samples_split=20, min_samples_leaf=13, max_depth=57, criterion=entropy, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=20, min_samples_leaf=13, max_depth=57, criterion=entropy, class_weight={1: 0.75, 0: 0.25}, total=   2.7s\n",
      "[CV] min_samples_split=20, min_samples_leaf=13, max_depth=57, criterion=entropy, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=20, min_samples_leaf=13, max_depth=57, criterion=entropy, class_weight={1: 0.75, 0: 0.25}, total=   2.7s\n",
      "[CV] min_samples_split=20, min_samples_leaf=13, max_depth=57, criterion=entropy, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=20, min_samples_leaf=13, max_depth=57, criterion=entropy, class_weight={1: 0.75, 0: 0.25}, total=   2.8s\n",
      "[CV] min_samples_split=50, min_samples_leaf=39, max_depth=42, criterion=gini, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=50, min_samples_leaf=39, max_depth=42, criterion=gini, class_weight={1: 0.75, 0: 0.25}, total=   2.2s\n",
      "[CV] min_samples_split=50, min_samples_leaf=39, max_depth=42, criterion=gini, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=50, min_samples_leaf=39, max_depth=42, criterion=gini, class_weight={1: 0.75, 0: 0.25}, total=   2.0s\n",
      "[CV] min_samples_split=50, min_samples_leaf=39, max_depth=42, criterion=gini, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=50, min_samples_leaf=39, max_depth=42, criterion=gini, class_weight={1: 0.75, 0: 0.25}, total=   2.0s\n",
      "[CV] min_samples_split=50, min_samples_leaf=39, max_depth=42, criterion=gini, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=50, min_samples_leaf=39, max_depth=42, criterion=gini, class_weight={1: 0.75, 0: 0.25}, total=   2.1s\n",
      "[CV] min_samples_split=30, min_samples_leaf=32, max_depth=49, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=30, min_samples_leaf=32, max_depth=49, criterion=entropy, class_weight=balanced, total=   2.4s\n",
      "[CV] min_samples_split=30, min_samples_leaf=32, max_depth=49, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=30, min_samples_leaf=32, max_depth=49, criterion=entropy, class_weight=balanced, total=   2.4s\n",
      "[CV] min_samples_split=30, min_samples_leaf=32, max_depth=49, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=30, min_samples_leaf=32, max_depth=49, criterion=entropy, class_weight=balanced, total=   2.3s\n",
      "[CV] min_samples_split=30, min_samples_leaf=32, max_depth=49, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=30, min_samples_leaf=32, max_depth=49, criterion=entropy, class_weight=balanced, total=   2.4s\n",
      "[CV] min_samples_split=10, min_samples_leaf=9, max_depth=38, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=10, min_samples_leaf=9, max_depth=38, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   2.5s\n",
      "[CV] min_samples_split=10, min_samples_leaf=9, max_depth=38, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=10, min_samples_leaf=9, max_depth=38, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   2.7s\n",
      "[CV] min_samples_split=10, min_samples_leaf=9, max_depth=38, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=10, min_samples_leaf=9, max_depth=38, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   2.8s\n",
      "[CV] min_samples_split=10, min_samples_leaf=9, max_depth=38, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=10, min_samples_leaf=9, max_depth=38, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   2.7s\n",
      "[CV] min_samples_split=30, min_samples_leaf=9, max_depth=33, criterion=gini, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=9, max_depth=33, criterion=gini, class_weight={1: 0.8, 0: 0.2}, total=   2.5s\n",
      "[CV] min_samples_split=30, min_samples_leaf=9, max_depth=33, criterion=gini, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=9, max_depth=33, criterion=gini, class_weight={1: 0.8, 0: 0.2}, total=   2.4s\n",
      "[CV] min_samples_split=30, min_samples_leaf=9, max_depth=33, criterion=gini, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=9, max_depth=33, criterion=gini, class_weight={1: 0.8, 0: 0.2}, total=   2.4s\n",
      "[CV] min_samples_split=30, min_samples_leaf=9, max_depth=33, criterion=gini, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=9, max_depth=33, criterion=gini, class_weight={1: 0.8, 0: 0.2}, total=   2.5s\n",
      "[CV] min_samples_split=30, min_samples_leaf=36, max_depth=30, criterion=entropy, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=36, max_depth=30, criterion=entropy, class_weight={1: 0.67, 0: 0.33}, total=   1.9s\n",
      "[CV] min_samples_split=30, min_samples_leaf=36, max_depth=30, criterion=entropy, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=36, max_depth=30, criterion=entropy, class_weight={1: 0.67, 0: 0.33}, total=   2.1s\n",
      "[CV] min_samples_split=30, min_samples_leaf=36, max_depth=30, criterion=entropy, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=36, max_depth=30, criterion=entropy, class_weight={1: 0.67, 0: 0.33}, total=   2.2s\n",
      "[CV] min_samples_split=30, min_samples_leaf=36, max_depth=30, criterion=entropy, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=36, max_depth=30, criterion=entropy, class_weight={1: 0.67, 0: 0.33}, total=   2.2s\n",
      "[CV] min_samples_split=40, min_samples_leaf=38, max_depth=25, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=40, min_samples_leaf=38, max_depth=25, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   1.6s\n",
      "[CV] min_samples_split=40, min_samples_leaf=38, max_depth=25, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=40, min_samples_leaf=38, max_depth=25, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   1.6s\n",
      "[CV] min_samples_split=40, min_samples_leaf=38, max_depth=25, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=40, min_samples_leaf=38, max_depth=25, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   1.8s\n",
      "[CV] min_samples_split=40, min_samples_leaf=38, max_depth=25, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=40, min_samples_leaf=38, max_depth=25, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   1.8s\n",
      "[CV] min_samples_split=30, min_samples_leaf=26, max_depth=49, criterion=gini, class_weight=None \n",
      "[CV]  min_samples_split=30, min_samples_leaf=26, max_depth=49, criterion=gini, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=30, min_samples_leaf=26, max_depth=49, criterion=gini, class_weight=None \n",
      "[CV]  min_samples_split=30, min_samples_leaf=26, max_depth=49, criterion=gini, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=30, min_samples_leaf=26, max_depth=49, criterion=gini, class_weight=None \n",
      "[CV]  min_samples_split=30, min_samples_leaf=26, max_depth=49, criterion=gini, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=30, min_samples_leaf=26, max_depth=49, criterion=gini, class_weight=None \n",
      "[CV]  min_samples_split=30, min_samples_leaf=26, max_depth=49, criterion=gini, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=10, min_samples_leaf=26, max_depth=38, criterion=gini, class_weight=None \n",
      "[CV]  min_samples_split=10, min_samples_leaf=26, max_depth=38, criterion=gini, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=10, min_samples_leaf=26, max_depth=38, criterion=gini, class_weight=None \n",
      "[CV]  min_samples_split=10, min_samples_leaf=26, max_depth=38, criterion=gini, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=10, min_samples_leaf=26, max_depth=38, criterion=gini, class_weight=None \n",
      "[CV]  min_samples_split=10, min_samples_leaf=26, max_depth=38, criterion=gini, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=10, min_samples_leaf=26, max_depth=38, criterion=gini, class_weight=None \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_split=10, min_samples_leaf=26, max_depth=38, criterion=gini, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=10, min_samples_leaf=22, max_depth=36, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=10, min_samples_leaf=22, max_depth=36, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   2.3s\n",
      "[CV] min_samples_split=10, min_samples_leaf=22, max_depth=36, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=10, min_samples_leaf=22, max_depth=36, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   2.3s\n",
      "[CV] min_samples_split=10, min_samples_leaf=22, max_depth=36, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=10, min_samples_leaf=22, max_depth=36, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   2.6s\n",
      "[CV] min_samples_split=10, min_samples_leaf=22, max_depth=36, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=10, min_samples_leaf=22, max_depth=36, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   2.5s\n",
      "[CV] min_samples_split=40, min_samples_leaf=43, max_depth=43, criterion=entropy, class_weight=None \n",
      "[CV]  min_samples_split=40, min_samples_leaf=43, max_depth=43, criterion=entropy, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=40, min_samples_leaf=43, max_depth=43, criterion=entropy, class_weight=None \n",
      "[CV]  min_samples_split=40, min_samples_leaf=43, max_depth=43, criterion=entropy, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=40, min_samples_leaf=43, max_depth=43, criterion=entropy, class_weight=None \n",
      "[CV]  min_samples_split=40, min_samples_leaf=43, max_depth=43, criterion=entropy, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=40, min_samples_leaf=43, max_depth=43, criterion=entropy, class_weight=None \n",
      "[CV]  min_samples_split=40, min_samples_leaf=43, max_depth=43, criterion=entropy, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=20, min_samples_leaf=27, max_depth=41, criterion=entropy, class_weight={1: 0.75, 0: 0.25} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_split=20, min_samples_leaf=27, max_depth=41, criterion=entropy, class_weight={1: 0.75, 0: 0.25}, total=   2.4s\n",
      "[CV] min_samples_split=20, min_samples_leaf=27, max_depth=41, criterion=entropy, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=20, min_samples_leaf=27, max_depth=41, criterion=entropy, class_weight={1: 0.75, 0: 0.25}, total=   2.3s\n",
      "[CV] min_samples_split=20, min_samples_leaf=27, max_depth=41, criterion=entropy, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=20, min_samples_leaf=27, max_depth=41, criterion=entropy, class_weight={1: 0.75, 0: 0.25}, total=   2.3s\n",
      "[CV] min_samples_split=20, min_samples_leaf=27, max_depth=41, criterion=entropy, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=20, min_samples_leaf=27, max_depth=41, criterion=entropy, class_weight={1: 0.75, 0: 0.25}, total=   2.6s\n",
      "[CV] min_samples_split=40, min_samples_leaf=17, max_depth=38, criterion=entropy, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  min_samples_split=40, min_samples_leaf=17, max_depth=38, criterion=entropy, class_weight={1: 0.67, 0: 0.33}, total=   2.4s\n",
      "[CV] min_samples_split=40, min_samples_leaf=17, max_depth=38, criterion=entropy, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  min_samples_split=40, min_samples_leaf=17, max_depth=38, criterion=entropy, class_weight={1: 0.67, 0: 0.33}, total=   2.5s\n",
      "[CV] min_samples_split=40, min_samples_leaf=17, max_depth=38, criterion=entropy, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  min_samples_split=40, min_samples_leaf=17, max_depth=38, criterion=entropy, class_weight={1: 0.67, 0: 0.33}, total=   2.6s\n",
      "[CV] min_samples_split=40, min_samples_leaf=17, max_depth=38, criterion=entropy, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  min_samples_split=40, min_samples_leaf=17, max_depth=38, criterion=entropy, class_weight={1: 0.67, 0: 0.33}, total=   2.6s\n",
      "[CV] min_samples_split=10, min_samples_leaf=25, max_depth=52, criterion=gini, class_weight=balanced \n",
      "[CV]  min_samples_split=10, min_samples_leaf=25, max_depth=52, criterion=gini, class_weight=balanced, total=   2.3s\n",
      "[CV] min_samples_split=10, min_samples_leaf=25, max_depth=52, criterion=gini, class_weight=balanced \n",
      "[CV]  min_samples_split=10, min_samples_leaf=25, max_depth=52, criterion=gini, class_weight=balanced, total=   2.1s\n",
      "[CV] min_samples_split=10, min_samples_leaf=25, max_depth=52, criterion=gini, class_weight=balanced \n",
      "[CV]  min_samples_split=10, min_samples_leaf=25, max_depth=52, criterion=gini, class_weight=balanced, total=   2.2s\n",
      "[CV] min_samples_split=10, min_samples_leaf=25, max_depth=52, criterion=gini, class_weight=balanced \n",
      "[CV]  min_samples_split=10, min_samples_leaf=25, max_depth=52, criterion=gini, class_weight=balanced, total=   2.2s\n",
      "[CV] min_samples_split=50, min_samples_leaf=31, max_depth=17, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=50, min_samples_leaf=31, max_depth=17, criterion=entropy, class_weight=balanced, total=   0.9s\n",
      "[CV] min_samples_split=50, min_samples_leaf=31, max_depth=17, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=50, min_samples_leaf=31, max_depth=17, criterion=entropy, class_weight=balanced, total=   1.0s\n",
      "[CV] min_samples_split=50, min_samples_leaf=31, max_depth=17, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=50, min_samples_leaf=31, max_depth=17, criterion=entropy, class_weight=balanced, total=   1.1s\n",
      "[CV] min_samples_split=50, min_samples_leaf=31, max_depth=17, criterion=entropy, class_weight=balanced \n",
      "[CV]  min_samples_split=50, min_samples_leaf=31, max_depth=17, criterion=entropy, class_weight=balanced, total=   1.0s\n",
      "[CV] min_samples_split=30, min_samples_leaf=48, max_depth=25, criterion=gini, class_weight=None \n",
      "[CV]  min_samples_split=30, min_samples_leaf=48, max_depth=25, criterion=gini, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=30, min_samples_leaf=48, max_depth=25, criterion=gini, class_weight=None \n",
      "[CV]  min_samples_split=30, min_samples_leaf=48, max_depth=25, criterion=gini, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=30, min_samples_leaf=48, max_depth=25, criterion=gini, class_weight=None \n",
      "[CV]  min_samples_split=30, min_samples_leaf=48, max_depth=25, criterion=gini, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=30, min_samples_leaf=48, max_depth=25, criterion=gini, class_weight=None \n",
      "[CV]  min_samples_split=30, min_samples_leaf=48, max_depth=25, criterion=gini, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=30, min_samples_leaf=5, max_depth=33, criterion=gini, class_weight={1: 0.8, 0: 0.2} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_split=30, min_samples_leaf=5, max_depth=33, criterion=gini, class_weight={1: 0.8, 0: 0.2}, total=   2.6s\n",
      "[CV] min_samples_split=30, min_samples_leaf=5, max_depth=33, criterion=gini, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=5, max_depth=33, criterion=gini, class_weight={1: 0.8, 0: 0.2}, total=   2.4s\n",
      "[CV] min_samples_split=30, min_samples_leaf=5, max_depth=33, criterion=gini, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=5, max_depth=33, criterion=gini, class_weight={1: 0.8, 0: 0.2}, total=   2.4s\n",
      "[CV] min_samples_split=30, min_samples_leaf=5, max_depth=33, criterion=gini, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=5, max_depth=33, criterion=gini, class_weight={1: 0.8, 0: 0.2}, total=   2.6s\n",
      "[CV] min_samples_split=30, min_samples_leaf=30, max_depth=52, criterion=gini, class_weight=balanced \n",
      "[CV]  min_samples_split=30, min_samples_leaf=30, max_depth=52, criterion=gini, class_weight=balanced, total=   2.3s\n",
      "[CV] min_samples_split=30, min_samples_leaf=30, max_depth=52, criterion=gini, class_weight=balanced \n",
      "[CV]  min_samples_split=30, min_samples_leaf=30, max_depth=52, criterion=gini, class_weight=balanced, total=   2.0s\n",
      "[CV] min_samples_split=30, min_samples_leaf=30, max_depth=52, criterion=gini, class_weight=balanced \n",
      "[CV]  min_samples_split=30, min_samples_leaf=30, max_depth=52, criterion=gini, class_weight=balanced, total=   2.2s\n",
      "[CV] min_samples_split=30, min_samples_leaf=30, max_depth=52, criterion=gini, class_weight=balanced \n",
      "[CV]  min_samples_split=30, min_samples_leaf=30, max_depth=52, criterion=gini, class_weight=balanced, total=   2.4s\n",
      "[CV] min_samples_split=40, min_samples_leaf=47, max_depth=45, criterion=entropy, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=40, min_samples_leaf=47, max_depth=45, criterion=entropy, class_weight={1: 0.75, 0: 0.25}, total=   2.3s\n",
      "[CV] min_samples_split=40, min_samples_leaf=47, max_depth=45, criterion=entropy, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=40, min_samples_leaf=47, max_depth=45, criterion=entropy, class_weight={1: 0.75, 0: 0.25}, total=   2.2s\n",
      "[CV] min_samples_split=40, min_samples_leaf=47, max_depth=45, criterion=entropy, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=40, min_samples_leaf=47, max_depth=45, criterion=entropy, class_weight={1: 0.75, 0: 0.25}, total=   2.1s\n",
      "[CV] min_samples_split=40, min_samples_leaf=47, max_depth=45, criterion=entropy, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=40, min_samples_leaf=47, max_depth=45, criterion=entropy, class_weight={1: 0.75, 0: 0.25}, total=   2.2s\n",
      "[CV] min_samples_split=40, min_samples_leaf=33, max_depth=23, criterion=gini, class_weight=None \n",
      "[CV]  min_samples_split=40, min_samples_leaf=33, max_depth=23, criterion=gini, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=40, min_samples_leaf=33, max_depth=23, criterion=gini, class_weight=None \n",
      "[CV]  min_samples_split=40, min_samples_leaf=33, max_depth=23, criterion=gini, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=40, min_samples_leaf=33, max_depth=23, criterion=gini, class_weight=None \n",
      "[CV]  min_samples_split=40, min_samples_leaf=33, max_depth=23, criterion=gini, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=40, min_samples_leaf=33, max_depth=23, criterion=gini, class_weight=None \n",
      "[CV]  min_samples_split=40, min_samples_leaf=33, max_depth=23, criterion=gini, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=30, min_samples_leaf=13, max_depth=20, criterion=gini, class_weight={1: 0.8, 0: 0.2} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  min_samples_split=30, min_samples_leaf=13, max_depth=20, criterion=gini, class_weight={1: 0.8, 0: 0.2}, total=   1.1s\n",
      "[CV] min_samples_split=30, min_samples_leaf=13, max_depth=20, criterion=gini, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=13, max_depth=20, criterion=gini, class_weight={1: 0.8, 0: 0.2}, total=   1.3s\n",
      "[CV] min_samples_split=30, min_samples_leaf=13, max_depth=20, criterion=gini, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=13, max_depth=20, criterion=gini, class_weight={1: 0.8, 0: 0.2}, total=   1.3s\n",
      "[CV] min_samples_split=30, min_samples_leaf=13, max_depth=20, criterion=gini, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=13, max_depth=20, criterion=gini, class_weight={1: 0.8, 0: 0.2}, total=   1.5s\n",
      "[CV] min_samples_split=40, min_samples_leaf=11, max_depth=40, criterion=entropy, class_weight=None \n",
      "[CV]  min_samples_split=40, min_samples_leaf=11, max_depth=40, criterion=entropy, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=40, min_samples_leaf=11, max_depth=40, criterion=entropy, class_weight=None \n",
      "[CV]  min_samples_split=40, min_samples_leaf=11, max_depth=40, criterion=entropy, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=40, min_samples_leaf=11, max_depth=40, criterion=entropy, class_weight=None \n",
      "[CV]  min_samples_split=40, min_samples_leaf=11, max_depth=40, criterion=entropy, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=40, min_samples_leaf=11, max_depth=40, criterion=entropy, class_weight=None \n",
      "[CV]  min_samples_split=40, min_samples_leaf=11, max_depth=40, criterion=entropy, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=10, min_samples_leaf=16, max_depth=59, criterion=gini, class_weight=None \n",
      "[CV]  min_samples_split=10, min_samples_leaf=16, max_depth=59, criterion=gini, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=10, min_samples_leaf=16, max_depth=59, criterion=gini, class_weight=None \n",
      "[CV]  min_samples_split=10, min_samples_leaf=16, max_depth=59, criterion=gini, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=10, min_samples_leaf=16, max_depth=59, criterion=gini, class_weight=None \n",
      "[CV]  min_samples_split=10, min_samples_leaf=16, max_depth=59, criterion=gini, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=10, min_samples_leaf=16, max_depth=59, criterion=gini, class_weight=None \n",
      "[CV]  min_samples_split=10, min_samples_leaf=16, max_depth=59, criterion=gini, class_weight=None, total=   0.0s\n",
      "[CV] min_samples_split=30, min_samples_leaf=25, max_depth=54, criterion=entropy, class_weight={1: 0.8, 0: 0.2} "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 890, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    expanded_class_weight = compute_sample_weight(\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/class_weight.py\", line 122, in compute_sample_weight\n",
      "    raise ValueError('The only valid preset for class_weight is '\n",
      "ValueError: The only valid preset for class_weight is \"balanced\". Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  min_samples_split=30, min_samples_leaf=25, max_depth=54, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   2.6s\n",
      "[CV] min_samples_split=30, min_samples_leaf=25, max_depth=54, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=25, max_depth=54, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   2.5s\n",
      "[CV] min_samples_split=30, min_samples_leaf=25, max_depth=54, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=25, max_depth=54, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   2.5s\n",
      "[CV] min_samples_split=30, min_samples_leaf=25, max_depth=54, criterion=entropy, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=25, max_depth=54, criterion=entropy, class_weight={1: 0.8, 0: 0.2}, total=   2.5s\n",
      "[CV] min_samples_split=40, min_samples_leaf=45, max_depth=42, criterion=gini, class_weight=balanced \n",
      "[CV]  min_samples_split=40, min_samples_leaf=45, max_depth=42, criterion=gini, class_weight=balanced, total=   2.0s\n",
      "[CV] min_samples_split=40, min_samples_leaf=45, max_depth=42, criterion=gini, class_weight=balanced \n",
      "[CV]  min_samples_split=40, min_samples_leaf=45, max_depth=42, criterion=gini, class_weight=balanced, total=   1.9s\n",
      "[CV] min_samples_split=40, min_samples_leaf=45, max_depth=42, criterion=gini, class_weight=balanced \n",
      "[CV]  min_samples_split=40, min_samples_leaf=45, max_depth=42, criterion=gini, class_weight=balanced, total=   1.9s\n",
      "[CV] min_samples_split=40, min_samples_leaf=45, max_depth=42, criterion=gini, class_weight=balanced \n",
      "[CV]  min_samples_split=40, min_samples_leaf=45, max_depth=42, criterion=gini, class_weight=balanced, total=   2.0s\n",
      "[CV] min_samples_split=20, min_samples_leaf=25, max_depth=52, criterion=gini, class_weight=balanced \n",
      "[CV]  min_samples_split=20, min_samples_leaf=25, max_depth=52, criterion=gini, class_weight=balanced, total=   2.3s\n",
      "[CV] min_samples_split=20, min_samples_leaf=25, max_depth=52, criterion=gini, class_weight=balanced \n",
      "[CV]  min_samples_split=20, min_samples_leaf=25, max_depth=52, criterion=gini, class_weight=balanced, total=   2.1s\n",
      "[CV] min_samples_split=20, min_samples_leaf=25, max_depth=52, criterion=gini, class_weight=balanced \n",
      "[CV]  min_samples_split=20, min_samples_leaf=25, max_depth=52, criterion=gini, class_weight=balanced, total=   2.1s\n",
      "[CV] min_samples_split=20, min_samples_leaf=25, max_depth=52, criterion=gini, class_weight=balanced \n",
      "[CV]  min_samples_split=20, min_samples_leaf=25, max_depth=52, criterion=gini, class_weight=balanced, total=   2.2s\n",
      "[CV] min_samples_split=30, min_samples_leaf=42, max_depth=33, criterion=gini, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=42, max_depth=33, criterion=gini, class_weight={1: 0.75, 0: 0.25}, total=   2.0s\n",
      "[CV] min_samples_split=30, min_samples_leaf=42, max_depth=33, criterion=gini, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=42, max_depth=33, criterion=gini, class_weight={1: 0.75, 0: 0.25}, total=   1.9s\n",
      "[CV] min_samples_split=30, min_samples_leaf=42, max_depth=33, criterion=gini, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=42, max_depth=33, criterion=gini, class_weight={1: 0.75, 0: 0.25}, total=   1.9s\n",
      "[CV] min_samples_split=30, min_samples_leaf=42, max_depth=33, criterion=gini, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  min_samples_split=30, min_samples_leaf=42, max_depth=33, criterion=gini, class_weight={1: 0.75, 0: 0.25}, total=   2.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 200 out of 200 | elapsed:  5.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=4, random_state=0, shuffle=True),\n",
       "                   estimator=DecisionTreeClassifier(), n_iter=50,\n",
       "                   param_distributions={'class_weight': [{0: 0.33, 1: 0.67},\n",
       "                                                         {0: 0.25, 1: 0.75},\n",
       "                                                         {0: 0.2, 1: 0.8},\n",
       "                                                         'None', 'balanced'],\n",
       "                                        'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': range(5, 60),\n",
       "                                        'min_samples_leaf': range(5, 50),\n",
       "                                        'min_samples_split': [10, 20, 30, 40,\n",
       "                                                              50]},\n",
       "                   scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold = StratifiedKFold(n_splits=4, shuffle=True, random_state=0) \n",
    "\n",
    "parameters= {\"criterion\": [\"gini\", \"entropy\"], \\\n",
    "             \"class_weight\": [{1:0.67, 0:0.33}, {1:0.75, 0:0.25}, {1:0.8, 0:0.2}, \"None\", \"balanced\"], \\\n",
    "            \"max_depth\": range(5,60) , \\\n",
    "            \"min_samples_leaf\" : range(5,50), \\\n",
    "            \"min_samples_split\" : [10, 20, 30, 40, 50]}\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model_rs =RandomizedSearchCV(model, parameters, cv= fold, verbose=2, scoring=\"f1\", n_iter=50)\n",
    "model_rs.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'min_samples_split': 50, 'min_samples_leaf': 37, 'max_depth': 37, 'criterion': 'gini', 'class_weight': {1: 0.67, 0: 0.33}}\n",
      "accuracy : 0.6875005149417299\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",model_rs.best_params_)\n",
    "print(\"accuracy :\",model_rs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dt_clf_rs = model_rs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores for default model on test set\n",
      "\n",
      "Accuracy Score : 0.9484728374912567\n",
      "Precision Score : 0.8011853448275862\n",
      "Recall Score : 0.6084288052373159\n",
      "F1 Score : 0.6916279069767441\n",
      "\n",
      "\n",
      "scores for default model on train set\n",
      "\n",
      "Accuracy Score : 0.9531845029921505\n",
      "Precision Score : 0.8426655606249136\n",
      "Recall Score : 0.6234656301145662\n",
      "F1 Score : 0.7166794050208712\n"
     ]
    }
   ],
   "source": [
    "print_scores(dt_clf_rs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_confusion_matrix(dt_clf_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n",
      "[CV] n_estimators=50, min_samples_split=20, min_samples_leaf=7, max_depth=48, criterion=entropy, class_weight=balanced \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=50, min_samples_split=20, min_samples_leaf=7, max_depth=48, criterion=entropy, class_weight=balanced, total=  15.7s\n",
      "[CV] n_estimators=50, min_samples_split=20, min_samples_leaf=7, max_depth=48, criterion=entropy, class_weight=balanced \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   15.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=50, min_samples_split=20, min_samples_leaf=7, max_depth=48, criterion=entropy, class_weight=balanced, total=  15.1s\n",
      "[CV] n_estimators=50, min_samples_split=20, min_samples_leaf=7, max_depth=48, criterion=entropy, class_weight=balanced \n",
      "[CV]  n_estimators=50, min_samples_split=20, min_samples_leaf=7, max_depth=48, criterion=entropy, class_weight=balanced, total=  16.6s\n",
      "[CV] n_estimators=50, min_samples_split=20, min_samples_leaf=7, max_depth=48, criterion=entropy, class_weight=balanced \n",
      "[CV]  n_estimators=50, min_samples_split=20, min_samples_leaf=7, max_depth=48, criterion=entropy, class_weight=balanced, total=  17.3s\n",
      "[CV] n_estimators=50, min_samples_split=20, min_samples_leaf=28, max_depth=27, criterion=gini, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  n_estimators=50, min_samples_split=20, min_samples_leaf=28, max_depth=27, criterion=gini, class_weight={1: 0.75, 0: 0.25}, total=   8.3s\n",
      "[CV] n_estimators=50, min_samples_split=20, min_samples_leaf=28, max_depth=27, criterion=gini, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  n_estimators=50, min_samples_split=20, min_samples_leaf=28, max_depth=27, criterion=gini, class_weight={1: 0.75, 0: 0.25}, total=   7.2s\n",
      "[CV] n_estimators=50, min_samples_split=20, min_samples_leaf=28, max_depth=27, criterion=gini, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  n_estimators=50, min_samples_split=20, min_samples_leaf=28, max_depth=27, criterion=gini, class_weight={1: 0.75, 0: 0.25}, total=   9.2s\n",
      "[CV] n_estimators=50, min_samples_split=20, min_samples_leaf=28, max_depth=27, criterion=gini, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  n_estimators=50, min_samples_split=20, min_samples_leaf=28, max_depth=27, criterion=gini, class_weight={1: 0.75, 0: 0.25}, total=   8.7s\n",
      "[CV] n_estimators=200, min_samples_split=20, min_samples_leaf=37, max_depth=25, criterion=entropy, class_weight=None \n",
      "[CV]  n_estimators=200, min_samples_split=20, min_samples_leaf=37, max_depth=25, criterion=entropy, class_weight=None, total=   0.0s\n",
      "[CV] n_estimators=200, min_samples_split=20, min_samples_leaf=37, max_depth=25, criterion=entropy, class_weight=None \n",
      "[CV]  n_estimators=200, min_samples_split=20, min_samples_leaf=37, max_depth=25, criterion=entropy, class_weight=None, total=   0.0s\n",
      "[CV] n_estimators=200, min_samples_split=20, min_samples_leaf=37, max_depth=25, criterion=entropy, class_weight=None \n",
      "[CV]  n_estimators=200, min_samples_split=20, min_samples_leaf=37, max_depth=25, criterion=entropy, class_weight=None, total=   0.0s\n",
      "[CV] n_estimators=200, min_samples_split=20, min_samples_leaf=37, max_depth=25, criterion=entropy, class_weight=None \n",
      "[CV]  n_estimators=200, min_samples_split=20, min_samples_leaf=37, max_depth=25, criterion=entropy, class_weight=None, total=   0.0s\n",
      "[CV] n_estimators=400, min_samples_split=50, min_samples_leaf=49, max_depth=22, criterion=gini, class_weight=None \n",
      "[CV]  n_estimators=400, min_samples_split=50, min_samples_leaf=49, max_depth=22, criterion=gini, class_weight=None, total=   0.0s\n",
      "[CV] n_estimators=400, min_samples_split=50, min_samples_leaf=49, max_depth=22, criterion=gini, class_weight=None \n",
      "[CV]  n_estimators=400, min_samples_split=50, min_samples_leaf=49, max_depth=22, criterion=gini, class_weight=None, total=   0.0s\n",
      "[CV] n_estimators=400, min_samples_split=50, min_samples_leaf=49, max_depth=22, criterion=gini, class_weight=None \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 330, in fit\n",
      "    y, expanded_class_weight = self._validate_y_class_weight(y)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 581, in _validate_y_class_weight\n",
      "    raise ValueError('Valid presets for class_weight include '\n",
      "ValueError: Valid presets for class_weight include \"balanced\" and \"balanced_subsample\".Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 330, in fit\n",
      "    y, expanded_class_weight = self._validate_y_class_weight(y)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 581, in _validate_y_class_weight\n",
      "    raise ValueError('Valid presets for class_weight include '\n",
      "ValueError: Valid presets for class_weight include \"balanced\" and \"balanced_subsample\".Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 330, in fit\n",
      "    y, expanded_class_weight = self._validate_y_class_weight(y)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 581, in _validate_y_class_weight\n",
      "    raise ValueError('Valid presets for class_weight include '\n",
      "ValueError: Valid presets for class_weight include \"balanced\" and \"balanced_subsample\".Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 330, in fit\n",
      "    y, expanded_class_weight = self._validate_y_class_weight(y)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 581, in _validate_y_class_weight\n",
      "    raise ValueError('Valid presets for class_weight include '\n",
      "ValueError: Valid presets for class_weight include \"balanced\" and \"balanced_subsample\".Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 330, in fit\n",
      "    y, expanded_class_weight = self._validate_y_class_weight(y)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 581, in _validate_y_class_weight\n",
      "    raise ValueError('Valid presets for class_weight include '\n",
      "ValueError: Valid presets for class_weight include \"balanced\" and \"balanced_subsample\".Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 330, in fit\n",
      "    y, expanded_class_weight = self._validate_y_class_weight(y)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 581, in _validate_y_class_weight\n",
      "    raise ValueError('Valid presets for class_weight include '\n",
      "ValueError: Valid presets for class_weight include \"balanced\" and \"balanced_subsample\".Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 330, in fit\n",
      "    y, expanded_class_weight = self._validate_y_class_weight(y)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 581, in _validate_y_class_weight\n",
      "    raise ValueError('Valid presets for class_weight include '\n",
      "ValueError: Valid presets for class_weight include \"balanced\" and \"balanced_subsample\".Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=400, min_samples_split=50, min_samples_leaf=49, max_depth=22, criterion=gini, class_weight=None, total=   0.0s\n",
      "[CV] n_estimators=400, min_samples_split=50, min_samples_leaf=49, max_depth=22, criterion=gini, class_weight=None \n",
      "[CV]  n_estimators=400, min_samples_split=50, min_samples_leaf=49, max_depth=22, criterion=gini, class_weight=None, total=   0.0s\n",
      "[CV] n_estimators=200, min_samples_split=30, min_samples_leaf=37, max_depth=14, criterion=gini, class_weight={1: 0.8, 0: 0.2} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 330, in fit\n",
      "    y, expanded_class_weight = self._validate_y_class_weight(y)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 581, in _validate_y_class_weight\n",
      "    raise ValueError('Valid presets for class_weight include '\n",
      "ValueError: Valid presets for class_weight include \"balanced\" and \"balanced_subsample\".Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=200, min_samples_split=30, min_samples_leaf=37, max_depth=14, criterion=gini, class_weight={1: 0.8, 0: 0.2}, total=  17.9s\n",
      "[CV] n_estimators=200, min_samples_split=30, min_samples_leaf=37, max_depth=14, criterion=gini, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  n_estimators=200, min_samples_split=30, min_samples_leaf=37, max_depth=14, criterion=gini, class_weight={1: 0.8, 0: 0.2}, total=  19.0s\n",
      "[CV] n_estimators=200, min_samples_split=30, min_samples_leaf=37, max_depth=14, criterion=gini, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  n_estimators=200, min_samples_split=30, min_samples_leaf=37, max_depth=14, criterion=gini, class_weight={1: 0.8, 0: 0.2}, total=  15.3s\n",
      "[CV] n_estimators=200, min_samples_split=30, min_samples_leaf=37, max_depth=14, criterion=gini, class_weight={1: 0.8, 0: 0.2} \n",
      "[CV]  n_estimators=200, min_samples_split=30, min_samples_leaf=37, max_depth=14, criterion=gini, class_weight={1: 0.8, 0: 0.2}, total=  14.1s\n",
      "[CV] n_estimators=400, min_samples_split=40, min_samples_leaf=23, max_depth=21, criterion=gini, class_weight=balanced \n",
      "[CV]  n_estimators=400, min_samples_split=40, min_samples_leaf=23, max_depth=21, criterion=gini, class_weight=balanced, total=  47.9s\n",
      "[CV] n_estimators=400, min_samples_split=40, min_samples_leaf=23, max_depth=21, criterion=gini, class_weight=balanced \n",
      "[CV]  n_estimators=400, min_samples_split=40, min_samples_leaf=23, max_depth=21, criterion=gini, class_weight=balanced, total=  47.7s\n",
      "[CV] n_estimators=400, min_samples_split=40, min_samples_leaf=23, max_depth=21, criterion=gini, class_weight=balanced \n",
      "[CV]  n_estimators=400, min_samples_split=40, min_samples_leaf=23, max_depth=21, criterion=gini, class_weight=balanced, total=  49.4s\n",
      "[CV] n_estimators=400, min_samples_split=40, min_samples_leaf=23, max_depth=21, criterion=gini, class_weight=balanced \n",
      "[CV]  n_estimators=400, min_samples_split=40, min_samples_leaf=23, max_depth=21, criterion=gini, class_weight=balanced, total=  46.4s\n",
      "[CV] n_estimators=300, min_samples_split=40, min_samples_leaf=25, max_depth=25, criterion=gini, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  n_estimators=300, min_samples_split=40, min_samples_leaf=25, max_depth=25, criterion=gini, class_weight={1: 0.67, 0: 0.33}, total=  44.9s\n",
      "[CV] n_estimators=300, min_samples_split=40, min_samples_leaf=25, max_depth=25, criterion=gini, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  n_estimators=300, min_samples_split=40, min_samples_leaf=25, max_depth=25, criterion=gini, class_weight={1: 0.67, 0: 0.33}, total=  45.1s\n",
      "[CV] n_estimators=300, min_samples_split=40, min_samples_leaf=25, max_depth=25, criterion=gini, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  n_estimators=300, min_samples_split=40, min_samples_leaf=25, max_depth=25, criterion=gini, class_weight={1: 0.67, 0: 0.33}, total=  53.1s\n",
      "[CV] n_estimators=300, min_samples_split=40, min_samples_leaf=25, max_depth=25, criterion=gini, class_weight={1: 0.67, 0: 0.33} \n",
      "[CV]  n_estimators=300, min_samples_split=40, min_samples_leaf=25, max_depth=25, criterion=gini, class_weight={1: 0.67, 0: 0.33}, total=  53.5s\n",
      "[CV] n_estimators=50, min_samples_split=30, min_samples_leaf=39, max_depth=57, criterion=entropy, class_weight=None \n",
      "[CV]  n_estimators=50, min_samples_split=30, min_samples_leaf=39, max_depth=57, criterion=entropy, class_weight=None, total=   0.0s\n",
      "[CV] n_estimators=50, min_samples_split=30, min_samples_leaf=39, max_depth=57, criterion=entropy, class_weight=None \n",
      "[CV]  n_estimators=50, min_samples_split=30, min_samples_leaf=39, max_depth=57, criterion=entropy, class_weight=None, total=   0.0s\n",
      "[CV] n_estimators=50, min_samples_split=30, min_samples_leaf=39, max_depth=57, criterion=entropy, class_weight=None \n",
      "[CV]  n_estimators=50, min_samples_split=30, min_samples_leaf=39, max_depth=57, criterion=entropy, class_weight=None, total=   0.0s\n",
      "[CV] n_estimators=50, min_samples_split=30, min_samples_leaf=39, max_depth=57, criterion=entropy, class_weight=None \n",
      "[CV]  n_estimators=50, min_samples_split=30, min_samples_leaf=39, max_depth=57, criterion=entropy, class_weight=None, total=   0.0s\n",
      "[CV] n_estimators=100, min_samples_split=50, min_samples_leaf=27, max_depth=48, criterion=gini, class_weight={1: 0.75, 0: 0.25} \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 330, in fit\n",
      "    y, expanded_class_weight = self._validate_y_class_weight(y)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 581, in _validate_y_class_weight\n",
      "    raise ValueError('Valid presets for class_weight include '\n",
      "ValueError: Valid presets for class_weight include \"balanced\" and \"balanced_subsample\".Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 330, in fit\n",
      "    y, expanded_class_weight = self._validate_y_class_weight(y)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 581, in _validate_y_class_weight\n",
      "    raise ValueError('Valid presets for class_weight include '\n",
      "ValueError: Valid presets for class_weight include \"balanced\" and \"balanced_subsample\".Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 330, in fit\n",
      "    y, expanded_class_weight = self._validate_y_class_weight(y)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 581, in _validate_y_class_weight\n",
      "    raise ValueError('Valid presets for class_weight include '\n",
      "ValueError: Valid presets for class_weight include \"balanced\" and \"balanced_subsample\".Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 330, in fit\n",
      "    y, expanded_class_weight = self._validate_y_class_weight(y)\n",
      "  File \"/Users/personal/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 581, in _validate_y_class_weight\n",
      "    raise ValueError('Valid presets for class_weight include '\n",
      "ValueError: Valid presets for class_weight include \"balanced\" and \"balanced_subsample\".Given \"None\".\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=100, min_samples_split=50, min_samples_leaf=27, max_depth=48, criterion=gini, class_weight={1: 0.75, 0: 0.25}, total=  21.2s\n",
      "[CV] n_estimators=100, min_samples_split=50, min_samples_leaf=27, max_depth=48, criterion=gini, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  n_estimators=100, min_samples_split=50, min_samples_leaf=27, max_depth=48, criterion=gini, class_weight={1: 0.75, 0: 0.25}, total=  19.3s\n",
      "[CV] n_estimators=100, min_samples_split=50, min_samples_leaf=27, max_depth=48, criterion=gini, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  n_estimators=100, min_samples_split=50, min_samples_leaf=27, max_depth=48, criterion=gini, class_weight={1: 0.75, 0: 0.25}, total=  17.0s\n",
      "[CV] n_estimators=100, min_samples_split=50, min_samples_leaf=27, max_depth=48, criterion=gini, class_weight={1: 0.75, 0: 0.25} \n",
      "[CV]  n_estimators=100, min_samples_split=50, min_samples_leaf=27, max_depth=48, criterion=gini, class_weight={1: 0.75, 0: 0.25}, total=  17.3s\n",
      "[CV] n_estimators=400, min_samples_split=30, min_samples_leaf=27, max_depth=29, criterion=entropy, class_weight=balanced \n",
      "[CV]  n_estimators=400, min_samples_split=30, min_samples_leaf=27, max_depth=29, criterion=entropy, class_weight=balanced, total=  58.0s\n",
      "[CV] n_estimators=400, min_samples_split=30, min_samples_leaf=27, max_depth=29, criterion=entropy, class_weight=balanced \n",
      "[CV]  n_estimators=400, min_samples_split=30, min_samples_leaf=27, max_depth=29, criterion=entropy, class_weight=balanced, total=  58.1s\n",
      "[CV] n_estimators=400, min_samples_split=30, min_samples_leaf=27, max_depth=29, criterion=entropy, class_weight=balanced \n",
      "[CV]  n_estimators=400, min_samples_split=30, min_samples_leaf=27, max_depth=29, criterion=entropy, class_weight=balanced, total=  59.8s\n",
      "[CV] n_estimators=400, min_samples_split=30, min_samples_leaf=27, max_depth=29, criterion=entropy, class_weight=balanced \n",
      "[CV]  n_estimators=400, min_samples_split=30, min_samples_leaf=27, max_depth=29, criterion=entropy, class_weight=balanced, total=  58.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed: 14.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=4, random_state=0, shuffle=True),\n",
       "                   estimator=RandomForestClassifier(),\n",
       "                   param_distributions={'class_weight': [{0: 0.33, 1: 0.67},\n",
       "                                                         {0: 0.25, 1: 0.75},\n",
       "                                                         {0: 0.2, 1: 0.8},\n",
       "                                                         'None', 'balanced'],\n",
       "                                        'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': range(5, 60),\n",
       "                                        'min_samples_leaf': range(5, 50),\n",
       "                                        'min_samples_split': [10, 20, 30, 40,\n",
       "                                                              50],\n",
       "                                        'n_estimators': [50, 100, 200, 300,\n",
       "                                                         400]},\n",
       "                   scoring='f1', verbose=2)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fold = StratifiedKFold(n_splits=3, shuffle=True, random_state=0) \n",
    "\n",
    "parameters= {\"criterion\": [\"gini\", \"entropy\"], \\\n",
    "             \"class_weight\": [{1:0.67, 0:0.33}, {1:0.75, 0:0.25}, {1:0.8, 0:0.2}, \"None\", \"balanced\"], \\\n",
    "            \"max_depth\": range(5,60) , \\\n",
    "            \"min_samples_leaf\" : range(5,50), \\\n",
    "            \"min_samples_split\" : [10, 20, 30, 40, 50], \\\n",
    "             \"n_estimators\" : [50, 100, 200, 300, 400]}\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model_rs =RandomizedSearchCV(model, parameters, cv=kfold, verbose=2, scoring=\"f1\", n_iter=10)\n",
    "model_rs.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'n_estimators': 300, 'min_samples_split': 40, 'min_samples_leaf': 25, 'max_depth': 25, 'criterion': 'gini', 'class_weight': {1: 0.67, 0: 0.33}}\n",
      "accuracy : 0.6995452809763139\n"
     ]
    }
   ],
   "source": [
    "print(\"tuned hpyerparameters :(best parameters) \",model_rs.best_params_)\n",
    "print(\"accuracy :\",model_rs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rf_clf_rs = model_rs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores for default model on test set\n",
      "\n",
      "Accuracy Score : 0.9576047252661848\n",
      "Precision Score : 0.9985261606484893\n",
      "Recall Score : 0.5544189852700491\n",
      "F1 Score : 0.7129702709813206\n",
      "\n",
      "\n",
      "scores for default model on train set\n",
      "\n",
      "Accuracy Score : 0.9561475091318877\n",
      "Precision Score : 0.9994305239179955\n",
      "Recall Score : 0.538563829787234\n",
      "F1 Score : 0.6999468226535496\n"
     ]
    }
   ],
   "source": [
    "print_scores(rf_clf_rs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_confusion_matrix(rf_clf_rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seems like this model is good at predicting lack of fraud  but not fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "svc_clf = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores for default model on test set\n",
      "\n",
      "Accuracy Score : 0.9568664024248077\n",
      "Precision Score : 0.9868613138686131\n",
      "Recall Score : 0.5531914893617021\n",
      "F1 Score : 0.7089669638175143\n",
      "\n",
      "\n",
      "scores for default model on train set\n",
      "\n",
      "Accuracy Score : 0.9555549079039403\n",
      "Precision Score : 0.9889076894153036\n",
      "Recall Score : 0.5380523731587561\n",
      "F1 Score : 0.6969195097714476\n"
     ]
    }
   ],
   "source": [
    "print_scores(svc_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_confusion_matrix(svc_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoost\n",
    "    - Seems like the best model is our decision tree from the gridsearch \n",
    "    - Let's try to Boost it through AdaBoost\n",
    "    - For time purposes we will use the default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "adab_clf = AdaBoostClassifier(base_estimator = rf_clf_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=RandomForestClassifier(class_weight={0: 0.33,\n",
       "                                                                       1: 0.67},\n",
       "                                                         max_depth=25,\n",
       "                                                         min_samples_leaf=25,\n",
       "                                                         min_samples_split=40,\n",
       "                                                         n_estimators=300))"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adab_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores for default model on test set\n",
      "\n",
      "Accuracy Score : 0.9552343203543949\n",
      "Precision Score : 0.9233289646133683\n",
      "Recall Score : 0.5765139116202946\n",
      "F1 Score : 0.709823677581864\n",
      "\n",
      "\n",
      "scores for default model on train set\n",
      "\n",
      "Accuracy Score : 0.9960849459858553\n",
      "Precision Score : 0.9973469171176907\n",
      "Recall Score : 0.9613338788870703\n",
      "F1 Score : 0.9790093234022605\n"
     ]
    }
   ],
   "source": [
    "print_scores(adab_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_confusion_matrix(adab_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion \n",
    "- The Adaboost model shows a lot of overfitting \n",
    "- Due to processing time constraints, we could not run a gridsearch cross validation on adaboost to optimize hyper parameters and avoid overfitting\n",
    "- All in all, it seems that the decision tree was the most efficient model, in terms of accuracy and processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
